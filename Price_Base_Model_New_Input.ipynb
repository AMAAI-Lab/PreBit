{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Price Base Model New Input",
      "provenance": [],
      "collapsed_sections": [
        "NpHkfoUnkocT",
        "SFfMPY--bvrO",
        "FMo638lbIbdp",
        "R7lIxy82XsK0",
        "mruUFVdyIxfH",
        "ojTvT9eqxR5b",
        "bf_54Mrvw1aO",
        "XqSIcZPr9qCY",
        "_E-oMKnKN-L9",
        "6pN-Is6Lv5OE"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM/K4+LJUKEP2ynnLEFnqEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanzhaoZ/PreBit/blob/main/Price_Base_Model_New_Input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpHkfoUnkocT"
      },
      "source": [
        "#set-ups "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKJf58FLcogN",
        "outputId": "eb536d6d-2a19-4e1e-a7db-1b1ff516223f"
      },
      "source": [
        " !pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.19.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/78/56a7c88a57d0d14945472535d0df9fb4bbad7d34ede658ec7961635c790e/lxml-4.6.2-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22616 sha256=28c0e73ea9ca32f32e526657e8fca4a3bb09626701591c8cae15e42d87cd45be\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.2 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0hPGdzadWND"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaxQ2CSuyy7T"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "import seaborn as sns\r\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BshD6EjfdHGy"
      },
      "source": [
        "# Loading Price Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGzvjjDYdLoi",
        "outputId": "92453041-626d-494a-96ba-f08b96661680"
      },
      "source": [
        "start_date ='2015-01-01'\n",
        "end_date = '2019-12-31'\n",
        "price = yf.download(\"BTC-USD\", start=start_date, end=end_date)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiqImSEpgGt5"
      },
      "source": [
        "def get_technical_indicators(price):\n",
        "    # Create 7 and 21 days Moving Average\n",
        "    dataset = price.copy()\n",
        "\n",
        "    dataset['ma7'] = dataset['Close'].rolling(window=7).mean()\n",
        "    dataset['ma21'] = dataset['Close'].rolling(window=21).mean()\n",
        "    \n",
        "    # Create MACD\n",
        "    #dataset['26ema'] = pd.ewma(dataset['Close'], span=26)\n",
        "    dataset['26ema'] = dataset['Close'].ewm(span=26).mean()\n",
        "    #dataset['12ema'] = pd.ewma(dataset['Close'], span=12)\n",
        "    dataset['12ema'] = dataset['Close'].ewm(span=12).mean()\n",
        "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
        "\n",
        "    # Create Bollinger Bands\n",
        "    #dataset['20sd'] = pd.stats.moments.rolling_std(dataset['Close'],20)\n",
        "    dataset['20sd'] = dataset[\"Close\"].rolling(window=20).std()\n",
        "    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
        "    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
        "    \n",
        "    # Create Exponential moving average\n",
        "    dataset['ema'] = dataset['Close'].ewm(com=0.5).mean()\n",
        "    \n",
        "    # Create Momentum\n",
        "    #dataset['momentum'] = dataset['Close']-1\n",
        "\n",
        "    # Create high-low spred\n",
        "    dataset['spread'] = dataset['High'] - dataset['Low']\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-keoW2D4TEb"
      },
      "source": [
        "The Gold etf SPDR Gold future, has a lot of NAN values. \r\n",
        "That might cause some issues, but let's see how it goes first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szog27YrNQSG"
      },
      "source": [
        " # to be finished \n",
        "# def get_related_asset (price, start_date, end_date):\n",
        "#     other_price = yf.download(\"ETH-USD\", start=start_date, end=end_date)\n",
        "\n",
        "#     price['eth']=other_price[\"Close\"]\n",
        "#     #there are nan values because the price datarange is not the same. so I should probalby fill the value by non-0, coz i need to do division later...\n",
        "#     #let's fill it with the next valid value \n",
        "#     price.eth.fillna(method='bfill', inplace= True, axis=0)\n",
        "\n",
        "#     return price\n",
        "\n",
        " # to be finished \n",
        "def get_related_asset (price, start_date, end_date):\n",
        "    other_price = yf.download(\"ETH-USD GLD\", start=start_date, end=end_date)\n",
        "\n",
        "    price['eth']=other_price.Close['ETH-USD']\n",
        "    price['gold'] = other_price.Close['GLD']\n",
        "    #there are nan values because the price datarange is not the same. so I should probalby fill the value by non-0, coz i need to do division later...\n",
        "    #let's fill it with the next valid value \n",
        "    price.eth.fillna(method='bfill', inplace= True, axis=0)\n",
        "    price.gold.fillna(method='bfill', inplace= True, axis=0) \n",
        "\n",
        "    return price\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "291fHPUribeU"
      },
      "source": [
        "def get_label (price,threshold):\n",
        "\n",
        "\n",
        "    price['change']=price.shift(-1).High/price.Close -1 \n",
        "    price['change_label']=price['change'].apply (lambda x: x> threshold)\n",
        "\n",
        "    #convert True/False to 1/0\n",
        "    class2idx = {True: 1, False:0}\n",
        "    price['change_label'].replace(class2idx, inplace=True)\n",
        "\n",
        "    return price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrQfP2Crtl8X"
      },
      "source": [
        "def normalise_close(price):\n",
        "    \n",
        "    df = price.copy()\n",
        "    for key in df.keys():\n",
        "        if not key in ['change','change_label','Volume','MACD','20sd','spread','eth','gold']:\n",
        "            df[key]=df[key]/price['Close'].shift(1) - 1\n",
        "        \n",
        "    df['Volume']=df['Volume']/price['Volume'].shift(1)-1\n",
        "    df['eth']  = df['eth']/price['eth'].shift(1)-1\n",
        "    df['gold'] = df['gold']/price['gold'].shift(1)-1\n",
        "    df['MACD'] = df['MACD']/price['Close'].shift(1)\n",
        "    df['20sd'] = df['20sd']/price['Close'].shift(1)\n",
        "    df['spread'] = df['spread']/price['Close'].shift(1)\n",
        "\n",
        "\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB1cLbyxCsb_"
      },
      "source": [
        "def get_ma_feature (price,threshold):\n",
        "    price['ma_feature']=price['ma7'].apply(lambda x: x > threshold)\n",
        "    \n",
        "    class2idx = {True: 1, False:0}\n",
        "    price['ma_feature'].replace(class2idx, inplace=True)\n",
        "    return price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr-qb6DFd-Dw"
      },
      "source": [
        "#Here I want to define a function to return a new dataframe, that's INDEPENDANT, and produce relative price. \n",
        "def process_price (original_df,threshold, start_date,end_date):\n",
        "    #get the indicators\n",
        "    df = get_technical_indicators(original_df)\n",
        "\n",
        "    #get related asset\n",
        "    df = get_related_asset(df,start_date,end_date)\n",
        "\n",
        "    #get label\n",
        "    df = get_label(df, threshold)\n",
        "\n",
        "    #normalise the data\n",
        "    df_normalised_close = normalise_close(df)\n",
        "\n",
        "    #get ma label\n",
        "    df_normalised_close = get_ma_feature(df_normalised_close, threshold)\n",
        "\n",
        "    #return both normalized, and un-normalized data (w/o ma label). \n",
        "    return df, df_normalised_close\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS3krSQDeA93",
        "outputId": "56ac7af3-bd2d-43b1-a2a0-1a2bbb8f64da"
      },
      "source": [
        "test_df, test_df_norm = process_price(price,0.05,start_date,end_date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  2 of 2 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "z-lIuKV9eA4H",
        "outputId": "0fe4cfdd-63c4-4d03-a79a-3b08faf4df6d"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "      <th>ema</th>\n",
              "      <th>spread</th>\n",
              "      <th>eth</th>\n",
              "      <th>gold</th>\n",
              "      <th>change</th>\n",
              "      <th>change_label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-01</th>\n",
              "      <td>320.434998</td>\n",
              "      <td>320.434998</td>\n",
              "      <td>314.002991</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>8036550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>6.432007</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02</th>\n",
              "      <td>314.079010</td>\n",
              "      <td>315.838989</td>\n",
              "      <td>313.565002</td>\n",
              "      <td>315.032013</td>\n",
              "      <td>315.032013</td>\n",
              "      <td>7860650</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.655561</td>\n",
              "      <td>314.673129</td>\n",
              "      <td>0.017568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.836258</td>\n",
              "      <td>2.273987</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-03</th>\n",
              "      <td>314.846008</td>\n",
              "      <td>315.149994</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>33054400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>302.592907</td>\n",
              "      <td>301.562504</td>\n",
              "      <td>-1.030403</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.467926</td>\n",
              "      <td>34.067993</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-04</th>\n",
              "      <td>281.145996</td>\n",
              "      <td>287.230011</td>\n",
              "      <td>257.612000</td>\n",
              "      <td>264.195007</td>\n",
              "      <td>264.195007</td>\n",
              "      <td>55629100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.858532</td>\n",
              "      <td>289.767045</td>\n",
              "      <td>-2.091487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>273.058706</td>\n",
              "      <td>29.618011</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.053544</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>265.084015</td>\n",
              "      <td>278.341003</td>\n",
              "      <td>265.084015</td>\n",
              "      <td>274.473999</td>\n",
              "      <td>274.473999</td>\n",
              "      <td>43962800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>287.826987</td>\n",
              "      <td>285.611979</td>\n",
              "      <td>-2.215008</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>274.006134</td>\n",
              "      <td>13.256989</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.047651</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...    change  change_label\n",
              "Date                                ...                        \n",
              "2015-01-01  320.434998  320.434998  ...  0.005060             0\n",
              "2015-01-02  314.079010  315.838989  ...  0.000375             0\n",
              "2015-01-03  314.846008  315.149994  ...  0.021873             0\n",
              "2015-01-04  281.145996  287.230011  ...  0.053544             1\n",
              "2015-01-05  265.084015  278.341003  ...  0.047651             0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "e4KJZaWZeA1r",
        "outputId": "d9f76494-8a14-420b-add8-03f9534b1107"
      },
      "source": [
        "test_df_norm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "      <th>ema</th>\n",
              "      <th>spread</th>\n",
              "      <th>eth</th>\n",
              "      <th>gold</th>\n",
              "      <th>change</th>\n",
              "      <th>change_label</th>\n",
              "      <th>ma_feature</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-01</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02</th>\n",
              "      <td>-0.000541</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>-0.002177</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>-0.021888</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001294</td>\n",
              "      <td>0.001350</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.007236</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-03</th>\n",
              "      <td>-0.000590</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>-0.107767</td>\n",
              "      <td>-0.107767</td>\n",
              "      <td>-0.107767</td>\n",
              "      <td>3.205047</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.039485</td>\n",
              "      <td>-0.042756</td>\n",
              "      <td>-0.003271</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.074799</td>\n",
              "      <td>0.108141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015077</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-04</th>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>-0.083499</td>\n",
              "      <td>-0.060079</td>\n",
              "      <td>-0.060079</td>\n",
              "      <td>0.682956</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038339</td>\n",
              "      <td>0.030899</td>\n",
              "      <td>-0.007441</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.028544</td>\n",
              "      <td>0.105371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053544</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>0.003365</td>\n",
              "      <td>0.053544</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>0.038907</td>\n",
              "      <td>0.038907</td>\n",
              "      <td>-0.209716</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.089449</td>\n",
              "      <td>0.081065</td>\n",
              "      <td>-0.008384</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.037136</td>\n",
              "      <td>0.050179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047651</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Open      High       Low  ...    change  change_label  ma_feature\n",
              "Date                                      ...                                    \n",
              "2015-01-01       NaN       NaN       NaN  ...  0.005060             0           0\n",
              "2015-01-02 -0.000541  0.005060 -0.002177  ...  0.000375             0           0\n",
              "2015-01-03 -0.000590  0.000375 -0.107767  ...  0.021873             0           0\n",
              "2015-01-04  0.000228  0.021873 -0.083499  ...  0.053544             1           0\n",
              "2015-01-05  0.003365  0.053544  0.003365  ...  0.047651             0           0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSRfavFZyt_8",
        "outputId": "09c30d2b-1b23-43d8-aec3-a40fbb8fdf0a"
      },
      "source": [
        "test_df_norm.change_label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1608\n",
              "1     218\n",
              "Name: change_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EuYIwJAHyT6"
      },
      "source": [
        "# Some analysis with MA only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5-Qm6rHx_b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ePkc-bMv5VZ",
        "outputId": "efd5152d-6e8c-47a7-9cc5-f7322122b7ef"
      },
      "source": [
        "(test_df_norm['change_label']==test_df_norm['ma_feature']).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     1537\n",
              "False     289\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCinzG02Dyba",
        "outputId": "2204c0f1-0a1c-4092-f68e-77cfd93fa485"
      },
      "source": [
        "test_df_norm['change_label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1608\n",
              "1     218\n",
              "Name: change_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOgB2oowD_Uz",
        "outputId": "a5739857-2cb7-4112-b072-c6c624f73f62"
      },
      "source": [
        "#7day ma feature\n",
        "\n",
        "#why not get a confusion matrix with these two labels and check it out. \n",
        "accuracy = (test_df_norm['change_label']==test_df_norm['ma_feature']).sum() / len(test_df_norm['change_label']==test_df_norm['ma_feature'])\n",
        "print ('accuracy:', accuracy)\n",
        "print (confusion_matrix(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "print (classification_report(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "\n",
        "#The true label, accuracy is only 0.27, and recall rate is quite low to be honest. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8417305585980285\n",
            "[[1495  113]\n",
            " [ 176   42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91      1608\n",
            "           1       0.27      0.19      0.23       218\n",
            "\n",
            "    accuracy                           0.84      1826\n",
            "   macro avg       0.58      0.56      0.57      1826\n",
            "weighted avg       0.82      0.84      0.83      1826\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt6Jsxx8F5I3",
        "outputId": "15d0d89a-87bb-4aed-c61b-8106ccb3398c"
      },
      "source": [
        "#for 21day ma features\n",
        "\n",
        "#why not get a confusion matrix with these two labels and check it out. \n",
        "accuracy = (test_df_norm['change_label']==test_df_norm['ma_feature']).sum() / len(test_df_norm['change_label']==test_df_norm['ma_feature'])\n",
        "print ('accuracy:', accuracy)\n",
        "print (confusion_matrix(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "print (classification_report(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "\n",
        "#The true label, accuracy is only 0.15, but recall is higher. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7431544359255202\n",
            "[[1301  307]\n",
            " [ 162   56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.81      0.85      1608\n",
            "           1       0.15      0.26      0.19       218\n",
            "\n",
            "    accuracy                           0.74      1826\n",
            "   macro avg       0.52      0.53      0.52      1826\n",
            "weighted avg       0.80      0.74      0.77      1826\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67tCONaUIdX7",
        "outputId": "3a60c80a-bff8-4771-e2b5-2f8f4aec74db"
      },
      "source": [
        "#for ema features\n",
        "\n",
        "#why not get a confusion matrix with these two labels and check it out. \n",
        "accuracy = (test_df_norm['change_label']==test_df_norm['ma_feature']).sum() / len(test_df_norm['change_label']==test_df_norm['ma_feature'])\n",
        "print ('accuracy:', accuracy)\n",
        "print (confusion_matrix(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "print (classification_report(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "\n",
        "#The true label, accuracy is only 0.27, and recall rate is quite low to be honest. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.864184008762322\n",
            "[[1561   47]\n",
            " [ 201   17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93      1608\n",
            "           1       0.27      0.08      0.12       218\n",
            "\n",
            "    accuracy                           0.86      1826\n",
            "   macro avg       0.58      0.52      0.52      1826\n",
            "weighted avg       0.81      0.86      0.83      1826\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH2o4ZSOWDUY"
      },
      "source": [
        "#so bascially 7day ma works best among these 3. got it. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM2W-oEPWNs0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFfMPY--bvrO"
      },
      "source": [
        "# Format Custom Dataset input for Torch Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcbqR134S4I"
      },
      "source": [
        "Creating two dataset classes for future use, 1 is for classification tast, the other for Regression task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me2mllPfb6bP"
      },
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.df = df\n",
        "        self.X, self.Y = self.clean_df()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "    def clean_df(self):\n",
        "        #drop NaN values, and also load the values into torch.tensor. \n",
        "        df = self.df.dropna()\n",
        "        y_values = df.change_label.values\n",
        "        df = df.drop (['change','change_label'],axis=1)\n",
        "        #try put the label as part of the feature see if the model cna leran that \n",
        "        #df = df.drop (['change'],axis=1)\n",
        "        x_values = df.values\n",
        "\n",
        "        return torch.from_numpy(x_values).float(), torch.from_numpy(y_values).long()\n",
        "\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7l-Gu-vkq83"
      },
      "source": [
        "class RegressionDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.df = df\n",
        "        self.X, self.Y = self.clean_df()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "    def clean_df(self):\n",
        "        #drop NaN values, and also load the values into torch.tensor.\n",
        "        df = self.df.dropna()\n",
        "        y_values = df.change.values\n",
        "        df = df.drop (['change','change_label'],axis=1)\n",
        "        x_values = df.values\n",
        "\n",
        "        return torch.from_numpy(x_values).float(), torch.from_numpy(y_values).float()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfHatgydCwHs"
      },
      "source": [
        "# define a function for train_test split, and initiate dataset? \n",
        "def split_train_test (df, threshold):\n",
        "    length = len(df)\n",
        "    split_number  = round(threshold*length)\n",
        "    return df[0:split_number], df[split_number:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVI-SUEoD_k2"
      },
      "source": [
        "#for classification dataset construction\n",
        "test_df_train,test_df_eval = split_train_test(test_df_norm, 0.7)\n",
        "train_dataset = ClassifierDataset(test_df_train)\n",
        "eval_dataset = ClassifierDataset (test_df_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTBt70ZjGOiw"
      },
      "source": [
        "# for Regression dataset construction\n",
        "\n",
        "# test_df_train,test_df_eval = split_train_test(test_df_norm, 0.7)\n",
        "# train_dataset = RegressionDataset(test_df_train)\n",
        "# eval_dataset = RegressionDataset (test_df_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HfWHePSo1Pa",
        "outputId": "d157b846-b791-4180-8981-fd341eda1d0d"
      },
      "source": [
        "eval_dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0009,  0.0467, -0.0125,  0.0358,  0.0358, -0.0817, -0.0207,  0.0035,\n",
              "          0.0373, -0.0022, -0.0395,  0.0413,  0.0861, -0.0791,  0.0226,  0.0592,\n",
              "          0.0472,  0.0000,  0.0000]), tensor(0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMo638lbIbdp"
      },
      "source": [
        "# Format DataLoader, different sampling options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0kk1mR_tJI0"
      },
      "source": [
        "#Now let's try to flow the data into dataloader \n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, )\n",
        "eval_loader = DataLoader(eval_dataset, batch_size = 64, )\n",
        "# add in shuffle/sampler options later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX7oSm_rOE9R"
      },
      "source": [
        "The above is the normal dataloader. Below I will try to use weighted samplers, which will include oversample and undersamples, and in this case, it will also disrupt the ordering/sequence of the input, ummmmmmmmmmm, How will that affect the model performance, let's seeeeeeeee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZvQSmAVOEXy"
      },
      "source": [
        "#obtain the label list. \r\n",
        "target_list = []\r\n",
        "for _,t in train_dataset:\r\n",
        "  target_list.append(t)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN4VLeQuZfHh",
        "outputId": "7bae1de5-d089-494a-b2c2-9f83b3568826"
      },
      "source": [
        "#obtain the class weights\r\n",
        "leng = len(target_list)\r\n",
        "total_true = sum(target_list)\r\n",
        "class_count = [leng-total_true, total_true]\r\n",
        "class_weight = 1./torch.tensor(class_count, dtype=torch.float)\r\n",
        "class_weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0009, 0.0062])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCvHSf-2apzB"
      },
      "source": [
        "#a weight for each sample\r\n",
        "class_weights_all = class_weight[target_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H4P0ryYe-3B"
      },
      "source": [
        "weighted_sampler = WeightedRandomSampler(\r\n",
        "    weights = class_weights_all,\r\n",
        "    num_samples = leng,\r\n",
        "    replacement = True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ku89M3fiah"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 64, sampler=weighted_sampler )\r\n",
        "eval_loader = DataLoader(eval_dataset, batch_size = 64, )\r\n",
        "# add in shuffle/sampler options later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_-C0_dCfsSJ",
        "outputId": "c61c4e9d-a35d-4972-ac50-c855bc207019"
      },
      "source": [
        "for i, batch in enumerate(train_loader):\r\n",
        "    _,t = (m for m in batch)\r\n",
        "    print (sum(t)/len(t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5312)\n",
            "tensor(0.5625)\n",
            "tensor(0.4688)\n",
            "tensor(0.5938)\n",
            "tensor(0.4844)\n",
            "tensor(0.3906)\n",
            "tensor(0.4844)\n",
            "tensor(0.4844)\n",
            "tensor(0.4062)\n",
            "tensor(0.5312)\n",
            "tensor(0.4375)\n",
            "tensor(0.5781)\n",
            "tensor(0.5000)\n",
            "tensor(0.3906)\n",
            "tensor(0.5000)\n",
            "tensor(0.5625)\n",
            "tensor(0.5000)\n",
            "tensor(0.7031)\n",
            "tensor(0.3594)\n",
            "tensor(0.5238)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chR_wC8ytJHm"
      },
      "source": [
        "#next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFK252mLtJGT"
      },
      "source": [
        "# for i, batch in enumerate(train_loader):\n",
        "#     print (i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLdhmP5MtJA8"
      },
      "source": [
        "#weighed random sampler test. \n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
        "# train_dataset = torch.tensor([1, 1 , 1, 1, 1, 1, 1, 1, 1, 0])\n",
        "\n",
        "\n",
        "# class_weights_all = [0.1, 0.1, 0.1, 0.1,0.1, 0.1, 0.1, 0.1,0.1, 0.9]\n",
        "\n",
        "# weighted_sampler = WeightedRandomSampler(\n",
        "#     weights=class_weights_all,\n",
        "#     num_samples=10,\n",
        "#     replacement=True #if True, sampler will draw repeating inputs, False will have 0 repeats. \n",
        "# )\n",
        "\n",
        "# BATCH_SIZE = 5\n",
        "# dataset = TensorDataset(train_dataset)\n",
        "# train_loader = DataLoader(dataset,\n",
        "#                           batch_size=BATCH_SIZE,\n",
        "#                           sampler=weighted_sampler\n",
        "# )\n",
        "# for batch in train_loader:\n",
        "#     print(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7lIxy82XsK0"
      },
      "source": [
        "#Format Dataset and DataLoader for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_t3QEgzXvh3"
      },
      "source": [
        "class LSTMDataset(Dataset):\r\n",
        "    def __init__(self,df,window_size):\r\n",
        "        self.df = df\r\n",
        "        self.window_size = window_size\r\n",
        "        self.X, self.Y = self.clean_df()\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.Y)\r\n",
        "\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.X[idx], self.Y[idx]\r\n",
        "\r\n",
        "\r\n",
        "    def clean_df(self):\r\n",
        "        #drop NaN values, and also load the values into torch.tensor. \r\n",
        "        df = self.df.dropna()\r\n",
        "        y_values = df.change_label.values[self.window_size:]\r\n",
        "        df = df.drop (['change','change_label'],axis=1)\r\n",
        "        #try put the label as part of the feature see if the model cna leran that \r\n",
        "        #df = df.drop (['change'],axis=1)\r\n",
        "        x_values = df.values\r\n",
        "        output = self.process(x_values)\r\n",
        "\r\n",
        "\r\n",
        "        return torch.tensor(output,dtype=torch.float), torch.from_numpy(y_values).long()\r\n",
        "\r\n",
        "    def process(self,data):\r\n",
        "        output = []\r\n",
        "        for i in range(self.window_size-1, len(data)):\r\n",
        "            raw_data = data[i-self.window_size+1:i+1]\r\n",
        "            output.append(raw_data)\r\n",
        "        return output\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7SAU11Qe11f"
      },
      "source": [
        "# define a function for train_test split, and initiate dataset? \r\n",
        "def split_train_test (df, threshold):\r\n",
        "    length = len(df)\r\n",
        "    split_number  = round(threshold*length)\r\n",
        "    return df[0:split_number], df[split_number:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JirYuopfdwYd"
      },
      "source": [
        "#for classification dataset construction\r\n",
        "test_df_train,test_df_eval = split_train_test(test_df_norm, 0.7)\r\n",
        "WINDOW_SIZE = 10 \r\n",
        "train_dataset = LSTMDataset(test_df_train, window_size=WINDOW_SIZE)\r\n",
        "eval_dataset = LSTMDataset (test_df_eval, window_size= WINDOW_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9nGvys-eNX9",
        "outputId": "d3de324c-f447-4222-e241-50786c5caf52"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2.9815e-04,  7.7955e-02, -4.8741e-04,  7.3738e-02,  7.3738e-02,\n",
              "           2.4421e-01,  9.5185e-04,  1.9347e-01,  1.2295e-01,  6.5804e-02,\n",
              "          -5.7147e-02,  1.8713e-01,  5.6772e-01, -1.8079e-01,  4.9743e-02,\n",
              "           7.8442e-02,  0.0000e+00,  2.4160e-04,  0.0000e+00],\n",
              "         [ 1.8731e-03,  4.4611e-02, -2.0406e-03,  2.8687e-02,  2.8687e-02,\n",
              "           1.2097e-01, -5.2953e-02,  9.4539e-02,  4.4277e-02, -1.6947e-03,\n",
              "          -4.5971e-02,  1.6074e-01,  4.1603e-01, -2.2695e-01,  1.1676e-02,\n",
              "           4.6651e-02,  0.0000e+00,  8.0496e-03,  0.0000e+00],\n",
              "         [ 4.7553e-04,  6.1652e-03, -3.5175e-02, -2.2579e-03, -2.2579e-03,\n",
              "          -2.6600e-01, -6.4195e-02,  4.7255e-02,  1.3600e-02, -2.5246e-02,\n",
              "          -3.8846e-02,  1.5229e-01,  3.5183e-01, -2.5732e-01, -7.0176e-03,\n",
              "           4.1340e-02,  0.0000e+00, -7.9853e-03,  0.0000e+00],\n",
              "         [-7.6864e-04,  6.5833e-02, -1.2268e-02,  6.4274e-02,  6.4274e-02,\n",
              "           6.5308e-03, -3.2272e-02,  4.2829e-02,  2.0149e-02, -9.3590e-03,\n",
              "          -2.9508e-02,  1.5119e-01,  3.4520e-01, -2.5954e-01,  4.1259e-02,\n",
              "           7.8101e-02,  0.0000e+00, -9.9815e-03,  0.0000e+00],\n",
              "         [-1.9972e-03,  2.9159e-02, -1.5965e-02,  2.3688e-02,  2.3688e-02,\n",
              "           3.5510e-01, -6.5712e-02, -2.2162e-02, -3.5809e-02, -5.4675e-02,\n",
              "          -1.8865e-02,  1.3917e-01,  2.5617e-01, -3.0050e-01,  8.5837e-03,\n",
              "           4.5125e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 1.4228e-03,  2.1940e-01,  1.4228e-03,  7.7862e-02,  7.7862e-02,\n",
              "           2.1800e+00, -5.4330e-02, -4.4977e-02, -4.6473e-02, -5.2481e-02,\n",
              "          -6.0081e-03,  1.3290e-01,  2.2082e-01, -3.1078e-01,  4.6990e-02,\n",
              "           2.1798e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [-1.1189e-03,  7.3390e-03, -8.3445e-02, -3.6559e-02, -3.6559e-02,\n",
              "          -5.8426e-01, -9.5395e-02, -1.1792e-01, -1.0868e-01, -1.0780e-01,\n",
              "           8.7805e-04,  1.1612e-01,  1.1432e-01, -3.5017e-01, -3.3920e-02,\n",
              "           9.0784e-02,  0.0000e+00,  1.1464e-02,  0.0000e+00],\n",
              "         [-4.7061e-04,  1.1614e-02, -1.3826e-01, -1.1219e-01, -1.1219e-01,\n",
              "          -1.0541e-03, -5.7263e-02, -9.5369e-02, -7.7987e-02, -7.9887e-02,\n",
              "          -1.8997e-03,  1.1371e-01,  1.3206e-01, -3.2280e-01, -7.3882e-02,\n",
              "           1.4988e-01,  0.0000e+00, -7.8778e-03,  0.0000e+00],\n",
              "         [-2.4239e-03,  2.0482e-02, -5.6444e-02, -1.7185e-03, -1.7185e-03,\n",
              "          -2.7369e-01,  6.1936e-02,  8.8042e-03,  3.5189e-02,  3.0479e-02,\n",
              "          -4.7092e-03,  1.1584e-01,  2.4048e-01, -2.2287e-01,  1.3238e-02,\n",
              "           7.6925e-02,  0.0000e+00, -2.1552e-02,  1.0000e+00],\n",
              "         [-3.1733e-03,  3.9989e-02, -3.2863e-02, -3.0354e-02, -3.0354e-02,\n",
              "          -1.7410e-01,  5.9816e-02, -2.5069e-03,  3.1433e-02,  2.2557e-02,\n",
              "          -8.8765e-03,  1.0831e-01,  2.1411e-01, -2.1913e-01, -1.5242e-02,\n",
              "           7.2852e-02,  0.0000e+00,  2.2276e-02,  1.0000e+00]]), tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5QoruL2evOV"
      },
      "source": [
        "#a vanilla dataloader\r\n",
        "\r\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, )\r\n",
        "eval_loader = DataLoader(eval_dataset, batch_size = 64, )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GBZUjaKg78J"
      },
      "source": [
        "#weighted_dataloader\r\n",
        "\r\n",
        "#obtain the label list. \r\n",
        "target_list = []\r\n",
        "for _,t in train_dataset:\r\n",
        "  target_list.append(t)\r\n",
        "\r\n",
        "#obtain the class weights\r\n",
        "leng = len(target_list)\r\n",
        "total_true = sum(target_list)\r\n",
        "class_count = [leng-total_true, total_true]\r\n",
        "class_weight = 1./torch.tensor(class_count, dtype=torch.float)\r\n",
        "\r\n",
        "\r\n",
        "#a weight for each sample\r\n",
        "class_weights_all = class_weight[target_list]\r\n",
        "\r\n",
        "weighted_sampler = WeightedRandomSampler(\r\n",
        "    weights = class_weights_all,\r\n",
        "    num_samples = leng,\r\n",
        "    replacement = True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o6_8iXAhUB1"
      },
      "source": [
        "#train_loader = DataLoader(train_dataset, batch_size = 64, sampler=weighted_sampler )\r\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, )\r\n",
        "eval_loader = DataLoader(eval_dataset, batch_size = 64, )\r\n",
        "# add in shuffle/sampler options later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xgqDc28hZ4D",
        "outputId": "0dd1060e-05cf-45f7-aaec-66debfd01c9d"
      },
      "source": [
        "next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[ 2.9815e-04,  7.7955e-02, -4.8741e-04,  ...,  0.0000e+00,\n",
              "            2.4160e-04,  0.0000e+00],\n",
              "          [ 1.8731e-03,  4.4611e-02, -2.0406e-03,  ...,  0.0000e+00,\n",
              "            8.0496e-03,  0.0000e+00],\n",
              "          [ 4.7553e-04,  6.1652e-03, -3.5175e-02,  ...,  0.0000e+00,\n",
              "           -7.9853e-03,  0.0000e+00],\n",
              "          ...,\n",
              "          [-4.7061e-04,  1.1614e-02, -1.3826e-01,  ...,  0.0000e+00,\n",
              "           -7.8778e-03,  0.0000e+00],\n",
              "          [-2.4239e-03,  2.0482e-02, -5.6444e-02,  ...,  0.0000e+00,\n",
              "           -2.1552e-02,  1.0000e+00],\n",
              "          [-3.1733e-03,  3.9989e-02, -3.2863e-02,  ...,  0.0000e+00,\n",
              "            2.2276e-02,  1.0000e+00]],\n",
              " \n",
              "         [[ 1.8731e-03,  4.4611e-02, -2.0406e-03,  ...,  0.0000e+00,\n",
              "            8.0496e-03,  0.0000e+00],\n",
              "          [ 4.7553e-04,  6.1652e-03, -3.5175e-02,  ...,  0.0000e+00,\n",
              "           -7.9853e-03,  0.0000e+00],\n",
              "          [-7.6864e-04,  6.5833e-02, -1.2268e-02,  ...,  0.0000e+00,\n",
              "           -9.9815e-03,  0.0000e+00],\n",
              "          ...,\n",
              "          [-2.4239e-03,  2.0482e-02, -5.6444e-02,  ...,  0.0000e+00,\n",
              "           -2.1552e-02,  1.0000e+00],\n",
              "          [-3.1733e-03,  3.9989e-02, -3.2863e-02,  ...,  0.0000e+00,\n",
              "            2.2276e-02,  1.0000e+00],\n",
              "          [ 7.0625e-05,  3.1264e-02, -4.4677e-02,  ...,  0.0000e+00,\n",
              "           -8.3434e-03,  1.0000e+00]],\n",
              " \n",
              "         [[ 4.7553e-04,  6.1652e-03, -3.5175e-02,  ...,  0.0000e+00,\n",
              "           -7.9853e-03,  0.0000e+00],\n",
              "          [-7.6864e-04,  6.5833e-02, -1.2268e-02,  ...,  0.0000e+00,\n",
              "           -9.9815e-03,  0.0000e+00],\n",
              "          [-1.9972e-03,  2.9159e-02, -1.5965e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [-3.1733e-03,  3.9989e-02, -3.2863e-02,  ...,  0.0000e+00,\n",
              "            2.2276e-02,  1.0000e+00],\n",
              "          [ 7.0625e-05,  3.1264e-02, -4.4677e-02,  ...,  0.0000e+00,\n",
              "           -8.3434e-03,  1.0000e+00],\n",
              "          [-2.7453e-03,  6.4884e-02, -2.5057e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  1.0000e+00]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-2.4258e-04,  3.4845e-02, -2.3194e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-6.1106e-04,  9.8598e-04, -8.4670e-02,  ...,  0.0000e+00,\n",
              "            2.4499e-03,  0.0000e+00],\n",
              "          [ 7.6427e-03,  1.4638e-02, -3.6971e-02,  ...,  0.0000e+00,\n",
              "            1.3966e-03,  1.0000e+00],\n",
              "          ...,\n",
              "          [ 6.8394e-04,  2.6900e-02, -1.4416e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-2.9090e-04,  4.8641e-03, -1.9339e-02,  ...,  0.0000e+00,\n",
              "           -7.9118e-04,  0.0000e+00],\n",
              "          [-4.0611e-06,  1.3582e-02, -1.2546e-02,  ...,  0.0000e+00,\n",
              "            1.7068e-02,  0.0000e+00]],\n",
              " \n",
              "         [[-6.1106e-04,  9.8598e-04, -8.4670e-02,  ...,  0.0000e+00,\n",
              "            2.4499e-03,  0.0000e+00],\n",
              "          [ 7.6427e-03,  1.4638e-02, -3.6971e-02,  ...,  0.0000e+00,\n",
              "            1.3966e-03,  1.0000e+00],\n",
              "          [ 3.2086e-04,  3.3132e-02, -5.2479e-03,  ...,  0.0000e+00,\n",
              "            6.5371e-03,  0.0000e+00],\n",
              "          ...,\n",
              "          [-2.9090e-04,  4.8641e-03, -1.9339e-02,  ...,  0.0000e+00,\n",
              "           -7.9118e-04,  0.0000e+00],\n",
              "          [-4.0611e-06,  1.3582e-02, -1.2546e-02,  ...,  0.0000e+00,\n",
              "            1.7068e-02,  0.0000e+00],\n",
              "          [-7.4007e-04,  2.9073e-02, -7.5059e-03,  ...,  0.0000e+00,\n",
              "           -2.7682e-03,  0.0000e+00]],\n",
              " \n",
              "         [[ 7.6427e-03,  1.4638e-02, -3.6971e-02,  ...,  0.0000e+00,\n",
              "            1.3966e-03,  1.0000e+00],\n",
              "          [ 3.2086e-04,  3.3132e-02, -5.2479e-03,  ...,  0.0000e+00,\n",
              "            6.5371e-03,  0.0000e+00],\n",
              "          [ 1.3679e-04,  3.3312e-02, -1.3354e-02,  ...,  0.0000e+00,\n",
              "           -3.6370e-03,  0.0000e+00],\n",
              "          ...,\n",
              "          [-4.0611e-06,  1.3582e-02, -1.2546e-02,  ...,  0.0000e+00,\n",
              "            1.7068e-02,  0.0000e+00],\n",
              "          [-7.4007e-04,  2.9073e-02, -7.5059e-03,  ...,  0.0000e+00,\n",
              "           -2.7682e-03,  0.0000e+00],\n",
              "          [ 2.7272e-04,  1.2008e-02, -4.4505e-03,  ...,  0.0000e+00,\n",
              "            1.2231e-02,  0.0000e+00]]]),\n",
              " tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mruUFVdyIxfH"
      },
      "source": [
        "\n",
        "\n",
        "# Torch Model 1 - FeedForward Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2zH_3fttI6v"
      },
      "source": [
        "#let's first try a simple FC NN\n",
        "class FFNN (nn.Module):\n",
        "    def __init__(self, input_size, num_classes,num_hidden, hidden_dim ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert num_hidden > 0 \n",
        "\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([])\n",
        "        self.hidden_layers.append (self.fc1)\n",
        "        for i in range (num_hidden -1 ):\n",
        "            self.hidden_layers.append(self.fc2)\n",
        "        \n",
        "        self.final_layer = nn.Linear (hidden_dim,num_classes)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = hidden_layer(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.relu(x)\n",
        "        \n",
        "        out = self.final_layer(x)\n",
        "        out_dist = F.log_softmax(out, dim= -1) #why is it -1, ok, coz it's batch x input x class. \n",
        "\n",
        "        return out_dist\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbT1kH2jFB6E"
      },
      "source": [
        "#try initiating the model\n",
        "INPUT_SIZE = 19\n",
        "NUM_CLASSES = 2\n",
        "NUM_HIDDEN = 2\n",
        "HIDDEN_DIM = 512\n",
        "\n",
        "model = FFNN(INPUT_SIZE, NUM_CLASSES, NUM_HIDDEN, HIDDEN_DIM)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgc97Ziqkn1G",
        "outputId": "a486e1f9-b527-437f-82ff-ce8597aa498d"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (fc1): Linear(in_features=19, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=19, out_features=512, bias=True)\n",
              "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (final_layer): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nW0_Vjqk4Ec",
        "outputId": "95624251-e5d0-428a-f5f9-d51d447c74b3"
      },
      "source": [
        "#print model parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 273,922 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy_YDstOu6kG"
      },
      "source": [
        "#define loss fuction and optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.NLLLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhKFYZjEvrJ9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ejBYTW2rVg"
      },
      "source": [
        "#define a function to calcualte prediction accuracy\n",
        "def accuracy(pred,label):\n",
        "    _,pred_label = torch.max(pred,dim=1)\n",
        "    correct = (pred_label==label).float()\n",
        "    accuracy = correct.sum()/len(correct)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGnVYr78lcs0"
      },
      "source": [
        "#can i define a function to calculate the f1 score/confusion matrix? \r\n",
        "def get_cfm (pred, label):\r\n",
        "    _,pred_label = torch.max(pred,dim=1)\r\n",
        "    m = classification_report(pred_label.cpu(), label.cpu())\r\n",
        "    return m\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV01Q5NlvukI"
      },
      "source": [
        "#now define the training and evaluation loop\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss= 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data, label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data)\n",
        "        loss = loss_fn(pred,label)\n",
        "        acc  = accuracy(pred,label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a07XNBqh5HdM"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0 \n",
        "    epoch_acc = 0 \n",
        "\n",
        "    pred_list =[]\n",
        "    label_list =[]\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        data,label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data)\n",
        "        loss = loss_fn(pred,label)\n",
        "        acc = accuracy(pred,label)\n",
        "        \n",
        "        #append the prediction result and show it per epoch later. \n",
        "        if step ==0:     \n",
        "            pred_list=pred.cpu().detach().numpy()\n",
        "            label_list = label.cpu().detach().numpy()\n",
        "        if step != 0:\n",
        "            pred_list = np.concatenate([pred_list,pred.cpu().detach().numpy()],axis =0)\n",
        "            label_list = np.concatenate([label_list,label.cpu().detach().numpy()],axis =0)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    report = get_cfm(torch.tensor(pred_list),torch.tensor(label_list))\n",
        "    print (report)\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EZeClpayNzv",
        "outputId": "2fced397-80ea-41f2-a9de-b0be86c932b8"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for i in range(N_EPOCHS):\n",
        "    train_loss,train_acc = train(model,train_loader, optimizer, loss_fn)\n",
        "    \n",
        "    eval_loss, eval_acc = evaluate(model,eval_loader, loss_fn)\n",
        "    \n",
        "    print (f' Epoch Number {i}') \n",
        "    print (f' Train. Loss: {train_loss:.3f} Train. Acc: {train_acc*100:.2f}%')\n",
        "    print (f' Eval loss , {eval_loss:.3f}, eval acc, {eval_acc*100:.2f} %')\n",
        "    # print(f'\\t Train. Loss: {train_loss:.3f} |  Train. Acc: {train_acc*100:.2f}%')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.91       480\n",
            "           1       0.25      0.19      0.22        67\n",
            "\n",
            "    accuracy                           0.83       547\n",
            "   macro avg       0.57      0.56      0.56       547\n",
            "weighted avg       0.81      0.83      0.82       547\n",
            "\n",
            " Epoch Number 0\n",
            " Train. Loss: 0.678 Train. Acc: 55.99%\n",
            " Eval loss , 0.589, eval acc, 83.45 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.91       478\n",
            "           1       0.29      0.22      0.25        69\n",
            "\n",
            "    accuracy                           0.84       547\n",
            "   macro avg       0.59      0.57      0.58       547\n",
            "weighted avg       0.82      0.84      0.82       547\n",
            "\n",
            " Epoch Number 1\n",
            " Train. Loss: 0.618 Train. Acc: 67.00%\n",
            " Eval loss , 0.471, eval acc, 83.80 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.88       448\n",
            "           1       0.33      0.17      0.23        99\n",
            "\n",
            "    accuracy                           0.79       547\n",
            "   macro avg       0.58      0.55      0.55       547\n",
            "weighted avg       0.74      0.79      0.76       547\n",
            "\n",
            " Epoch Number 2\n",
            " Train. Loss: 0.608 Train. Acc: 67.09%\n",
            " Eval loss , 0.478, eval acc, 79.29 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.93      0.87       437\n",
            "           1       0.37      0.17      0.24       110\n",
            "\n",
            "    accuracy                           0.78       547\n",
            "   macro avg       0.59      0.55      0.55       547\n",
            "weighted avg       0.73      0.78      0.74       547\n",
            "\n",
            " Epoch Number 3\n",
            " Train. Loss: 0.602 Train. Acc: 67.71%\n",
            " Eval loss , 0.512, eval acc, 78.07 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       427\n",
            "           1       0.39      0.17      0.23       120\n",
            "\n",
            "    accuracy                           0.76       547\n",
            "   macro avg       0.60      0.55      0.55       547\n",
            "weighted avg       0.71      0.76      0.72       547\n",
            "\n",
            " Epoch Number 4\n",
            " Train. Loss: 0.587 Train. Acc: 69.55%\n",
            " Eval loss , 0.527, eval acc, 76.68 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHUUqSS434YB"
      },
      "source": [
        "# #obtain the label list. \r\n",
        "# target_list = []\r\n",
        "# for _,t in eval_dataset:\r\n",
        "#   target_list.append(t)\r\n",
        "\r\n",
        "# #obtain the class weights\r\n",
        "# leng = len(target_list)\r\n",
        "# total_true = sum(target_list)\r\n",
        "# class_count = [leng-total_true, total_true]\r\n",
        "# class_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRZib4vB9pq7"
      },
      "source": [
        "# for step,batch in enumerate(eval_loader):\r\n",
        "\r\n",
        "#     data,label = (t for t in batch)\r\n",
        "#     data = data.to(device)\r\n",
        "#     label = label.to(device)\r\n",
        "\r\n",
        "#     pred = model(data)\r\n",
        "#     loss = loss_fn(pred,label)\r\n",
        "#     acc = accuracy(pred,label)\r\n",
        "#     report = get_cfm(pred,label)\r\n",
        "    \r\n",
        "#     epoch_loss += loss.item()\r\n",
        "#     epoch_acc += acc     \r\n",
        "\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy1Db8zvm_fU"
      },
      "source": [
        "    # pred_list =[]\r\n",
        "    # label_list =[]\r\n",
        "    # for step,batch in enumerate(eval_loader):\r\n",
        "    #     data,label = (t for t in batch)\r\n",
        "    #     data = data.to(device)\r\n",
        "    #     label = label.to(device)\r\n",
        "\r\n",
        "    #     pred = model(data)\r\n",
        "    #     loss = loss_fn(pred,label)\r\n",
        "    #     acc = accuracy(pred,label)\r\n",
        "    #     if step ==0:\r\n",
        "    #         pred_list=pred.cpu().detach().numpy()\r\n",
        "    #         label_list = label.cpu().detach().numpy()\r\n",
        "    #     if step != 0:\r\n",
        "    #         pred_list = np.concatenate([pred_list,pred.cpu().detach().numpy()],axis =0)\r\n",
        "    #         label_list = np.concatenate([label_list,label.cpu().detach().numpy()],axis =0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # report = get_cfm(torch.tensor(pred_list),torch.tensor(label_list))\r\n",
        "    # print (report)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RRyt4SystDX",
        "outputId": "a2bec302-9acf-413c-98ae-3d3dd0c3f213"
      },
      "source": [
        "target = torch.empty(3).random_(2)\r\n",
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojTvT9eqxR5b"
      },
      "source": [
        "# Torch Model 1.1 - FeedForward with CE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLJPZbgaxZaG"
      },
      "source": [
        "#let's first try a simple FC NN\r\n",
        "class FFNN (nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes,num_hidden, hidden_dim ):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        assert num_hidden > 0 \r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\r\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\r\n",
        "\r\n",
        "        self.hidden_layers = nn.ModuleList([])\r\n",
        "        self.hidden_layers.append (self.fc1)\r\n",
        "        for i in range (num_hidden -1 ):\r\n",
        "            self.hidden_layers.append(self.fc2)\r\n",
        "        \r\n",
        "        self.final_layer = nn.Linear (hidden_dim,num_classes)\r\n",
        "        self.dropout = nn.Dropout()\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self,x):\r\n",
        "        for hidden_layer in self.hidden_layers:\r\n",
        "            x = hidden_layer(x)\r\n",
        "            x = self.dropout(x)\r\n",
        "            x = self.relu(x)\r\n",
        "        \r\n",
        "        out = self.final_layer(x)\r\n",
        "         #why is it -1, ok, coz it's batch x input x class. \r\n",
        "\r\n",
        "        return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMlcM_qozOB0"
      },
      "source": [
        "#try initiating the model\r\n",
        "INPUT_SIZE = 19\r\n",
        "NUM_CLASSES = 2\r\n",
        "NUM_HIDDEN = 2\r\n",
        "HIDDEN_DIM = 512\r\n",
        "\r\n",
        "model = FFNN(INPUT_SIZE, NUM_CLASSES, NUM_HIDDEN, HIDDEN_DIM)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTZe1h5BzRp5"
      },
      "source": [
        "#define loss fuction and optimizer\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aPZQU0u0GuL"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = model.to(device)\r\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08VJ2ZgqzVc4"
      },
      "source": [
        "#now define the training and evaluation loop\r\n",
        "def train(model, dataloader, optimizer, loss_fn):\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    epoch_loss= 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        data, label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "\r\n",
        "    return epoch_loss/len(dataloader)\r\n",
        "        \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0cFc_FIzsRA"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    epoch_loss = 0 \r\n",
        "    epoch_acc = 0 \r\n",
        "\r\n",
        "    pred_list =[]\r\n",
        "    label_list =[]\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        data,label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        \r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "\r\n",
        "\r\n",
        "    return epoch_loss/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap6hirwVzvcC",
        "outputId": "84505724-dc75-40db-b677-e01db7fdff06"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "\r\n",
        "for i in range(N_EPOCHS):\r\n",
        "    train_loss = train(model,train_loader, optimizer, loss_fn)\r\n",
        "    \r\n",
        "    eval_loss = evaluate(model,eval_loader, loss_fn)\r\n",
        "    \r\n",
        "    print (f' Epoch Number {i}') \r\n",
        "    print (f' Train. Loss: {train_loss:.3f} ')\r\n",
        "    print (f' Eval loss , {eval_loss:.3f} ')\r\n",
        "    # print(f'\\t Train. Loss: {train_loss:.3f} |  Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch Number 0\n",
            " Train. Loss: 0.664 \n",
            " Eval loss , 0.591 \n",
            " Epoch Number 1\n",
            " Train. Loss: 0.622 \n",
            " Eval loss , 0.504 \n",
            " Epoch Number 2\n",
            " Train. Loss: 0.617 \n",
            " Eval loss , 0.569 \n",
            " Epoch Number 3\n",
            " Train. Loss: 0.579 \n",
            " Eval loss , 0.488 \n",
            " Epoch Number 4\n",
            " Train. Loss: 0.601 \n",
            " Eval loss , 0.527 \n",
            " Epoch Number 5\n",
            " Train. Loss: 0.573 \n",
            " Eval loss , 0.472 \n",
            " Epoch Number 6\n",
            " Train. Loss: 0.603 \n",
            " Eval loss , 0.544 \n",
            " Epoch Number 7\n",
            " Train. Loss: 0.581 \n",
            " Eval loss , 0.543 \n",
            " Epoch Number 8\n",
            " Train. Loss: 0.602 \n",
            " Eval loss , 0.536 \n",
            " Epoch Number 9\n",
            " Train. Loss: 0.585 \n",
            " Eval loss , 0.487 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf_54Mrvw1aO"
      },
      "source": [
        "# Torch Model 2 - Feedforward Classification with F1 loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8hcgMTYw7h6"
      },
      "source": [
        "#let's first try a simple FC NN\r\n",
        "class FFNN_F1 (nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes,num_hidden, hidden_dim ):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        assert num_hidden > 0 \r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\r\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\r\n",
        "\r\n",
        "        self.hidden_layers = nn.ModuleList([])\r\n",
        "        self.hidden_layers.append (self.fc1)\r\n",
        "        for i in range (num_hidden -1 ):\r\n",
        "            self.hidden_layers.append(self.fc2)\r\n",
        "        \r\n",
        "        self.final_layer = nn.Linear (hidden_dim,num_classes)\r\n",
        "        self.dropout = nn.Dropout()\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self,x):\r\n",
        "        for hidden_layer in self.hidden_layers:\r\n",
        "            x = hidden_layer(x)\r\n",
        "            x = self.dropout(x)\r\n",
        "            x = self.relu(x)\r\n",
        "        \r\n",
        "        out = self.final_layer(x)\r\n",
        "               \r\n",
        "        return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_3EXVoYrtc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNYld1FHw7fq",
        "outputId": "e7f2f390-5bf2-4ece-df2f-bf8a53da78f0"
      },
      "source": [
        "#try initiating the model\r\n",
        "INPUT_SIZE = 19\r\n",
        "NUM_CLASSES = 2\r\n",
        "NUM_HIDDEN = 2\r\n",
        "HIDDEN_DIM = 512\r\n",
        "\r\n",
        "model = FFNN_F1(INPUT_SIZE, NUM_CLASSES, NUM_HIDDEN, HIDDEN_DIM)\r\n",
        "\r\n",
        "model\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN_F1(\n",
              "  (fc1): Linear(in_features=19, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=19, out_features=512, bias=True)\n",
              "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (final_layer): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKh99uxBY6ie",
        "outputId": "bc4d55f7-9c5d-4f0b-b15b-defcfd488aa4"
      },
      "source": [
        "#print model parameters\r\n",
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 273,922 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb7-RwCBw7dp",
        "outputId": "b2d9ad1d-e510-492e-d5d7-d56bcbc5862f"
      },
      "source": [
        "#define optimizer, loss function\r\n",
        "class F1_Loss(nn.Module):\r\n",
        "    '''Calculate F1 score. Can work with gpu tensors\r\n",
        "    \r\n",
        "    The original implmentation is written by Michal Haltuf on Kaggle.\r\n",
        "    \r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    torch.Tensor\r\n",
        "        `ndim` == 1. epsilon <= val <= 1\r\n",
        "    \r\n",
        "    Reference\r\n",
        "    ---------\r\n",
        "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\r\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\r\n",
        "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\r\n",
        "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\r\n",
        "    '''\r\n",
        "    def __init__(self, epsilon=1e-7):\r\n",
        "        super().__init__()\r\n",
        "        self.epsilon = epsilon\r\n",
        "        \r\n",
        "    def forward(self, y_pred, y_true,):\r\n",
        "        assert y_pred.ndim == 2\r\n",
        "        assert y_true.ndim == 1\r\n",
        "        y_true = F.one_hot(y_true, 2).to(torch.float32)\r\n",
        "        y_pred = F.softmax(y_pred, dim=1)\r\n",
        "        \r\n",
        "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\r\n",
        "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\r\n",
        "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\r\n",
        "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\r\n",
        "\r\n",
        "        precision = tp / (tp + fp + self.epsilon)\r\n",
        "        recall = tp / (tp + fn + self.epsilon)\r\n",
        "\r\n",
        "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\r\n",
        "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\r\n",
        "        return 1 - f1.mean()\r\n",
        "\r\n",
        "\r\n",
        "params = model.parameters()\r\n",
        "optimizer = optim.Adam(params)\r\n",
        "loss_fn =F1_Loss()\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = model.to(device)\r\n",
        "loss_fn = loss_fn.to(device)\r\n",
        "\r\n",
        "print (device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hgaRdJEw7ak"
      },
      "source": [
        "def accuracy(preds, y):\r\n",
        "    \"\"\"\r\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #round predictions to the closest integer\r\n",
        "    prediciton = F.softmax(preds, dim =1)\r\n",
        "    _, pred = torch.max(prediciton, 1)\r\n",
        "    correct = (pred == y).float() #convert into float for division \r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0M9YnRqa1_l"
      },
      "source": [
        "#can i define a function to calculate the f1 score/confusion matrix? \r\n",
        "def get_cfm (preds, label):\r\n",
        "    pred = F.softmax(preds, dim =1)\r\n",
        "    _,pred_label = torch.max(pred,dim=1)\r\n",
        "    m = classification_report(pred_label.cpu(), label.cpu())\r\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kn6Ua6KZZYF"
      },
      "source": [
        "#now define the training and evaluation loop\r\n",
        "def train(model, dataloader, optimizer, loss_fn):\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    epoch_loss= 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        data, label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        acc  = accuracy(pred,label)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc\r\n",
        "\r\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUWmYf6mZZVI"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    epoch_loss = 0 \r\n",
        "    epoch_acc = 0 \r\n",
        "\r\n",
        "    pred_list =[]\r\n",
        "    label_list =[]\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        data,label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        acc = accuracy(pred,label)\r\n",
        "        \r\n",
        "        #append the prediction result and show it per epoch later. \r\n",
        "        if step ==0:     \r\n",
        "            pred_list=pred.cpu().detach().numpy()\r\n",
        "            label_list = label.cpu().detach().numpy()\r\n",
        "        if step != 0:\r\n",
        "            pred_list = np.concatenate([pred_list,pred.cpu().detach().numpy()],axis =0)\r\n",
        "            label_list = np.concatenate([label_list,label.cpu().detach().numpy()],axis =0)\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc\r\n",
        "\r\n",
        "    report = get_cfm(torch.tensor(pred_list),torch.tensor(label_list))\r\n",
        "    print (report)\r\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvIYSXJCZZSe",
        "outputId": "fe276acd-01e6-41f9-9c45-9ce877d28456"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "\r\n",
        "for i in range(N_EPOCHS):\r\n",
        "    train_loss,train_acc = train(model,train_loader, optimizer, loss_fn)\r\n",
        "    \r\n",
        "    eval_loss, eval_acc = evaluate(model,eval_loader, loss_fn)\r\n",
        "    \r\n",
        "    print (f' Epoch Number {i}') \r\n",
        "    print (f' Train. Loss: {train_loss:.3f} Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    print (f' Eval loss , {eval_loss:.3f}, eval acc, {eval_acc*100:.2f} %')\r\n",
        "    # print(f'\\t Train. Loss: {train_loss:.3f} |  Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       474\n",
            "           1       0.27      0.19      0.23        73\n",
            "\n",
            "    accuracy                           0.82       547\n",
            "   macro avg       0.58      0.56      0.56       547\n",
            "weighted avg       0.80      0.82      0.81       547\n",
            "\n",
            " Epoch Number 0\n",
            " Train. Loss: 0.481 Train. Acc: 57.39%\n",
            " Eval loss , 0.571, eval acc, 82.76 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88       444\n",
            "           1       0.39      0.19      0.26       103\n",
            "\n",
            "    accuracy                           0.79       547\n",
            "   macro avg       0.61      0.56      0.57       547\n",
            "weighted avg       0.75      0.79      0.76       547\n",
            "\n",
            " Epoch Number 1\n",
            " Train. Loss: 0.427 Train. Acc: 62.00%\n",
            " Eval loss , 0.521, eval acc, 79.63 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.94      0.82       383\n",
            "           1       0.55      0.17      0.26       164\n",
            "\n",
            "    accuracy                           0.71       547\n",
            "   macro avg       0.64      0.56      0.54       547\n",
            "weighted avg       0.67      0.71      0.65       547\n",
            "\n",
            " Epoch Number 2\n",
            " Train. Loss: 0.353 Train. Acc: 68.11%\n",
            " Eval loss , 0.534, eval acc, 71.96 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       424\n",
            "           1       0.43      0.18      0.25       123\n",
            "\n",
            "    accuracy                           0.76       547\n",
            "   macro avg       0.61      0.56      0.56       547\n",
            "weighted avg       0.71      0.76      0.72       547\n",
            "\n",
            " Epoch Number 3\n",
            " Train. Loss: 0.331 Train. Acc: 69.19%\n",
            " Eval loss , 0.505, eval acc, 77.00 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       426\n",
            "           1       0.39      0.17      0.23       121\n",
            "\n",
            "    accuracy                           0.76       547\n",
            "   macro avg       0.59      0.55      0.54       547\n",
            "weighted avg       0.71      0.76      0.72       547\n",
            "\n",
            " Epoch Number 4\n",
            " Train. Loss: 0.304 Train. Acc: 71.08%\n",
            " Eval loss , 0.502, eval acc, 76.51 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.94      0.81       375\n",
            "           1       0.57      0.17      0.26       172\n",
            "\n",
            "    accuracy                           0.70       547\n",
            "   macro avg       0.64      0.55      0.54       547\n",
            "weighted avg       0.67      0.70      0.64       547\n",
            "\n",
            " Epoch Number 5\n",
            " Train. Loss: 0.324 Train. Acc: 67.98%\n",
            " Eval loss , 0.520, eval acc, 70.78 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       419\n",
            "           1       0.41      0.16      0.23       128\n",
            "\n",
            "    accuracy                           0.75       547\n",
            "   macro avg       0.60      0.55      0.54       547\n",
            "weighted avg       0.70      0.75      0.71       547\n",
            "\n",
            " Epoch Number 6\n",
            " Train. Loss: 0.320 Train. Acc: 69.38%\n",
            " Eval loss , 0.505, eval acc, 75.78 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       417\n",
            "           1       0.41      0.16      0.23       130\n",
            "\n",
            "    accuracy                           0.75       547\n",
            "   macro avg       0.60      0.54      0.54       547\n",
            "weighted avg       0.69      0.75      0.70       547\n",
            "\n",
            " Epoch Number 7\n",
            " Train. Loss: 0.319 Train. Acc: 69.08%\n",
            " Eval loss , 0.507, eval acc, 75.44 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       417\n",
            "           1       0.43      0.17      0.24       130\n",
            "\n",
            "    accuracy                           0.75       547\n",
            "   macro avg       0.61      0.55      0.55       547\n",
            "weighted avg       0.70      0.75      0.71       547\n",
            "\n",
            " Epoch Number 8\n",
            " Train. Loss: 0.300 Train. Acc: 70.80%\n",
            " Eval loss , 0.508, eval acc, 75.78 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.94      0.84       397\n",
            "           1       0.53      0.18      0.27       150\n",
            "\n",
            "    accuracy                           0.73       547\n",
            "   macro avg       0.64      0.56      0.55       547\n",
            "weighted avg       0.69      0.73      0.68       547\n",
            "\n",
            " Epoch Number 9\n",
            " Train. Loss: 0.302 Train. Acc: 70.76%\n",
            " Eval loss , 0.513, eval acc, 73.90 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqSIcZPr9qCY"
      },
      "source": [
        "# Torch Model 3 - Feedforward Regresssion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U02qHiN79wNe"
      },
      "source": [
        "#let's first try a simple FC NN\n",
        "class FFNN_regression (nn.Module):\n",
        "    def __init__(self, input_size,num_hidden, hidden_dim ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert num_hidden > 0 \n",
        "\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([])\n",
        "        self.hidden_layers.append (self.fc1)\n",
        "        for i in range (num_hidden -1 ):\n",
        "            self.hidden_layers.append(self.fc2)\n",
        "        \n",
        "        self.final_layer = nn.Linear (hidden_dim,1)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = hidden_layer(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.relu(x)\n",
        "        \n",
        "        out = self.final_layer(x)\n",
        "        \n",
        "        return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOkl8d-M-EtB"
      },
      "source": [
        "#try initiating the model\n",
        "INPUT_SIZE = 18\n",
        "NUM_HIDDEN = 4\n",
        "HIDDEN_DIM = 1024\n",
        "\n",
        "model = FFNN_regression(INPUT_SIZE, NUM_HIDDEN, HIDDEN_DIM)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE-ZITBl-EqZ"
      },
      "source": [
        "#define loss fuction and optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQhSlaHL-Eit"
      },
      "source": [
        "#now define the training and evaluation loop\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss= 0\n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data, label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data).squeeze(1)\n",
        "        loss = loss_fn(pred,label)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/len(dataloader)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1LTWnox_rJK"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0 \n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        data,label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data).squeeze(1)\n",
        "        loss = loss_fn(pred,label)\n",
        "\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGq3iPf3-lO1",
        "outputId": "55b6a105-3143-4c36-e4dc-7c85e1a66556"
      },
      "source": [
        "N_EPOCHS = 20 \n",
        "\n",
        "for i in range(N_EPOCHS):\n",
        "    train_loss = train(model,train_loader, optimizer, loss_fn)\n",
        "    eval_loss = evaluate(model,eval_loader, loss_fn)\n",
        "    \n",
        "    print (f' Epoch Number {i}') \n",
        "    print (f' Train. Loss: {train_loss:.5f} ')\n",
        "    print (f' Eval loss , {eval_loss:.5f} ')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch Number 0\n",
            " Train. Loss: 0.01819 \n",
            " Eval loss , 0.01586 \n",
            " Epoch Number 1\n",
            " Train. Loss: 0.01819 \n",
            " Eval loss , 0.01614 \n",
            " Epoch Number 2\n",
            " Train. Loss: 0.01786 \n",
            " Eval loss , 0.01623 \n",
            " Epoch Number 3\n",
            " Train. Loss: 0.01790 \n",
            " Eval loss , 0.01642 \n",
            " Epoch Number 4\n",
            " Train. Loss: 0.01800 \n",
            " Eval loss , 0.01593 \n",
            " Epoch Number 5\n",
            " Train. Loss: 0.01772 \n",
            " Eval loss , 0.01546 \n",
            " Epoch Number 6\n",
            " Train. Loss: 0.01777 \n",
            " Eval loss , 0.01570 \n",
            " Epoch Number 7\n",
            " Train. Loss: 0.01737 \n",
            " Eval loss , 0.01564 \n",
            " Epoch Number 8\n",
            " Train. Loss: 0.01764 \n",
            " Eval loss , 0.01640 \n",
            " Epoch Number 9\n",
            " Train. Loss: 0.01744 \n",
            " Eval loss , 0.01590 \n",
            " Epoch Number 10\n",
            " Train. Loss: 0.01722 \n",
            " Eval loss , 0.01566 \n",
            " Epoch Number 11\n",
            " Train. Loss: 0.01740 \n",
            " Eval loss , 0.01632 \n",
            " Epoch Number 12\n",
            " Train. Loss: 0.01794 \n",
            " Eval loss , 0.01632 \n",
            " Epoch Number 13\n",
            " Train. Loss: 0.01759 \n",
            " Eval loss , 0.01537 \n",
            " Epoch Number 14\n",
            " Train. Loss: 0.01768 \n",
            " Eval loss , 0.01596 \n",
            " Epoch Number 15\n",
            " Train. Loss: 0.01705 \n",
            " Eval loss , 0.01582 \n",
            " Epoch Number 16\n",
            " Train. Loss: 0.01724 \n",
            " Eval loss , 0.01615 \n",
            " Epoch Number 17\n",
            " Train. Loss: 0.01743 \n",
            " Eval loss , 0.01585 \n",
            " Epoch Number 18\n",
            " Train. Loss: 0.01743 \n",
            " Eval loss , 0.01560 \n",
            " Epoch Number 19\n",
            " Train. Loss: 0.01714 \n",
            " Eval loss , 0.01593 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyEdBEQh_ayw"
      },
      "source": [
        "The loss seems way too small??? am I calculating it correctly???\n",
        "I'm going to use L1loss instead of L2 loss and see how it goes. \n",
        "It seems that the class imbalance is too dominant, I'll have to work around it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVf57rdX_GQh",
        "outputId": "3241d689-b33d-4b95-c43c-af6153234831"
      },
      "source": [
        "for i,batch in enumerate(train_loader):\n",
        "    data,label = (t for t in batch)\n",
        "    print (i)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GboHeo62BWBW",
        "outputId": "df0a8af7-4279-4a38-db5f-9a85f08658b7"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.9815e-04,  7.7955e-02, -4.8741e-04,  ...,  7.8442e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 1.8731e-03,  4.4611e-02, -2.0406e-03,  ...,  4.6651e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 4.7553e-04,  6.1652e-03, -3.5175e-02,  ...,  4.1340e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        ...,\n",
              "        [-2.4258e-04,  3.4845e-02, -2.3194e-02,  ...,  5.8039e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [-6.1106e-04,  9.8598e-04, -8.4670e-02,  ...,  8.5656e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 7.6427e-03,  1.4638e-02, -3.6971e-02,  ...,  5.1609e-02,\n",
              "          0.0000e+00,  1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v5viZ5fBxE5",
        "outputId": "4a23d3c0-223a-4650-e376-a19c80c97d28"
      },
      "source": [
        "label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0446,  0.0062,  0.0658,  0.0292,  0.2194,  0.0073,  0.0116,  0.0205,\n",
              "         0.0400,  0.0313,  0.0649,  0.0670,  0.0324,  0.0123,  0.0553,  0.0617,\n",
              "         0.0361,  0.0074,  0.0025,  0.0077,  0.0162,  0.0138,  0.0834,  0.1036,\n",
              "         0.0322,  0.0200,  0.0510,  0.0026,  0.0269,  0.0284,  0.0473,  0.0076,\n",
              "         0.0175,  0.0042,  0.0025,  0.0010,  0.0856,  0.0034,  0.0291,  0.0619,\n",
              "         0.0367,  0.0090,  0.0314,  0.0052,  0.0188,  0.0058,  0.0669,  0.0360,\n",
              "         0.0193,  0.0024,  0.0005,  0.0035,  0.0165,  0.0270,  0.0061, -0.0006,\n",
              "         0.0310,  0.0150,  0.0017,  0.0374,  0.0348,  0.0010,  0.0146,  0.0331])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3swifsyBysK",
        "outputId": "e3be6c4d-f594-4733-aad6-04a049b6ab0c"
      },
      "source": [
        "model(data.to(device)).squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0306, 0.0253, 0.0240, 0.0256, 0.0248, 0.0387, 0.0230, 0.0273, 0.0294,\n",
              "        0.0302, 0.0312, 0.0329, 0.0207, 0.0208, 0.0152, 0.0203, 0.0126, 0.0092,\n",
              "        0.0113, 0.0096, 0.0081, 0.0083, 0.0082, 0.0177, 0.0202, 0.0215, 0.0082,\n",
              "        0.0101, 0.0153, 0.0084, 0.0109, 0.0119, 0.0129, 0.0082, 0.0082, 0.0078,\n",
              "        0.0074, 0.0177, 0.0110, 0.0160, 0.0200, 0.0211, 0.0205, 0.0203, 0.0196,\n",
              "        0.0192, 0.0197, 0.0226, 0.0210, 0.0200, 0.0206, 0.0205, 0.0193, 0.0161,\n",
              "        0.0170, 0.0176, 0.0211, 0.0222, 0.0179, 0.0064, 0.0064, 0.0088, 0.0134,\n",
              "        0.0227], device='cuda:0', grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp13tzHLB1mx",
        "outputId": "a27cd2bf-3d43-4de8-d2d3-a36645bc10a9"
      },
      "source": [
        "loss_fn(model(data.to(device)).squeeze(),label.to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0214, device='cuda:0', grad_fn=<L1LossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_e3F0DCGp2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-oMKnKN-L9"
      },
      "source": [
        "#Torch Model 4 - LSTM Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5LDTZiSN9jL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhvmCMcpOi48"
      },
      "source": [
        "The previous 3 models used the almost the same dataloader because the similar input format, for LSTM I will need to make some adjustments. And perhaps try out 2 scenarios with and w/o the weighted sampler. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EPDbh22O5Xn"
      },
      "source": [
        "class LSTMModel(nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes,  num_hidden, hidden_dim):\r\n",
        "        super().__init__()\r\n",
        "        #num_layers = num_layers\r\n",
        "        # self.input_size = input_size\r\n",
        "        # self.hidden_size = hidden_size\r\n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, num_hidden, batch_first=True, bidirectional=False, dropout=0.5)\r\n",
        "        self.ff = nn.Linear(hidden_dim, num_classes)\r\n",
        "        self.dropout = nn.Dropout()\r\n",
        "\r\n",
        "        #need to change the loss function. \r\n",
        "    def forward(self, input):\r\n",
        "        output, (hn, cn) = self.lstm(input)\r\n",
        "        hn = self.dropout(hn[-1,:,:])\r\n",
        "        return self.ff(hn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y0n47b1Qj2I"
      },
      "source": [
        "INPUT_SIZE = 19\r\n",
        "NUM_CLASSES = 2\r\n",
        "NUM_HIDDEN = 2\r\n",
        "HIDDEN_DIM = 512\r\n",
        "\r\n",
        "model = LSTMModel(INPUT_SIZE, NUM_CLASSES, NUM_HIDDEN, HIDDEN_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfj9ru919ubE"
      },
      "source": [
        "class FocalLoss(nn.Module):\r\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\r\n",
        "        super(FocalLoss, self).__init__()\r\n",
        "        self.gamma = gamma\r\n",
        "        self.alpha = alpha\r\n",
        "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\r\n",
        "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\r\n",
        "        self.size_average = size_average\r\n",
        "\r\n",
        "    def forward(self, input, target):\r\n",
        "        if input.dim()>2:\r\n",
        "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\r\n",
        "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\r\n",
        "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\r\n",
        "        target = target.view(-1,1)\r\n",
        "\r\n",
        "        logpt = F.log_softmax(input)\r\n",
        "        logpt = logpt.gather(1,target)\r\n",
        "        logpt = logpt.view(-1)\r\n",
        "        pt = Variable(logpt.data.exp())\r\n",
        "\r\n",
        "        if self.alpha is not None:\r\n",
        "            if self.alpha.type()!=input.data.type():\r\n",
        "                self.alpha = self.alpha.type_as(input.data)\r\n",
        "            at = self.alpha.gather(0,target.data.view(-1))\r\n",
        "            logpt = logpt * Variable(at)\r\n",
        "\r\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\r\n",
        "        if self.size_average: return loss.mean()\r\n",
        "        else: return loss.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93C2J3V1Ud8c",
        "outputId": "c2f0ffbb-957f-45ca-b575-562194e9af31"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (lstm): LSTM(19, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (ff): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFfo_4kuUpcS",
        "outputId": "77e75f41-397a-45b4-8e7c-b4a20aca6611"
      },
      "source": [
        "#print model parameters\r\n",
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,193,858 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0hdVHycWRIi"
      },
      "source": [
        "#define loss fuction and optimizer\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "#loss_fn = nn.NLLLoss()\r\n",
        "loss_fn= FocalLoss(gamma=0,alpha=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCJxYz-WX_z"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = model.to(device)\r\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T6Pr2z9UvD5"
      },
      "source": [
        "def accuracy(preds, y):\r\n",
        "    \"\"\"\r\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #round predictions to the closest integer\r\n",
        "    prediciton = F.softmax(preds, dim =1)\r\n",
        "    _, pred = torch.max(prediciton, 1)\r\n",
        "    correct = (pred == y).float() #convert into float for division \r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8mJpUVIWdSI"
      },
      "source": [
        "#can i define a function to calculate the f1 score/confusion matrix? \r\n",
        "def get_cfm (preds, label):\r\n",
        "    pred = F.softmax(preds, dim =1)\r\n",
        "    _,pred_label = torch.max(pred,dim=1)\r\n",
        "    m = classification_report(pred_label.cpu(), label.cpu())\r\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJK5wkYWhN8"
      },
      "source": [
        "#now define the training and evaluation loop\r\n",
        "def train(model, dataloader, optimizer, loss_fn):\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    epoch_loss= 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        data, label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        acc  = accuracy(pred,label)\r\n",
        "\r\n",
        "        #append the prediction result and show it per epoch later. \r\n",
        "        if step ==0:     \r\n",
        "            pred_list=pred.cpu().detach().numpy()\r\n",
        "            label_list = label.cpu().detach().numpy()\r\n",
        "        if step != 0:\r\n",
        "            pred_list = np.concatenate([pred_list,pred.cpu().detach().numpy()],axis =0)\r\n",
        "            label_list = np.concatenate([label_list,label.cpu().detach().numpy()],axis =0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc\r\n",
        "    report = get_cfm(torch.tensor(pred_list),torch.tensor(label_list))\r\n",
        "    print (report)\r\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls3DvxraWkgw"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    epoch_loss = 0 \r\n",
        "    epoch_acc = 0 \r\n",
        "\r\n",
        "    pred_list =[]\r\n",
        "    label_list =[]\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        data,label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        acc = accuracy(pred,label)\r\n",
        "        \r\n",
        "        #append the prediction result and show it per epoch later. \r\n",
        "        if step ==0:     \r\n",
        "            pred_list=pred.cpu().detach().numpy()\r\n",
        "            label_list = label.cpu().detach().numpy()\r\n",
        "        if step != 0:\r\n",
        "            pred_list = np.concatenate([pred_list,pred.cpu().detach().numpy()],axis =0)\r\n",
        "            label_list = np.concatenate([label_list,label.cpu().detach().numpy()],axis =0)\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc\r\n",
        "\r\n",
        "    report = get_cfm(torch.tensor(pred_list),torch.tensor(label_list))\r\n",
        "    print (report)\r\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6fc8cJzWnjN",
        "outputId": "dd81e8c0-dcaf-407d-e424-77c3128c3da1"
      },
      "source": [
        "N_EPOCHS = 15\r\n",
        "\r\n",
        "for i in range(N_EPOCHS):\r\n",
        "    train_loss,train_acc = train(model,train_loader, optimizer, loss_fn)\r\n",
        "    \r\n",
        "    eval_loss, eval_acc = evaluate(model,eval_loader, loss_fn)\r\n",
        "    \r\n",
        "    print (f' Epoch Number {i}') \r\n",
        "    print (f' Train. Loss: {train_loss:.3f} Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    print (f' Eval loss , {eval_loss:.3f}, eval acc, {eval_acc*100:.2f} %')\r\n",
        "    # print(f'\\t Train. Loss: {train_loss:.3f} |  Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92      1219\n",
            "           1       0.03      0.14      0.04        29\n",
            "\n",
            "    accuracy                           0.85      1248\n",
            "   macro avg       0.50      0.50      0.48      1248\n",
            "weighted avg       0.95      0.85      0.90      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95       537\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.91       537\n",
            "   macro avg       0.50      0.45      0.48       537\n",
            "weighted avg       1.00      0.91      0.95       537\n",
            "\n",
            " Epoch Number 0\n",
            " Train. Loss: 0.191 Train. Acc: 85.70%\n",
            " Eval loss , 0.170, eval acc, 90.88 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.87      0.93      1248\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87      1248\n",
            "   macro avg       0.50      0.44      0.47      1248\n",
            "weighted avg       1.00      0.87      0.93      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95       537\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.91       537\n",
            "   macro avg       0.50      0.45      0.48       537\n",
            "weighted avg       1.00      0.91      0.95       537\n",
            "\n",
            " Epoch Number 1\n",
            " Train. Loss: 0.188 Train. Acc: 87.34%\n",
            " Eval loss , 0.168, eval acc, 90.88 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.87      0.93      1248\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87      1248\n",
            "   macro avg       0.50      0.44      0.47      1248\n",
            "weighted avg       1.00      0.87      0.93      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95       537\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.91       537\n",
            "   macro avg       0.50      0.45      0.48       537\n",
            "weighted avg       1.00      0.91      0.95       537\n",
            "\n",
            " Epoch Number 2\n",
            " Train. Loss: 0.189 Train. Acc: 87.34%\n",
            " Eval loss , 0.165, eval acc, 90.88 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.87      0.93      1248\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87      1248\n",
            "   macro avg       0.50      0.44      0.47      1248\n",
            "weighted avg       1.00      0.87      0.93      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95       537\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.91       537\n",
            "   macro avg       0.50      0.45      0.48       537\n",
            "weighted avg       1.00      0.91      0.95       537\n",
            "\n",
            " Epoch Number 3\n",
            " Train. Loss: 0.185 Train. Acc: 87.34%\n",
            " Eval loss , 0.164, eval acc, 90.88 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.88      0.93      1222\n",
            "           1       0.05      0.31      0.09        26\n",
            "\n",
            "    accuracy                           0.86      1248\n",
            "   macro avg       0.52      0.59      0.51      1248\n",
            "weighted avg       0.96      0.86      0.91      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91       480\n",
            "           1       0.20      0.18      0.19        57\n",
            "\n",
            "    accuracy                           0.84       537\n",
            "   macro avg       0.55      0.55      0.55       537\n",
            "weighted avg       0.83      0.84      0.83       537\n",
            "\n",
            " Epoch Number 4\n",
            " Train. Loss: 0.184 Train. Acc: 86.56%\n",
            " Eval loss , 0.165, eval acc, 84.45 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.88      0.91      1166\n",
            "           1       0.12      0.23      0.16        82\n",
            "\n",
            "    accuracy                           0.84      1248\n",
            "   macro avg       0.53      0.56      0.53      1248\n",
            "weighted avg       0.89      0.84      0.86      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93       499\n",
            "           1       0.16      0.21      0.18        38\n",
            "\n",
            "    accuracy                           0.86       537\n",
            "   macro avg       0.55      0.56      0.55       537\n",
            "weighted avg       0.88      0.86      0.87       537\n",
            "\n",
            " Epoch Number 5\n",
            " Train. Loss: 0.181 Train. Acc: 83.91%\n",
            " Eval loss , 0.155, eval acc, 87.06 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      1058\n",
            "           1       0.31      0.26      0.29       190\n",
            "\n",
            "    accuracy                           0.80      1248\n",
            "   macro avg       0.59      0.58      0.58      1248\n",
            "weighted avg       0.79      0.80      0.79      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       465\n",
            "           1       0.25      0.18      0.21        72\n",
            "\n",
            "    accuracy                           0.82       537\n",
            "   macro avg       0.57      0.55      0.55       537\n",
            "weighted avg       0.79      0.82      0.81       537\n",
            "\n",
            " Epoch Number 6\n",
            " Train. Loss: 0.168 Train. Acc: 80.31%\n",
            " Eval loss , 0.163, eval acc, 82.89 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89      1080\n",
            "           1       0.29      0.27      0.28       168\n",
            "\n",
            "    accuracy                           0.81      1248\n",
            "   macro avg       0.59      0.58      0.59      1248\n",
            "weighted avg       0.81      0.81      0.81      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       474\n",
            "           1       0.20      0.16      0.18        63\n",
            "\n",
            "    accuracy                           0.82       537\n",
            "   macro avg       0.54      0.54      0.54       537\n",
            "weighted avg       0.81      0.82      0.82       537\n",
            "\n",
            " Epoch Number 7\n",
            " Train. Loss: 0.177 Train. Acc: 81.41%\n",
            " Eval loss , 0.157, eval acc, 83.41 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      1052\n",
            "           1       0.31      0.26      0.28       196\n",
            "\n",
            "    accuracy                           0.79      1248\n",
            "   macro avg       0.59      0.58      0.58      1248\n",
            "weighted avg       0.78      0.79      0.79      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87       439\n",
            "           1       0.29      0.15      0.20        98\n",
            "\n",
            "    accuracy                           0.78       537\n",
            "   macro avg       0.56      0.54      0.54       537\n",
            "weighted avg       0.73      0.78      0.75       537\n",
            "\n",
            " Epoch Number 8\n",
            " Train. Loss: 0.172 Train. Acc: 79.84%\n",
            " Eval loss , 0.160, eval acc, 79.07 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88      1063\n",
            "           1       0.28      0.24      0.26       185\n",
            "\n",
            "    accuracy                           0.80      1248\n",
            "   macro avg       0.58      0.57      0.57      1248\n",
            "weighted avg       0.78      0.80      0.79      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       442\n",
            "           1       0.25      0.14      0.18        95\n",
            "\n",
            "    accuracy                           0.78       537\n",
            "   macro avg       0.54      0.53      0.52       537\n",
            "weighted avg       0.73      0.78      0.75       537\n",
            "\n",
            " Epoch Number 9\n",
            " Train. Loss: 0.173 Train. Acc: 79.92%\n",
            " Eval loss , 0.158, eval acc, 78.90 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88      1052\n",
            "           1       0.31      0.25      0.28       196\n",
            "\n",
            "    accuracy                           0.79      1248\n",
            "   macro avg       0.59      0.57      0.58      1248\n",
            "weighted avg       0.78      0.79      0.78      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       457\n",
            "           1       0.25      0.16      0.20        80\n",
            "\n",
            "    accuracy                           0.80       537\n",
            "   macro avg       0.56      0.54      0.54       537\n",
            "weighted avg       0.77      0.80      0.79       537\n",
            "\n",
            " Epoch Number 10\n",
            " Train. Loss: 0.166 Train. Acc: 79.69%\n",
            " Eval loss , 0.155, eval acc, 81.50 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       870\n",
            "           1       0.64      0.27      0.38       378\n",
            "\n",
            "    accuracy                           0.73      1248\n",
            "   macro avg       0.70      0.60      0.61      1248\n",
            "weighted avg       0.72      0.73      0.69      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       467\n",
            "           1       0.24      0.17      0.20        70\n",
            "\n",
            "    accuracy                           0.82       537\n",
            "   macro avg       0.56      0.54      0.55       537\n",
            "weighted avg       0.80      0.82      0.81       537\n",
            "\n",
            " Epoch Number 11\n",
            " Train. Loss: 0.166 Train. Acc: 73.91%\n",
            " Eval loss , 0.164, eval acc, 82.89 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87      1002\n",
            "           1       0.44      0.28      0.34       246\n",
            "\n",
            "    accuracy                           0.79      1248\n",
            "   macro avg       0.64      0.60      0.61      1248\n",
            "weighted avg       0.76      0.79      0.77      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       447\n",
            "           1       0.24      0.13      0.17        90\n",
            "\n",
            "    accuracy                           0.78       537\n",
            "   macro avg       0.54      0.52      0.52       537\n",
            "weighted avg       0.74      0.78      0.76       537\n",
            "\n",
            " Epoch Number 12\n",
            " Train. Loss: 0.163 Train. Acc: 79.06%\n",
            " Eval loss , 0.165, eval acc, 79.42 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       967\n",
            "           1       0.49      0.28      0.36       281\n",
            "\n",
            "    accuracy                           0.77      1248\n",
            "   macro avg       0.65      0.60      0.61      1248\n",
            "weighted avg       0.74      0.77      0.75      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       454\n",
            "           1       0.25      0.16      0.19        83\n",
            "\n",
            "    accuracy                           0.80       537\n",
            "   macro avg       0.56      0.54      0.54       537\n",
            "weighted avg       0.76      0.80      0.78       537\n",
            "\n",
            " Epoch Number 13\n",
            " Train. Loss: 0.160 Train. Acc: 77.73%\n",
            " Eval loss , 0.161, eval acc, 80.98 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85       929\n",
            "           1       0.54      0.27      0.36       319\n",
            "\n",
            "    accuracy                           0.76      1248\n",
            "   macro avg       0.67      0.60      0.61      1248\n",
            "weighted avg       0.72      0.76      0.72      1248\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89       463\n",
            "           1       0.24      0.16      0.19        74\n",
            "\n",
            "    accuracy                           0.81       537\n",
            "   macro avg       0.55      0.54      0.54       537\n",
            "weighted avg       0.78      0.81      0.80       537\n",
            "\n",
            " Epoch Number 14\n",
            " Train. Loss: 0.159 Train. Acc: 76.02%\n",
            " Eval loss , 0.163, eval acc, 82.19 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1rtD7Guh-g5"
      },
      "source": [
        "why is the loss negative here, did I mess up with the NLLloss? I passed the softmax into the NLLloss correctly ya? \r\n",
        "Ah, because i used softmax, it should be log_softmax instead. \r\n",
        "\r\n",
        " what about the actual result here. maybe try a few more epochs? \r\n",
        "\r\n",
        " The results is not exactly stable ?\r\n",
        " It's actually a common theme, throughout all the 4 models though .\r\n",
        "\r\n",
        " Hard to say, the recall of true label is not very good in evaluation set, although the accuracy is going up. The recall rate in trainning set seems decent though. ummm. \r\n",
        "\r\n",
        " What if I want to focus on the recall rate, maybe the focal loss could come into play here ???? maybe it can address the class imbalance better than over/undersampling? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEFnPR3BiFYw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pN-Is6Lv5OE"
      },
      "source": [
        "# Torch Model 5 - Feedforward with Focal Loss\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emj_r3CNwBzL"
      },
      "source": [
        "Now that I understand a little bit more about Cross-entropy and the concept of focal loss, let me try it out on the most basic network and see if it works. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJhkY-kkwAlO"
      },
      "source": [
        "#first, define focal loss?\r\n",
        "#there are a few variations...let's try "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZxNAbE63TNq"
      },
      "source": [
        "class FocalLoss(nn.Module):\r\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\r\n",
        "        super(FocalLoss, self).__init__()\r\n",
        "        self.gamma = gamma\r\n",
        "        self.alpha = alpha\r\n",
        "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\r\n",
        "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\r\n",
        "        self.size_average = size_average\r\n",
        "\r\n",
        "    def forward(self, input, target):\r\n",
        "        if input.dim()>2:\r\n",
        "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\r\n",
        "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\r\n",
        "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\r\n",
        "        target = target.view(-1,1)\r\n",
        "\r\n",
        "        logpt = F.log_softmax(input)\r\n",
        "        logpt = logpt.gather(1,target)\r\n",
        "        logpt = logpt.view(-1)\r\n",
        "        pt = Variable(logpt.data.exp())\r\n",
        "\r\n",
        "        if self.alpha is not None:\r\n",
        "            if self.alpha.type()!=input.data.type():\r\n",
        "                self.alpha = self.alpha.type_as(input.data)\r\n",
        "            at = self.alpha.gather(0,target.data.view(-1))\r\n",
        "            logpt = logpt * Variable(at)\r\n",
        "\r\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\r\n",
        "        if self.size_average: return loss.mean()\r\n",
        "        else: return loss.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUyoMJCYpPEL"
      },
      "source": [
        "loss_fn = FocalLoss(gamma=0, alpha=0.2)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVSyzRMwpZo2"
      },
      "source": [
        "#let's first try a simple FC NN\r\n",
        "class FFNN (nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes,num_hidden, hidden_dim ):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        assert num_hidden > 0 \r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\r\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\r\n",
        "\r\n",
        "        self.hidden_layers = nn.ModuleList([])\r\n",
        "        self.hidden_layers.append (self.fc1)\r\n",
        "        for i in range (num_hidden -1 ):\r\n",
        "            self.hidden_layers.append(self.fc2)\r\n",
        "        \r\n",
        "        self.final_layer = nn.Linear (hidden_dim,num_classes)\r\n",
        "        self.dropout = nn.Dropout()\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self,x):\r\n",
        "        for hidden_layer in self.hidden_layers:\r\n",
        "            x = hidden_layer(x)\r\n",
        "            x = self.dropout(x)\r\n",
        "            x = self.relu(x)\r\n",
        "        \r\n",
        "        out = self.final_layer(x)\r\n",
        "\r\n",
        "        return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEfWUpxVp9fD"
      },
      "source": [
        "#try initiating the model\r\n",
        "INPUT_SIZE = 19\r\n",
        "NUM_CLASSES = 2\r\n",
        "NUM_HIDDEN = 2\r\n",
        "HIDDEN_DIM = 512\r\n",
        "\r\n",
        "model = FFNN(INPUT_SIZE, NUM_CLASSES, NUM_HIDDEN, HIDDEN_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAkvOEmWqBWz"
      },
      "source": [
        "#define loss fuction and optimizer\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3nNaR4eqHJ_"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model = model.to(device)\r\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqbOEELoqJp-"
      },
      "source": [
        "#define a function to calcualte prediction accuracy\r\n",
        "def accuracy(pred,label):\r\n",
        "    _,pred_label = torch.max(pred,dim=1)\r\n",
        "    correct = (pred_label==label).float()\r\n",
        "    accuracy = correct.sum()/len(correct)\r\n",
        "    return accuracy\r\n",
        "\r\n",
        "#can i define a function to calculate the f1 score/confusion matrix? \r\n",
        "def get_cfm (pred, label):\r\n",
        "    _,pred_label = torch.max(pred,dim=1)\r\n",
        "    m = classification_report(pred_label.cpu(), label.cpu())\r\n",
        "    return m\r\n",
        "\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q50awQL1qSm-"
      },
      "source": [
        "#now define the training and evaluation loop\r\n",
        "def train(model, dataloader, optimizer, loss_fn):\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    epoch_loss= 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        data, label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        acc  = accuracy(pred,label)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc\r\n",
        "\r\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-LO9tVqVa0"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    epoch_loss = 0 \r\n",
        "    epoch_acc = 0 \r\n",
        "\r\n",
        "    pred_list =[]\r\n",
        "    label_list =[]\r\n",
        "    for step,batch in enumerate(dataloader):\r\n",
        "        data,label = (t for t in batch)\r\n",
        "        data = data.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        pred = model(data)\r\n",
        "        loss = loss_fn(pred,label)\r\n",
        "        acc = accuracy(pred,label)\r\n",
        "        \r\n",
        "        #append the prediction result and show it per epoch later. \r\n",
        "        if step ==0:     \r\n",
        "            pred_list=pred.cpu().detach().numpy()\r\n",
        "            label_list = label.cpu().detach().numpy()\r\n",
        "        if step != 0:\r\n",
        "            pred_list = np.concatenate([pred_list,pred.cpu().detach().numpy()],axis =0)\r\n",
        "            label_list = np.concatenate([label_list,label.cpu().detach().numpy()],axis =0)\r\n",
        "\r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc\r\n",
        "\r\n",
        "    report = get_cfm(torch.tensor(pred_list),torch.tensor(label_list))\r\n",
        "    print (report)\r\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWlqJYPHqXrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4baefe90-55b0-424e-a113-6a0ee50b729c"
      },
      "source": [
        "N_EPOCHS = 20\r\n",
        "\r\n",
        "for i in range(N_EPOCHS):\r\n",
        "    train_loss,train_acc = train(model,train_loader, optimizer, loss_fn)\r\n",
        "    \r\n",
        "    eval_loss, eval_acc = evaluate(model,eval_loader, loss_fn)\r\n",
        "    \r\n",
        "    print (f' Epoch Number {i}') \r\n",
        "    print (f' Train. Loss: {train_loss:.3f} Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    print (f' Eval loss , {eval_loss:.3f}, eval acc, {eval_acc*100:.2f} %')\r\n",
        "    # print(f'\\t Train. Loss: {train_loss:.3f} |  Train. Acc: {train_acc*100:.2f}%')\r\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95       547\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.91       547\n",
            "   macro avg       0.50      0.45      0.48       547\n",
            "weighted avg       1.00      0.91      0.95       547\n",
            "\n",
            " Epoch Number 0\n",
            " Train. Loss: 0.210 Train. Acc: 83.39%\n",
            " Eval loss , 0.156, eval acc, 90.71 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       498\n",
            "           1       0.18      0.18      0.18        49\n",
            "\n",
            "    accuracy                           0.85       547\n",
            "   macro avg       0.55      0.55      0.55       547\n",
            "weighted avg       0.85      0.85      0.85       547\n",
            "\n",
            " Epoch Number 1\n",
            " Train. Loss: 0.183 Train. Acc: 82.53%\n",
            " Eval loss , 0.164, eval acc, 85.19 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.92       502\n",
            "           1       0.14      0.16      0.15        45\n",
            "\n",
            "    accuracy                           0.85       547\n",
            "   macro avg       0.53      0.53      0.53       547\n",
            "weighted avg       0.86      0.85      0.85       547\n",
            "\n",
            " Epoch Number 2\n",
            " Train. Loss: 0.181 Train. Acc: 84.68%\n",
            " Eval loss , 0.154, eval acc, 85.19 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       498\n",
            "           1       0.18      0.18      0.18        49\n",
            "\n",
            "    accuracy                           0.85       547\n",
            "   macro avg       0.55      0.55      0.55       547\n",
            "weighted avg       0.85      0.85      0.85       547\n",
            "\n",
            " Epoch Number 3\n",
            " Train. Loss: 0.174 Train. Acc: 83.93%\n",
            " Eval loss , 0.151, eval acc, 85.19 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       495\n",
            "           1       0.20      0.19      0.19        52\n",
            "\n",
            "    accuracy                           0.85       547\n",
            "   macro avg       0.56      0.55      0.56       547\n",
            "weighted avg       0.85      0.85      0.85       547\n",
            "\n",
            " Epoch Number 4\n",
            " Train. Loss: 0.170 Train. Acc: 83.03%\n",
            " Eval loss , 0.148, eval acc, 85.01 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.91       482\n",
            "           1       0.24      0.18      0.21        65\n",
            "\n",
            "    accuracy                           0.83       547\n",
            "   macro avg       0.56      0.55      0.56       547\n",
            "weighted avg       0.81      0.83      0.82       547\n",
            "\n",
            " Epoch Number 5\n",
            " Train. Loss: 0.165 Train. Acc: 82.21%\n",
            " Eval loss , 0.147, eval acc, 83.45 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90       474\n",
            "           1       0.29      0.21      0.24        73\n",
            "\n",
            "    accuracy                           0.83       547\n",
            "   macro avg       0.59      0.56      0.57       547\n",
            "weighted avg       0.80      0.83      0.81       547\n",
            "\n",
            " Epoch Number 6\n",
            " Train. Loss: 0.165 Train. Acc: 81.86%\n",
            " Eval loss , 0.146, eval acc, 83.11 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90       471\n",
            "           1       0.31      0.21      0.25        76\n",
            "\n",
            "    accuracy                           0.83       547\n",
            "   macro avg       0.60      0.57      0.58       547\n",
            "weighted avg       0.80      0.83      0.81       547\n",
            "\n",
            " Epoch Number 7\n",
            " Train. Loss: 0.158 Train. Acc: 79.72%\n",
            " Eval loss , 0.146, eval acc, 82.93 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.90       466\n",
            "           1       0.31      0.20      0.24        81\n",
            "\n",
            "    accuracy                           0.82       547\n",
            "   macro avg       0.59      0.56      0.57       547\n",
            "weighted avg       0.79      0.82      0.80       547\n",
            "\n",
            " Epoch Number 8\n",
            " Train. Loss: 0.158 Train. Acc: 80.65%\n",
            " Eval loss , 0.146, eval acc, 82.06 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       461\n",
            "           1       0.33      0.20      0.25        86\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.60      0.56      0.57       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 9\n",
            " Train. Loss: 0.156 Train. Acc: 80.97%\n",
            " Eval loss , 0.146, eval acc, 81.69 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       461\n",
            "           1       0.33      0.20      0.25        86\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.60      0.56      0.57       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 10\n",
            " Train. Loss: 0.153 Train. Acc: 78.59%\n",
            " Eval loss , 0.147, eval acc, 81.69 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89       462\n",
            "           1       0.31      0.19      0.24        85\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.59      0.56      0.56       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 11\n",
            " Train. Loss: 0.149 Train. Acc: 79.84%\n",
            " Eval loss , 0.147, eval acc, 81.51 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       459\n",
            "           1       0.35      0.20      0.26        88\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.61      0.57      0.58       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 12\n",
            " Train. Loss: 0.154 Train. Acc: 77.65%\n",
            " Eval loss , 0.146, eval acc, 81.69 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       457\n",
            "           1       0.33      0.19      0.24        90\n",
            "\n",
            "    accuracy                           0.80       547\n",
            "   macro avg       0.59      0.56      0.56       547\n",
            "weighted avg       0.77      0.80      0.78       547\n",
            "\n",
            " Epoch Number 13\n",
            " Train. Loss: 0.149 Train. Acc: 79.09%\n",
            " Eval loss , 0.147, eval acc, 80.99 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       459\n",
            "           1       0.33      0.19      0.24        88\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.60      0.56      0.57       547\n",
            "weighted avg       0.77      0.81      0.79       547\n",
            "\n",
            " Epoch Number 14\n",
            " Train. Loss: 0.152 Train. Acc: 79.01%\n",
            " Eval loss , 0.147, eval acc, 81.34 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       462\n",
            "           1       0.33      0.20      0.25        85\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.60      0.56      0.57       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 15\n",
            " Train. Loss: 0.153 Train. Acc: 78.12%\n",
            " Eval loss , 0.146, eval acc, 81.86 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       458\n",
            "           1       0.33      0.19      0.24        89\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.59      0.56      0.57       547\n",
            "weighted avg       0.77      0.81      0.78       547\n",
            "\n",
            " Epoch Number 16\n",
            " Train. Loss: 0.154 Train. Acc: 78.47%\n",
            " Eval loss , 0.147, eval acc, 81.17 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       460\n",
            "           1       0.33      0.20      0.25        87\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.60      0.56      0.57       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 17\n",
            " Train. Loss: 0.152 Train. Acc: 77.18%\n",
            " Eval loss , 0.147, eval acc, 81.51 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       458\n",
            "           1       0.33      0.19      0.24        89\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.59      0.56      0.57       547\n",
            "weighted avg       0.77      0.81      0.78       547\n",
            "\n",
            " Epoch Number 18\n",
            " Train. Loss: 0.152 Train. Acc: 78.55%\n",
            " Eval loss , 0.147, eval acc, 81.17 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.89       460\n",
            "           1       0.33      0.20      0.25        87\n",
            "\n",
            "    accuracy                           0.81       547\n",
            "   macro avg       0.60      0.56      0.57       547\n",
            "weighted avg       0.78      0.81      0.79       547\n",
            "\n",
            " Epoch Number 19\n",
            " Train. Loss: 0.152 Train. Acc: 78.24%\n",
            " Eval loss , 0.147, eval acc, 81.51 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZJe2EJ_tOT8",
        "outputId": "1b48a27f-00c4-4693-86ad-fcfbf1f7e3d1"
      },
      "source": [
        "a = torch.range(1,6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmoM5BBvtU0q",
        "outputId": "20d6cb67-e5eb-4e60-8d63-4a8494d536b2"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxRsRxnZtQmL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCU6zdnstXVH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omgHNeY9n3dn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exKTVUAan4EP"
      },
      "source": [
        "# Torch Model 6 -  SVM and PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "AJHt2zjrn8Tg",
        "outputId": "52f5e144-8e8f-465e-f82a-629a97ae286d"
      },
      "source": [
        "test_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "      <th>ema</th>\n",
              "      <th>spread</th>\n",
              "      <th>eth</th>\n",
              "      <th>gold</th>\n",
              "      <th>change</th>\n",
              "      <th>change_label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-01</th>\n",
              "      <td>320.434998</td>\n",
              "      <td>320.434998</td>\n",
              "      <td>314.002991</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>8036550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>6.432007</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02</th>\n",
              "      <td>314.079010</td>\n",
              "      <td>315.838989</td>\n",
              "      <td>313.565002</td>\n",
              "      <td>315.032013</td>\n",
              "      <td>315.032013</td>\n",
              "      <td>7860650</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.655561</td>\n",
              "      <td>314.673129</td>\n",
              "      <td>0.017568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.836258</td>\n",
              "      <td>2.273987</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-03</th>\n",
              "      <td>314.846008</td>\n",
              "      <td>315.149994</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>33054400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>302.592907</td>\n",
              "      <td>301.562504</td>\n",
              "      <td>-1.030403</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.467926</td>\n",
              "      <td>34.067993</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...    change  change_label\n",
              "Date                                ...                        \n",
              "2015-01-01  320.434998  320.434998  ...  0.005060             0\n",
              "2015-01-02  314.079010  315.838989  ...  0.000375             0\n",
              "2015-01-03  314.846008  315.149994  ...  0.021873             0\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32Nf1XEzgY_",
        "outputId": "51bb7a0a-63da-464f-ae84-74cb3fd68900"
      },
      "source": [
        "print (\"Shape of DataFrame: \", test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (1826, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "DlzKs0YXzoox",
        "outputId": "f0dd8f66-57bf-4756-878c-c700f525b44f"
      },
      "source": [
        "corr = test_df.corr()\r\n",
        "#fig = plt.figure()\r\n",
        "#plt.subplot(1, 2, 1)\r\n",
        "fig=plt.figure(figsize=(13,11))\r\n",
        "g1 = sns.heatmap(corr, cmap='coolwarm', vmin=0, vmax=1)\r\n",
        "g1.set_xticklabels(g1.get_xticklabels(), rotation=70, fontsize=8)\r\n",
        "g1.set_yticklabels(g1.get_yticklabels(), rotation=15, fontsize=8)\r\n",
        "plt.title(\"Correlation Plot of the Features\")\r\n",
        "plt.savefig(\"Corr_Features.png\", dpi=200)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x792 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "yRobp6Mxz7DB",
        "outputId": "4a164967-38bc-4b3d-bcec-3ffff04aebea"
      },
      "source": [
        "sns.set(font_scale=1.2)\r\n",
        "j=sns.jointplot(test_df['Adj Close'], test_df['eth']\r\n",
        ", kind='hex', color=\"#4CB391\")\r\n",
        "j.set_axis_labels('Adj Close', 'eth', fontsize=15)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.JointGrid at 0x7f6845e387b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "LcdioLH90hBa",
        "outputId": "a659ade4-7500-4783-bac0-a71030562b22"
      },
      "source": [
        "j2 = sns.jointplot(test_df['Adj Close'], test_df['eth'], kind='kde', color='orange')\r\n",
        "j2.set_axis_labels('Adj Close', 'eth', fontsize=15)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.JointGrid at 0x7f68436d6ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAGgCAYAAAAZyDjpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5gV5dnH8e/MnF63sJSlClLFpVojKin2GNSAsIkmKjFRY0JEXyOJJjHRJBKNnRg1INZYElExSmKNRqM0YenC0tuy9fQyM+8fi6sbWNhyOvfnurhYzsw8cz+c3fPbmXnmGcU0TRMhhBAiD6jZLkAIIYRoLwktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQecOS7QJyVU1NINsltFJc7KK+PpztMtKmkPtXyH0D6V8mlJV5s7r/XCKhlScsFq3Vv7XQBixNSzDsvUgUfQnU/H4r/7d/haSQ+wbSP5FZ+f1JdyQyEnjWzMCx8wkUmu8LT/jGERj5Z3T34CwXJ4QQ6SXXtPKJqeOtuhLnzseJ9LuGuhM/oOmYOWiRaooWn40a2ZbtCoUQIq0ktPKIc8t9OPa8QHDwrYSG3o7uPYZY+bdoGP8aGFH8yy8GPZrtMoUQIm0ktPJFsBr3xt8SKzuXyIAZrRbpnmEERj6CJViFa/NdWSpQCCHST0IrXyz9CaaiERw2+6CL42VnEe35TVzVd6GFNmS4OCGEyAwJrTygBVbA9gVE+v8Iw9GnzfVCQ27HVG24P/11BqsTQojMkdDKA+5Ns8HqI9LvB4dcz7D3JNLvKux7X0QLVGWoOiGEyBwJrRynhT7FvncBDLkW01p02PUj/X+IYfHh3vS7DFQnhBCZJaGV4xzb/4KpWGDID9u1vmktJtL3Smx7X0YNb0pzdUIIkVkSWrlMD+PY+QSx7ueDs2e7N4v2+R4oFpzbHkpjcUIIkXkSWjnMvvtvqMkGon2/16HtDEcvYj0uwLHjCZRkU5qqE0KIzJPQymGOXU+TdA0iUXRyh7eN9LsKVQ/g2PlEGioTQojskNDKUWp0O9b694j1vBgUpcPbJ/3jSPhPwLn1ITD1NFQohBCZJ6GVo+y7n0fBJNprSqfbiPS7Ci1Sja3m9RRWJoQQ2SOhlaMcu/5Kwn88hmtgp9uIdT8f3dEH57Y/pbAyIYTIHgmtHKQFqrAEVxHtdXHXGlItRPpcga3ubbTgutQUJ4QQWSShlYMcu/6KqViI9biwy21Fe38HU7Hh3P7nFFQmhBDZJaGVa0wD++7niJd+FdNW2vXmbN2I9bwI+86nZfi7ECLvSWjlGGv9e2ixncS6emrwCyJ9r0TVg9h3Pp2yNoUQIhsktHKMfddfMTQvsbKzU9Zm0j+OhG8czm1/BtNMWbtCCJFpElq5RI9g37uAeI/zQXOltOlI3yuxhDdgrXsrpe0KIUQmSWjlENu+11CTTUR7dv7erLbEel6IYeuOa8t9KW9bCCEyRUIrhzh2/RXd1pNEyampb1y1E+n3A2y1b8iztoQQeUtCK0co8Vps+/5JrNdkULS07CPS53JM1YVry71paV8IIdJNQitH2Pe8iGImun5D8SGY1hIifb6LffdzqOGNaduPEEKki4RWjnDs/itJ9zB0z7Fp3U9kwAxQrLir/5DW/QghRDpIaOUALbQBa8OHzUdZnZjRvSMMe08ifS7HvusZtNCGtO5LCCFSTUIrBzh2PoGpaMTKv5WR/YUHXIepunCv/3lG9ieEEKkioZVtRgLHzieJdzsLw94zI7s07d0JH3U99n3/wFr7Zkb2KYQQqSChlWW2fa+hxvcS7X1pRvcb6XcVuvMovGtmgB7K6L6FEKKzJLSyzLHjMXR7L+KlX8vsjjUHgWPmoEa24NlwS2b3LYQQnWTJdgFHMjW6Hdu+fxE+aiaomX8rEsUnE+l3Na6tD5DwH5/SSXqzSYnXoEW2oMZ2o8ZrABVTtWBqbgxHH3Rnf0xrt7QPehFCpJ6EVhY5djyBgkG09yVZqyE0+FdYAp/gXf1DDHtvEiWnZK2WTtND2PcswFb3FtaG/6JFNh92E8NSRNI3hqRvLPHik0kUfynl8z0KIVJPQitbjDiOHfOIl0zEcA7IXh2qjaaK+RQtPhv/sotoqphHPIUzzKeNaWJp/AjHziew734BVQ9i2LqTKDqRSJ/vobuPxrD3wrCVASYYCRQ9gBbZjhbdghZci6VpKc4t9+DafCemYiNRfDLx0q8Q7/Y1dPdwORITIgdJaGWJffdzaLGdBEZkfwJb09aNhvH/wL/0QvzLLybS93uEBt6EaevWzgZ00CMoRgzFTGBYi0G1p6VWJbYHx65ncOx8HEtoPabmJtrjAqLll5AsOvGwQaN7K/7nhTDW+v9gq30TW92beDbcDBtuRncOINbtLOJl5zQfhanWtPRHCNEximnKA5YOpqYmkL7GTZPiD08CoP7ED9r1G31ZmTe9NQHoEdwbfoFz20OgOoiVnU2i+BR0Z39QHSjJAGp8T/O1oug2tMgWtMhW1Nh2FFNv1ZRh8WM4epP0HkvSO4qkbywJ31jQHB3vnxHDtu9fOHY+gW3fayimTsJ/AtHelxLrMQnT4k3Zf4Ea3Ylt3yJsNa9iq3sbxYhiWPzES79KvOwc4t2+hmkt6lCbGXnvskj6l5kaRDMJrTak85vUtvcV/J9U0nTMnHbfUJzJHxwttB7nlgew1byKFt9z0HV0W08MZ390Z7/mgQ2WIkzVDoqGmqhDje9FjWzFEliBFtsJgKlYSfpGkyg6kUTRSSSKTsC0lR3YP9NEjW7F0rQUe80/sNW8ippswrB1J1peSbT82+juIen/j9BD2GrfxlbzKvZ9r6HGazAVC4niLxEvO5tYt7MxXEcdtplc+NBLJ+lfZmoQzSS02pC2b1JTp/jDL4ERo/6kj9s9ajArPzimgRrbhRrdhmLEMDUvhr1H83Ui1dbuZpTYXqyNi7E2foi14UMsjUtRzDgAhubFcPTG4iknnjBRkk1okWrURF3zcksRse7nEe8xiXjJxOydpjMNLI2LW0LUEloDQNIzgni3s4mVnU3SPx6UA+8iyYUPvXSS/mWmBtFMQqsN6fomte/6K76q79F07F+I9fxmu7fLhR+clNGjWALLsTYuRo1sRYvtwG7UkkgkMC0+dEcfkt7RJH2jSXqP7VBAZooa3rQ/wP6BteF9FFPHsHUnXvoVEv7jSPqPI+k5BlRLYb13ByH9y0wNopmEVhvS8U2qJJsofn88hr0nDSe8fdDfytuSCz846ZTP/VMS9dj2/bP5Olj9v/ffGwam6iLhG4Ot18k0WitI+sdj2MsLblRiPr937ZEL/ZPQ+pyMHswg18bfosb30DT6yQ4FlshtprWYWK8pxHpN2X89bgvWxsVYGj/G2vgxrLsHv9F8OlS39STpH0/CP46kfzxJ3xhMiy/LPRAif0hoZYi17l2cWx8k2udykv7jsl2OSBdFwXAOIOYc0HL6t6zERn31f7A0LsbatGT/tbFXADBRSHpHkyg5lXjJqSSKTgKLJ5s9ECKnSWhlgBLbi3fldHTX0QSH/Cbb5YhM0+zNR1X+8UT3v6Qk6rA0LsXa+BHW+vdwbp2Da8s9mIqFpG8c8ZLTiHf7KknfOLlHTIgvkNBKMyUZwL9sMmqykfqxz4PmznZJIgeY1hIS3b5KottXm1/Qw1gb/out7l2sdW/jqv4D7uo7MCw+EsWnNs/UUfrldg2xF6KQSWilkZKox7d8GpbgCppGPX3gbAxCfEZzkSidSKJ0IvALlEQ91rp3m2fqqH2j5XSi7jyKeOmXiZd+lUTJBLkeJo44ElppogVW4lt5GVp4M4GRjxAvOyvbJYk8YlqLiff4BvEe3wDTRAt/irX2TWy1b+LY9QzO7Y9iKhpJ//H7j8ImkvRWpG36LCFyhYRWiinxWlyb/4hz6xxMazGNY/9OomRCtssS+UxR0N2D0d2Difb7PhhxrA0fYa17E9u+N3BtvA33xt9gKhZ09/DmqbN8FejOgejOfhiOvimd6kqIbJLQ6irTRI1U75909V/YaxaCESfWaxrBIbdh2kqzXaEoNKqNRMkpJEpOIXz0LSjxfVjr38Pa9AmWwCfYav+FY9dTrTYxLEUYtm6YFh+mxd/8R3NgKhZQLKBo+7/WAHX/LRnK/r9VTEVp/vcXXmu+30yFvU6coXjz663asn7epmLBVK1fWP7Z1xZM1fL514rlgNc/X3d/u5+101KDOJJIaLVBVdv+YbA2fIB913OosZ1o0R2oyXoADEsxsYE/IdprKrpr0Gc/4hmpqRAUcv/S2jdHGcleF5DsdUHLS0p8H1p0+/5puHaixXaiJBtRkgEUPYiabEJJ1oCZBFNvnvDYTIJp0DwQ3wCM5sbM/V+bn71+oGwN0m8ONA0TS3NoqlbM/SGJojYv57PQ1PjfgG7eTtsfhFrLn5btVA12O/HEzP2va18IWK3V3y1BD81/K1/4mub/1YN9Iui+CnSnDLBpL5kRQwghRN6QaRmEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUPmHjyE2toghpEbs1wVF7uorw9nu4y0KeT+FXLfQPqXCWVl7Z+lP5c+tzrrUP2VI608YbFo2S4hrQq5f4XcN5D+icyS0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeSPjobVw4UIqKysZO3YsQ4cOPWD50KFDqaioYMyYMS1/1q1b17LcMAzuuusuTj75ZMaMGcMVV1zBjh07WrXxn//8h/PPP59Ro0Zx5pln8uqrr6a9X0IIIdIv46Hl8/morKxk1qxZba7z8MMPs2zZspY/Xwy3Rx55hFdeeYUnnniC9957j/Lycn7wgx9gGAYA27dv56qrruKSSy7h448/5qc//Sk33XQTn3zySdr7JoQQIr0yHloTJkzgvPPOo2/fvp3a/plnnmH69OkMHDgQt9vNDTfcQHV1NUuWLAHg73//O0OGDGHy5MnYbDYmTpzIxIkTeeaZZ1LZDSGEEFmQk8/TmjlzJolEgvLycqZNm8aUKVMACAQC7Nixg5EjR7as6/P56N+/P2vWrOG4445j7dq1rZYDjBw5koULF3a4jtJST9c6kmIdeaZOPirk/hVy30D6l0ty7XMr1XIutObNm8eYMWNQVZUPP/yQ66+/nmQySWVlJcFgEGgOqi/yer0ty4LBIEcffXSr5T6fr2V5R+TSw9TKyrzU1ASyXUbaFHL/CrlvIP3LVA3tlUufW52VVw+BPOmkk3A4HNhsNk499VS++93v8tJLLwHg8TT/BhEItP4GCgQCLcs8Hs8By5uamlqWCyGEyF85F1r/S1VVTLP5twav10vv3r2pqqpqWR4IBNi6dSvDhw8HYNiwYa2WA6xatYphw4ZlrmghhBBpkfHQ0nWdWCxGIpEAIBaLEYvFMAyDVatWsXLlSuLxOMlkkvfff5+5c+dy7rnntmw/depUHn30UaqrqwmHw8yePZsBAwYwbtw4ACZNmsS6det44YUXSCQSvPPOO7z11ltMnTo1010VQgiRYhm/prVgwQJuuummln9XVFQAMH/+fEKhELNnz2b37t1omkZ5eTkzZsxg2rRpLetPnz6dQCBAZWUlkUiEcePGMWfOHFS1OX/79u3LnDlz+O1vf8uvfvUrevbsye23386oUaMy21EhhBApp5ifnXsTB8ilC5q5cDE4nQq5f4XcN5D+ZaqG9sqlz63OyquBGEIIIURbJLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeUNCSwghRN6Q0BJCCJE3JLSEEELkDQktIYQQeSPjobVw4UIqKysZO3YsQ4cObbVs+fLlXHnllZx88smMHTuWCy64gEWLFrVa57777mP48OGMGTOm5c91113Xap3Vq1czdepURo0axemnn878+fPT3i8hhBDpZ8n0Dn0+H5WVlUSjUX72s5+1WtbY2Mg555zD7373O4qKivjnP//JzJkzefLJJ6moqGhZb/z48Tz++OMHbT8YDDJ9+nQqKyt57LHHWLNmDVdeeSXdu3fnrLPOSmvfhBBCpFfGj7QmTJjAeeedR9++fQ9YdtpppzFp0iRKSkpQVZUzzzyTwYMHs2TJkna3v2jRIlRV5eqrr8ZutzN69GgmT57MU089lcpuCCGEyIKcvqa1Z88eNm3axLBhw1q9XlVVxYknnsjEiROZOXMm27Zta1m2du1aRowYgap+3rWRI0eydu3ajNUthBAiPTJ+erC9QqEQ1157LRMnTuSkk05qef3MM8/kwgsvpLy8nL1793LnnXdy2WWXsWDBAtxuN8FgEK/X26otn89HMBjscA2lpZ4u9yOVysq8h18pjxVy/wq5byD9yyW59rmVajkZWoFAgCuvvJKysjJ+//vft1o2ZMiQlq979OjBbbfdxvjx41m2bBmnnHIKHo+H2traVts0NTXh8XT8jaytDWIYZuc6kWJlZV5qagLZLiNtCrl/hdw3kP5lqob2yqXPrc46VH9z7vRgfX093/nOd+jVqxf33HMPNpvtkOsrioKiKJhm85s0bNgwVq9ejWEYLeusWrXqgFOMQggh8k/GQ0vXdWKxGIlEAoBYLEYsFsMwDGpqarjkkksYOnQof/jDH7BYDjwQfPXVV6mrqwOgtraWm2++mZKSEsaMGQPAGWecga7rzJkzh3g8zooVK3juueeYNm1a5jophBAiLTJ+enDBggXcdNNNLf/+bCj7/Pnz+fjjj9mwYQPbt2/ntddea1nn61//OrfeeisAL730ErfeeiuRSASfz8dxxx3H3LlzW07/eTweHnnkEX71q1/x0EMPUVxczDXXXMPZZ5+dwV4KIYRIB8X87LyaOEAunRvOhfPq6VTI/SvkvoH0L1M1tFcufW51Vl5d0xJCCCHaIqElhBAib0hoCSGEyBsSWkIIIfKGhJYQQoi8IaElhBAib0hoCSGEyBsSWkIIIfKGhJYQQoi8IaElhBAib0hoCSGEyBsSWkIIIfKGhJYQQoi8IaElhBAib0hoCSFEISnwp01l/CGQQogUMU200DosTUtQY3swHH1JFJ+C4eiV7cpENpk6oGW7irSR0BIiz6jRXTh2zMWx82m06JZWy0zVRd3JH2I4B2SnOJEDEkhoCSGyTo3uwLXpDhw7nwQzQaLkdMJHXUei+BR0ey8sgZUULfk6ruo/EhxxT7bLFVmiGAlQHdkuI20ktITIdXoIV/WduLbcB6ZBtPelhPtfi+Ea2Gq1ZPFJxLt9FWv9e1kqVOQEU892BWkloSVEDrPtW4RnzXVo0a1Ee04mdPQtGM7+ba6vGHFMzZXBCkWuUYx4IZ8dlNASIhcpyQDu9bNw7niMpHsoDeNfI1F88qE3Mk0sTcuIdzszM0WK3GQms11BWkloCZFjtMBKfJ9cghapJjzgOkKDbgLVftjtLI0foSZqiZeenv4iRc5SzES2S0grCS0hcoh951N418zAsBbTOP5VEsVfave2jp1PYqpO4mXnprFCkfPkSEsIkXamjnv9z3FtfYB48QSaKuZh2sravbkS34dj1zNEe12MafGmsVCR6xRDjrSEEOmkh/GtvAJ7zULCfb9PaMjtoFo71IRrywNgxIj0vzZNRYq8IUdaQoh0URL1+JdNwdL4EYGhdxDt94OOtxHfh2PbQ8R6XIDuHpKGKkVekSHvQoh0UOL7KFryDbTQOpoqHiPeY1Kn2nFtugNFDxMeeFOKKxT5SJHQEkKkmhKvoWjxeWiRahrH/JVE6Vc61Y4W2oBz+yNEe1+K7hma4ipFXjKNbFeQVhJaQmSYEq+laMn5aJHNNI55jkTJaZ1uy73+Z5iqk9Cgn6ewQpHfCvtISx5NIkQGKckm/MsuRAt/SuPoZ7oUWNZ9/8S+7zXCA/8P0949hVWK/CZHWkKIVNCj+JZPwxJYSdOoJ0mUTux8W0Ycz7qfknQNItLvqtTVKPKfUdijBzN+pLVw4UIqKysZO3YsQ4ceeA5+9erVTJ06lVGjRnH66aczf/78Vsuj0Si33HILxx9/PGPHjmXGjBk0NDS0WueVV17hjDPOoKKigvPPP58PPvggrX0S4rBMHV/VdGz1/yZwzJ+Il53dpeacWx/EEt5AaOjvQbWlqEhRGAr7SCvjoeXz+aisrGTWrFkHLAsGg0yfPp1TTjmFjz76iLvvvpv777+f1157rWWd22+/naqqKl5++WXeeustwuEwN954Y8vypUuXMmvWLG666SYWL17MJZdcwlVXXcXOnTsz0j8hDmCaeNb9H/a9LxEc8ltivaZ0qTk1ugvXpjuIdTubeLczUlSkKBgFPhAj46E1YcIEzjvvPPr27XvAskWLFqGqKldffTV2u53Ro0czefJknnrqKaD5KOvFF1/kxz/+MT169MDv93PjjTfy9ttvt4TSs88+y5e//GUmTpyIzWZj8uTJDB48mL/97W8Z7acQLdbMxrntYcL9f0Sk/zVdbs618dcoRpzg0NtTUJwoOAU+5D2nBmKsXbuWESNGoKqflzVy5EjWrl0LwObNm4nFYhx77LEtywcNGoTT6WTNmjUtbYwcObJVu19sQ4hMsu9+AZbfSLTHhYQG39rl9rRAFY6dTxLp9wMM16AUVCgKjdynlUHBYBCvt/W8aT6fj2Aw2LIcOGAdr9fbah2fz3dAG9XV1R2up7TU0+Ft0qmsrLDnlCu4/u39N6z6PpRNwHH6kzi0FDxNdvVvwerHddwvcdly5/+r4N67/5FP/fN6rHjzqN6OyqnQ8ng81NbWtnqtqakJj8fTshwgEAhQUlLSsk4gEGi1TiAQaLONjqitDWIYZoe3S4eyMi81NYHDr5inCq1/Wmg9RR+dj+Hoj+XUF6mpSwBdm8hUC1RRsuNlQoN+TrjRAuTG/1ehvXf/Kxf615HQDDSFiOb5+3Go/ubU6cFhw4axevVqDOPzC4mrVq1i2LBhAAwYMAC73U5VVVXL8o0bNxKJRFrWGTZsWKvl/9uGEOmmxPbgX/ZNUK00jnke7CWH36gdnNsexlSdRPpOT0l7olDJQIyU0nWdWCxGItH8W2csFiMWi2EYBmeccQa6rjNnzhzi8TgrVqzgueeeY9q0aQA4HA4mTZrEvffey969e2lsbGT27Nmcdtpp9O7dG4ApU6bw5ptv8s4775BIJHjhhRdYv349F1xwQaa7Ko5EySD+ZVNQY3tpHP1XDNdRqWnXSGLfu4BY9/MwrakJQVGYCv2aVsZDa8GCBVRUVHDFFVcAUFFRQUVFBR9//DEej4dHHnmEd999l/Hjx3PttddyzTXXcPbZn9/TMmvWLIYPH865557LxIkTsdvt3HHHHS3Lx44dy2233cZtt93GuHHjmDdvHnPmzGkJNSHSxkjgX3EJlsAnNFXMJekfn7KmtfAG1EQd8W5fS1mbokAVeGgppmnmxkWbHCTXtDIn7/tnGnhXXYVj19MEht9HtM93Whalom/W2jcpWjqJhnELSZRM6Gq1KZX3791h5EL/OnJNK1j1MJEeU9NYTfrlzTUtIfKVe8PNOHY9TWjQz1sFVqroroEAaMFVKW9bFBalwB8CKaElRBc5q/+Ia8t9RPpeSfioG9KyD8M5gKRnJK7qO1Fie9KyD1EgCvzkmYSWEF3g2D4Pz6e/INrjIoJD7wBFSdu+mkY+jJpswr9sMkq8Jm37EXlOjrSEEAdj3/0CnjU/JtbtDAIjHwIlvT9OuvcYmirmYwmto+jjM1Cju9K6P5GfFKNr9wPmOgktITrBVvMa3qrvkSg6iaaK+RmbaT1ediYN4xagxvbgW34x6KGM7FfkD8WIZLuEtJLQEqKDrHX/xrfiUpKeY2ka/VfQXBndf7LoRALHPoolsALPhl9kdN8i9yl6ONslpJWElhAdYGlcjG/5xejOATSO/Rum1Z+VOuJlZxMt/xaOHY+jxGsPv4E4YiiGhJYQAtCCq/EvuwjT1o3GsQswbaVZrSfa57soRgRb3dtZrUPkmKSElhBHPDVcjX/JJEzFTsO4lzAcvbJdEklP8yN4tPCnWa5E5BKlwK9z5tQs70LkIiW2h6Kl30AxYzSM/weGc0C2S2rWMlpRfvcUnyv004MSWkIcgpJswr/sItTYXhrGv4zuGZHtklqo0R0AGLayLFcicolS4KcHJbSEaIsRx/fJt7AEV9M4+lmS/uOyXVEr1ob/ApD0jclyJSKXKIacHhTiyGOaeFddja3uHZqOeYhEt69mu6ID2GteQbf1JOkdme1SRA5RdLlPS4gjjmvT7Th2P0to0M3Eyqdlu5wDKLG92GpeI9bzQlC0bJcjcojcpyXEEca+6zncm35PpPzbhI+6PtvlHJRz+yMoZoJonyuyXYrIMYoRKehnakloCfEFlsaleFdfQ7zoSwSH353WCXA7S0k04Nz6J2Jl56K7B2e7HJGLCvgUoYSWEPsp8Vp8K76NYSujadTjGZtPsKNcm/+IkmwkNOimbJciclQhzz8oAzGEADANfFXfax7aftwiTFu3bFd0UGpkC86tc4j1moLurch2OSJHKXqYQn2qloSWEIBzy/3Yav9FYNhdJP1js11OmzzrbgJUQoNuyXYpIocV8ghCOT0ojnhaYCXuT39FrPv5OT2wwbZvEfaaVwgNvAHD2Tfb5YgcVsgjCCW0xJHNSOCr+j6GtYTA8HtycuAFAHoYz9rrSbqHEOl/bbarETlOrmkJUaCcW+7FEqyicdQzWZ+1/VDcm+5Ai2ymYdzCnB0gInKIHGkJUXjU6E7cm2YT634+8e7nZLucNmmBVTi33Eu0/FskSiZkuxyRB+SalhAFyI5F+igAACAASURBVLXxNjCTBIf8JtultM008K75EabFT3BwDtcpcoqcHhSiwKjhTTh2PUWk75W586iRg3DsfAJr48c0HfOnnD59KXKLDMQQosA4tz8KqEQG/CTbpbRJidfi3nAL8aKTifXKvfkPRe6S0BKikJgG9l3PEi87C8PeM9vVtMm98TcoyUaCw+/K3VGNIidJaAlRQLTgarT4HmJluT34wrF9LpE+03PqwZMi95mKBgV8TUtCSxxxLIGVADn3UMcv8qyfhWnxEZb5BUUHmaoLRS/cB0FKaIkjjpJsBMCwFme5koOz1r6Fre4twgP/D9Naku1yRJ4xVYecHhSikBiO5imQtPCmLFdyEKaBe8Mv0R19ifSZnu1qRD7SJLSEKCiJouMxFQv2PX/LdikHsNUsxBpYRmjQLNAc2S5H5KHm04OFG1o5d5/Wueeey86dO1v+bRgG0WiU+++/n6997WsMHToUu92Opn3+iPFnnnmGoUOHtqx/99138/zzzxOJRBg7diy33norvXv3znhfRG4ybWXEek7Guf0xwgNnYVr92S6pmWni2nQHSdcgYj0vznY1Ik+ZmhMl3pTtMtIm5460Fi5cyLJly1r+zJw5k6KiIk499dSWdR5++OFW63wWWACPPPIIr7zyCk888QTvvfce5eXl/OAHP8AwjGx0R+SoSJ/LUYwwtn2vZbuUFs1HWZ8QPup6UHPu90mRJ0w5PZhdTz/9NN/85jex2+3tWv+ZZ55h+vTpDBw4ELfbzQ033EB1dTVLlixJc6UinyT9x2EqVizBVdkupZlp4tr0e5LOgXKUJbrEVJ0FHVod+nUuFovx8ccfs3v3bmKxWKtliqJQWVmZ0uI++OADNm/ezNSpU1u9PnPmTBKJBOXl5UybNo0pU6YAEAgE2LFjByNHjmxZ1+fz0b9/f9asWcNxx3VsiHNpqafrnUihsjJvtktIq4z2LxkBM4HLV4orA/s9bN92LYLAJ3DCI5T1yM1RjYci35u5w+70QkM0r2ruiHaH1uLFi/nRj35EXV3dQZenI7SefvppJkyYQN++nz/wbt68eYwZMwZVVfnwww+5/vrrSSaTVFZWEgwGgeag+iKv19uyrCNqa4MYRm48tLqszEtNTSDbZaRNpvtn27cIP9CgjSCR5v0etm+mSdGyX6Lae1Pn+Qbk2fss35uZqaG9okkr1niIujx+Tw7V33aH1m233Ubfvn35y1/+wqBBg7BarSkpri179uzhjTfe4IEHHmj1+kknndTy9amnnsp3v/tdXnrpJSorK/F4mo+MAoHWb1YgEGhZJgSAY8d8DIufRHH2H/VhrX8fa8MHBIbOBrV9p8GFaJNqL+hZ3tt9Tau6upof/vCHDBs2LO2BBfDss8/Ss2fPVgMwDkZVVUyz+WjI6/XSu3dvqqqqWpYHAgG2bt3K8OHD01qvyB9acA32vS8R6XtlTgwrd22+C8PajWjvS7NdiigApmpH0aPZLiNt2h1aQ4cOZd++femspUUymeTZZ5/l4osvRlU/L3HVqlWsXLmSeDxOMpnk/fffZ+7cuZx77rkt60ydOpVHH32U6upqwuEws2fPZsCAAYwbNy4jtYvc59r0OwzNS6Tf1dkuBUvjUmy1/yLc/xrQnNkuRxQAU7WDEQUzNy5tpFq7Tw/+8pe/5Kc//Sm9e/fm+OOPT2dNvPHGGzQ0NPDNb36z1et79uxh9uzZ7N69G03TKC8vZ8aMGUyb9vljG6ZPn04gEKCyspJIJMK4ceOYM2dOq/ATRy5r/X9w7Pk7oYE35sTzqVzVszEsRUT7fi/bpYhCodpRMMGMg1J4p5sV02w7jk888USULzwSIRKJEIvFsFqtuN3uA9b/4IMP0lNllshAjMzJSP+MJMX/PRUl2UDdyR+DduD3cDq01TctuI6SD44jNPBGwoN+lpFa0kG+NzNTQ3uFVjyIu+oa9p2+FdNalMaq0qfTAzG+9a1vtQotIfKZc/vDWIJVNFY8nrHAOhTX5j9gqi4ifb+f7VJEQSnsz+xDhta1116bqTqESCsltgfXxtuIl36ZePfzO9eIHsKx+2+okWp0z0hiPS/sdD1quBr7rueI9L8G09at0+0IcQBTb/5b0Q69Xp5q94WeSy+9lI0bNx50WXV1NZdeKiOfRO7yrP8Zih4lOPQPHX8KsGng2PYwpe9V4F19Da7qO/Gt/C72XX/tdD3OrQ+CohHp98NOtyHEQe0PLVMpzKnA2h1aH330EaHQwR8sFgwGWbx4ccqKEiKVrPv+iWP3s4QHzEB3H92hbZV4Lf5lF+JdO5OkZwT1419n31dq0J0DsO9+vlP1KIk6nDseJ9ZzMoajV6faEKItSsuRVmGGVpd7FY/H+fDDD+nWTU5xiBykR5oDxz2E8MAbOrSpFlyHf/lk1OhOAsP+SLTP5S1HaQnfGCxNn3SqJMf2uShGmHB/Of0u0iHZ/FeBnh48ZGjdf//9LTNSKIrCxRe3PZHnFVdckdrKhEgBV/VstMhmGsa93KHZJiyNi/Ev+yYoFhrGLyRZdEKr5Wq8BtNW1vGCTAPn9rnES05D9x7T8e2FOBxTx0QBpTBv8zlkaJ166qkUFxdjmia/+c1vuOyyy+jTp0+rdaxWKwMHDmT8+PFpLVSIjtKCa3Ftvodor6kkSk5r93bW+v/gX3YRhq2MhrF/x3ANar2CqWNp+oRYrykdrsla9w5adCuhwb/s8LZCtIdiGgV7ahAOE1oVFRVUVFQA4Ha7Of3006mtraWqqordu3dz0UUXUVZWxpYtWwgGgzK/n8gdpoFnzQxMzU1wyO3t3sxa9y7+ZVPQHb1pGP8qpr3HAetYGhej6gESxV/qcFmOXX/FsPiJlZ3X4W2FaBdTP3JD64vOOOMMZs2axaJFi9A0DV3XmTBhAmVlZdx1112Ul5dz4403prNWIdrNseMxbA3/ITDigXYPKbfUf4B/+cXozv40jHsZ0979oOvZ976CqViIl36lY0UZCWw1rxDrfn5OzHkoCpSZxCzQ61nQgdGDv/vd71i2bBlz585l6dKlfHEijdNOO41///vfaSlQiI5S4vtwb/gF8eJTiJZ/u13bWJqW4V92Ebq9F43jFrQZWBgJHLueJl76VUxrx557ZWlaippsIt7tjA5tJ0SHmHrBDsKADoTWokWLuP766znxxBPRtNb/IeXl5ezYsSPlxQnRGZ51N6LoIYLD7mrXPVlacDX+pZMwrSU0jnsFw96zzXVtNa+gxvcS7XNZh+uyNjbfFpIoOukwawrReQpGwQ7CgA6EViwWo6jo4PNYhUKhA4JMiGyw7VuEY/dzhI+aie4Zdtj11cgW/EsvxFTsNIx7CcNRfsj1ndseRnf079TRkhZcjWErO+h1MiFSq3Cncmp3aB177LEsWLDgoMtef/11xowZk7KihOgMJdmEZ80Mku6hhI+aefj14/vwL/kGih6mcezfMFwDD7m+FliJrf49In2v6NTpFy2yBd156H0I0WUF+kiSz7R7IMaPf/xjLrvsMr773e9y1llnoSgK77zzDvPmzeP111/niSeeSGedQhyW+9NbUaM7aDjun4e9J0tJBvAvuwgttpOGcS+je0cetn3XlgcwVRfR3t/pVH1qbBfJduxHiK4xkSMtYPz48cybN494PM6vf/1rTNPkvvvuY9u2bcydO7dlaLwQ2WBp+BDHtoeJ9P0+yaLDPO/NSOBb8R0sgRU0VTx2wI3DB6PE9mLf/TzR3t/u8ACMz6jJBkxL57YVomMKN7Q6NJh/3LhxPPXUU0SjURobG/H5fDid8rRVkWV6CF/V9zGc/QkfffOh1zVNvKt/iK32XwRG3E+87Ox27cK5Yx6KGe/SY0SUZBDT0v7nIgkhDtSpO9AcDgcOh9xnInKDZ/3NqJHNNI5beNhQcG38DY5dTxMaOIto73Y+mcDUcWyfS7xkIrp7cOeKNJIoRgQzB57jJQqbqdrAiGW7jLQp3HGR4ohg3fdPnNsfIdLvGhIlpxxyXcf2x3BXzybS+zuEB7b/Rnhb7RtosR1E+nR+fk1Fb37yrRxpiXQzNSeKEc52GWkjoSXylpKow7v6hyTdwwkdfcsh17XWvoln7QzipV9p9/1bn7HvfgHDUkS87Kwu1QpgWEs63YYQ7aLYmx9PYiSyXUlaSGiJ/GSaeFfPQI3XEBj5p0NOi6QF1+BbcSm6exhNFY+Bau3Afgxs+xYRLzsTVFuny1VjewEwOjMzvBAdYGrN4wwU/eDPP8x3EloiL9l3PYV974uEBv2cpK/tewSVeA3+ZVMwVSeNY57DtPg6tB8ttA41UUu85PQu1atFtwNgOPocZk0huuazU9BKsjHLlaSHhJbIO1pwHd41M4kXTyAy4Mdtr6hH8S+vRI3vpWn0M50KDC20FoCkt2u3dGiRTc0lOft1qR0hDsfYf0uGGq/NciXpUbjz14vCpEfxrbwcU3MSGPlI2zNT7B/abm38L40V80n6x3Vqd1psNwCG/dDTOx22nfAmdHs5aK4utSPE4ZiW5un2lISElhBZ51l/E5bgShpHP4vh6NXmes7Nd+PY/SyhQT8n3mNSp/dnttyk2bWpcbTwhs4PlxeiAz4b7KMWaGjJ6UGRN2x7X8a5/VHC/a895Eg+W80/cH/6S6I9LiJ81A1d2qfh6A00zxvYaaaJFlyH7h7SpVqEaA/D3jzYR40W5pM3JLREXlAjm/GuupqEbwyho3/R5npacDXelVeQ9I4mcMyDHRrafjBJ77EAWBo/7nwj4a2oeoCke0SXahGiXVQnuq0HWrg625WkhYSWyH16FN+K5klqm4esH3zouZKow798Kqbmpmn006B1fYoxwzmApGsQ9n2LOt9I/ScAMlmuyBjDdVTL4J9CI6Elcp5n3Y1Ym5YROOZBDOeAg69kJPGtuAw1upOmUU8c9rlYHRHvdjbWundRkoHONVC/HBOFpOeYlNUkxKHozoFypCVENth3Polzx1zCA35CvPvX21zPvfFWbHVvERx+V7tmbe+IeNnZKGYca/17nWugfhm6axBYPCmtS4i26K6j0GI7QI9ku5SUk9ASOcvStBzvmhnEi08lNKjt2dvtu/+Ga/PdRPpc0f5JcDsg4R+PqVixNvy3cw3UL+/yfV5CdMRnDxvt0gCiHCWhJXKSEq/F98klGNZuNFXMA/Xgd2dowTV4V19Dwn8CwaG/T08xmhPd0Re1Mx8AehhCm9E9w1NflxBt0F1HAc33BxaanAut++67j+HDhzNmzJiWP9ddd13L8tWrVzN16lRGjRrF6aefzvz581ttH41GueWWWzj++OMZO3YsM2bMoKGhIdPdEF1hJPGtvAw1vpumUY9j2roddDUl0YBv+bTmgRcV87s0N+DhmNYi1GTHv4+0yDYA9LauxQmRBrrrsyOtwgutnLy5ePz48Tz++OMHvB4MBpk+fTqVlZU89thjrFmzhiuvvJLu3btz1lnN9+3cfvvtVFVV8fLLL+NwOLjhhhu48cYbeeihhzLdDdFJ7g0/x1b3Nk0jHiTpH3/wlUwDb9X30aJbaRj/6iFvNE4FxYhhqB1/hpwa2wV0fUYNITrCtJZgWIrkSCvbFi1ahKqqXH311djtdkaPHs3kyZN56qmngOajrBdffJEf//jH9OjRA7/fz4033sjbb7/Nzp07s1y9aA/H9sdwbX2QcN8fEOv97TbXc226A/u+fxAc8luSRSemtyjTRI1u79SIxM+eo2VY/amuSohD0gt02HtOhlZVVRUnnngiEydOZObMmWzb1nyKZe3atYwYMQJV/bzskSNHsnZt86SmmzdvJhaLceyxx7YsHzRoEE6nkzVr1mS2E6LDbPsW7X/m1ZcJDbm97fVqXsO16bdEe00l2vfKtNelxnagJhtJujoxo4WZ3P9FG3MkCpEmzcPeCy+0cu704JlnnsmFF15IeXk5e/fu5c477+Syyy5jwYIFBINBvN7WT371+XwEg0GAlr//dx2v19uyrCNKS3NriHJZWQE/9XbfR/hXfgeKjsX25b9TZm3jESJNG2DV96B4NI4Jf8Fh6foNxIe1eTkA3qMm4i3p4HuQ6AFAiScBBfz+FfT3JvnVv5bPrW7DYO+LlJU62xzIlI9yridDhnz+22yPHj247bbbGD9+PMuWLcPj8VBb23oSyKamJjye5jfps78DgQAlJZ8/ITYQCLQs64ja2iCG0bWJUlOlrMxLTU0nb27NcVqgipKl56Jby2g49lmMBgU4SF+TQYo/noSKRv0x8zHqkwdfL8W81S9hs5ZQmxwEHXwP1GQ5pUBg+xKiyuj0FJhlhfy9CbnRv46E5mefWw6jDK+pU7tjQ949x+1Q/c3J04NfpCgKiqJgmibDhg1j9erVGIbRsnzVqlUMGzYMgAEDBmC326mqqmpZvnHjRiKRSMs6IrdogZUULfk6aC4axr2EYe958BVNE9+qq9GCa2k69i8Yzv6ZKVCPYqt5jXi3M9t+DMohGI7+4OqLfc8LaShOiLYZ9ubJngtt4tycC61XX32Vuro6AGpra7n55pspKSlhzJgxnHHGGei6zpw5c4jH46xYsYLnnnuOadOmAeBwOJg0aRL33nsve/fupbGxkdmzZ3PaaafRu3fvbHZLHISl4UOKFp+LqTrgK2+1PUUT4Np8Z/OTigffSqL0yxmr0bbvNdRkA9GekzvXgKLAsJnY6t/DWvt2SmsT4lD0/UdXmoRWer300kucc845jBo1ikmTJhGLxZg7dy4ejwePx8MjjzzCu+++y/jx47n22mu55pprOPvss1u2nzVrFsOHD+fcc89l4sSJ2O127rjjjiz2SByMfdezFC35OoatlIbj/gG+tp81Zdu7EPentxLtOZlI/2szWCU4t89Fd/QhUTqx840cfSW6cwCetTM7P3+hEB302WN1Cu1ISzFNMzcu2uQguaaVekoygHv9LJw7HiNRdBKNo57CtJW22T8tsILij88k6R5Kw/h/pGTm9vbSQhso+c84QoN+RnjgjZ1up6zMS8O6V/Av+Qbx7uc3z1TfxUem5JJC+d5sSy70rzPXtDBNur1RQnjATwgffUsaq0u9vL6mJQqEaWDf/TzFH5yAY8d8wgOuo2HcK5i20jY3UaM78C+bgmEpomn0MxkNLADn1jmYio1In8u73Fai5DRCg3+Jfe+LOLbJje4iAxQF0+JDTTZmu5KUyrnRg6KwqJEt2GsW4tg+D0toLUnPSBqOm0ey6PhDbqckGvAvuwglGaDhuNfbHqCRJkq8FsfOJ4n2moJpK0tJm5H+P8Za/z6eDTeTKDkV3SMPhRTpZVr8KAkJLSFaM+JoofVYQutQI1vQotvQwpvQQmvR9k9jlPCOoWnko8R6Xnj4UXh6CP/yKWihDTSOeR49Cw9PdG7/C4oRIdL/h6lrVFEIHPMgJe+Pw7Xp9wQqHktd20IchGHxoySbsl1GSkloiU5Rwxux71mArfZfWBsXoxjRlmWGtQTd0Z9EyamEfeNJlJyO7hnavob1CP7llVgaPqKpYl7XBkB0lhHDue0hYqVfS/nRkGkrI1r+bZzb/kQwXnvI06NCdJVp8cvpQXEEM3VsNf/AufVBbPsfiJjwjiLS53KSvnEkPcMxnP0xLZ2cPUAP418+DWvd2wSOeZB4j0kpLL797Hv+jhrfS6T/1WlpP979PFxb78fa+BHxsrMPv4EQnWRafKiRwnqCsYSWODzTxLb3Jdwbf40ltB7d0Z/g0b8k1mtK6u60j9dTtHQSloaPCBzzILHyb6Wm3U5wbv8LSdfRJErSc5SX8I3GRMHStExCS6SVafWjBORISxxBtEAVnrU3YGt4n6R7KE3HziXW/RspnctMjWyFjy7G0rSepop5qTvCMg1A6dDwcjW8EWvDhwQH3wpKmgbXai5010AsgarDrytEFxgWn1zTEkcII46rejau6jsxLX4Cw+9pfpR9J6YyOhRLw3/xf1IJZpzGsX8jUXJal9u01r6Na8vdWBo+wnD0oWnUk+jutm9e/iL73oUAxHpc2OU6DiVZdCK2vQvBSBbUZKYit5jWEtRkE+hR0Dr+PLhcJPdpiQNooQ0UffQ13Jt+T6znRdSdvJhon8tSG1imiWPrQxQtPgdT88AZH3Q5sNTodnzLvknR0vPRguuI9boYNbod5+Y/trsNa/37JN1DMJz9ulTL4cTKzkFNNmCreSWt+xFHNn3/HJ1adFuWK0kd+RVPtGLb8yLeVVeDaqVx1JPEu3895ftQEvV41szAsefvxLqdSWDkn+nm79fhGdRbmCaOHY/hXv8zFAyCQ24n0mc6aA608KdYgu1/lpoW/jQj90/Fy85Bdx6Fe9Ns4mXngGpL+z7FkUd3HgWAFqlu99mGXCehJZqZBq6Nt+OuvoOEfzxNFfPT8jgDa92/8a76PmpsN8Gjf0FkwE8Ofu3INLEEPsHSuAQtuhVTcxEvOZ1k0QmtVlPDm/Cu+Qm2ureIF59K4Jj7W028qyTqMW3d21+gqWOq1k72rgMUjeDgX+Nf8W3cG24mNOR3XZvaSY+iRarRIptRo9tQY7ub/yTqUfQwmAlAxbR4MGw90N1DiHc7E919dMq6JHKP7mp+f7XASuh2RparSQ0JLQFGHO+qq3Dsfo5I+SUEh/8x9b/56yE8G36Bc9ufSToH0nDcIpL+8QespgXX4tj5JPY9L6BFtwNgKlYUM4F7420k/McT6XMZpqUI277Xcex8ClNzEBh2F9E+l7cOQCOGJbiWSP/2zwpv2HuihTZ0ubvtEe9xPpG+V+LaOgc10Uhg+F2guQ67nRrbjaVxKZbAciyBlViCq1AjW1D4fJ5MU9EwbN0xraWYmhtTbf4/VCNbsTZ8iJqog/U3ES/9CoER97dMrioKi2krJekehq3+fSJHzcx2OSkhoXWk08P4P6nEVvvm/iOf61I+mat137/wrr0ONbKFcL+rCB39i9YfzqYB21/Cv/JObPXvYioW4qVfJTToZySKJ2A4+oIewrHzCZzbHsK36qrmzVQ70d6XED7qBgxH+QH7tTR9gmLGSfgODMe2xLufh2f9LCyNiw8aqqkWHHoHhrUb7k23Y619k3iPr5PwjsG0dQMUlGQTamwnWmQzWmgDltBa1PheAExUdPfRJHxj0XtNRXcNRncNwHD0xbCVHfIapBrZhn3387ir76D4g5OoP+m/GI5eae+vyLxE8Zew73q2YAb9yCzvh1Dws7zrIfzLpmCtf4/giPuJ9r4kpc2rsd24192EY88LJF2DCY64l0Txlz5fwUhg3/0srs1/3H//V18ifa4g2vvS/R/aB2GaWJqWACq6axCm1d/m/h3b/ox37fXUTljT7iMJJdFI8QcnYFqLqD/hHVDtHejxwbXnvbPWvYdzy33Y6t9F0UMHLDcsRejuo9HdQ0l6RpLwjyPpPRY0d5dq0wJVFH94CpEBPyI0+NZOtZELs6CnUy70r1OzvO9n27sQ/yfTaBz9HPGyM9NRXsodqr/5H7uic/Ro8+wT9e8TGPkwsV5TUte2kcC57SFcG29HMeKEBs4ifNRPPg8AI4l91zO4q+9Ai2wm6RkJJz9FnfOsw/8mqCjtPgKyBNdgWIow7AcehbXFtPoJDr8H//LJeNb+H8ER97R7265IlJxCouQUMHW0cDVKsh5ME9Pix3D0wrT40rJf3TuSROlEbPv+2enQErkt3u1rGNYS7LuezpvQOhQJrSORqeNbeTm2urdpOuZPKQ0sa+0beNbdhCW0lljp1wgOuwPDNWj/fg3su1/Atel2LOGNJLxjCI7+PfFuZ1HW3df50YNtUGO7mk8bdvB0Z7zsTMIDrsO1+S4SRScSK5+W0roOSdEyPjjCsPVAC63L6D5FBqk2oj0n49wxryDmu5T7tI5AnnU3Yq95hcDQO4iVV6akTTWyBd8n36Zo6QUoRozGUU/TNOb5lsCy1r5F0X9Pw1d1BagOGkc9TcMJbzdPY5SmByKamqt55FwnhAb9nHjxKXjX/AQ1vDHFleUWJV6DYc3vDzJxaNE+08GI49z6QLZL6TIJrSOMY/tfcG77M+F+PyTa7wddbzAZxL3hF5S8Pw7bvn8SPPoX1J38EfHu54KioAXX4F96IUVLv4GaqKNp5J+pP/H9luXplPSMRItsxlbzj45vrFoIjHwYU7Xhq/p+80XsQmSaWAIr0d1Dsl2JSCPdM5RYjwtwbn0IJVGX7XK6RELrCGJp/BjP2huaR+YN+XXXGjNN7Lufp+Q/43Ft/mPzzBlfWto8rFa1o8Rr8aydSfGHJ2NpXExw8G3UnbyEWK+p6ZvT739E+l1NwjsK38rLcW/4FWpkc4e2Nxy9CQ67E2vjR7iq/5CeIrNMC65Gi+8mUXxqtksRaRYe+H+oegDX5ruzXUqXyDWtI4SSaMC34nIMezlNxz7apSmZtNAGPGuvw1b3DgnvaJoqHvv8pl9Tb56d4tNfoSQaifa5nNCgn2XnPLrmoGnUk3jW/RTn5j/i2nwnCW8F8W5nkSj9Mgn/8Ycd+BHrNZnovtdxbfodieKTUjI3Yi6x730RE4VY2VnZLkWkme4ZQbRXJc4tDxAtvyRvZ8iQI60jhGfdjaix7TQd+yimtbhzjZg6zuo/UvzBSVialhMYdhcNJ7zVEliWpuUUffQVvGtmkPQcQ/2J7xMcfldWL/wazn40jX6KulNWEBx8G2guXNV/oGjxWZS+ezTuDbegRncdso3A8LvR3YPxfXIJlqblGao8A/YfLSeKT8G098h2NSIDgoNvxdRceNbdAHl6t5OE1hHAVvM6jl1PEx4wk2TR8Z1qQw1vomjx2Xg+/QXxsrOaJ9HtO735iE0P4V7/M4r+ezpadDtNIx+hcdxCdO8xzRubBlroU9TwpubZprPAcPYjMuBaGo5bRO3pm2msmE+ieALOLfdR8p+xOLc80PYPscVD45gXMC0+/EvOx1r7RmaLTxNr/b+xhDcSzeKzg3aj2AAAIABJREFUy0RmmfbuhAfNwlb7Jra9L2W7nE6R0Cp0egjP2pkk3UMJD/y/TjVh3/UcJR9+CS24hqaRf6ap4vGW38yt9e9T8sFJuLbcR7T3pdSd/HHLEHpr7Zt4V1xG6dsDKPnPWErfH03JexVoHZjANh1MaxHxHpNoGvU4dScvIV78JTzrb8Jb1TzC6mAMZz8axr+CYe9F0dILcK+7ESXRkOHKU8u55X4MazdiPS7IdikigyJ9vkfSMxLP+pvgIDey5zoJrQLn2nwvWnQrweH3dHw+QSOJe+0N+KquIOk9lvqTPtg/kEIBI4Z7/c/xLz4HgIZxrxIccW/znIB7X6Xov6dRtHQStro3iXX/OoERD9A04kHURA2OnU+moaedY7gG0jT6OUJH34Jj93N4q763/+GRB1nXOYD6E94m0vd7OLf+iZL3R+Os/iNKMk2zJZgGanQHlsaPsda+ibX2DSxNy1KyPy20Adu+14n0vQI0ZwqKFXlDtRAYdidadDuu6juzXU2HyUCMAqbE9uDafA+x7pNIFJ/csY2TQXwrvoO99p+E+11NaPCvYf/s51poA96Vl2ENrCDy/+ydd3hUZdqH71PmTJ9JJY0QEnpvspZV1rLurrqWdVEBu2LvBXtfG4u9wSqWXXvvupa1rPpZEAidECAhgfQ2fc7MKd8fJwYwhYAgZee+Lq4LmHfOec+Z5DzzPu/v+T19zyQ8+HaQ3MiBBXjKZmALzEN3FhMa/ijxvOM7nDCEZABh+flW/6ye0KMozZ8jJppIZEzCcBVvy+X3HkEgWnwlpmDHU349umsA0YE3dT1WchIeei/x/FNwr74Vz+qbcVXeR7zgVGJ9z8BwlWzbHEwdKbwCW2AecnABcnAxcqQMwehcZ2Yiksz4HeEhM9E9Q7fpdM5K60tMrO9Z2zbfFLs1Wvq+xPOmWM+HvGm7ldt/Kmjtwbgq7gVTJTzo5q16n5Boxr9wMnKo1OpY3Pf0jtfsda/hXX4RpmgnMPZlqzhYC+NeOQNn9eOYSjah4Y8Qz5vWSZnnrH4cgER3SjXTwLH+Sdxr70ZMNFpjMw4kMGEbcu+mjhxaihxajBRdg5BswxRtGI4CkumT0HxjO0nvY0UXIkVX4a64B83/m+7nCWi+MQTGv4EcmI9z3UM4qx7Fte4hEumTUHMnW8HWWdx1LZppIsbXI4eXIgcXYmv7HjnwI6JuraAMWzqadwyxvqeiuwZjOPIx5DQAxGQTcnAhzvVPk/7d/oSGP7zVjh1SZDWO2ueJ9Z2Oad+Kti0p9ijCg/6G0vA+7rKrCY57bYfXTW4vUkFrD0VINOHc8AzxvKkbbZR69b5m0uYfiRQtJzj6OasIGMDUcZffhGvdwyTT9iE46mkMRwG21m/wLjsPMbaOeOF0IgNu6tLEVoyuwVV5H2rWYVbA+DmxWvwLTuzoixUdORfX2plI0YreX7RpYGv5AkftSyiN/0bUrD0nU7Bhyn4wk4haAICkdzThofegpe2zycULhIfMwhZYgHfZ+bTs+90WH+qafwKh0f8kEq/BUfMs9poX8a64GGg3uXUVg7sPvqSJoMcQE41IsaqOFZSJiO4Zjpp3PMm0vUn6J2I4S3p8gCT6HEms33n4F52Ip+wq1D5HgryF1esmuCpmgqAQLb6y1+9Jsedh2nOIDrgWz6rrUJr+bX0B3Q1IBa09FGfVHDBUYv0v7fV7hGQb/gVHI0XLCYx9mWRmex8qLYxvyenYmz4iVng24cF3gSDiWn07ropZGM4i2vb6N1r6vl0fWI/iW3wGpmAjPOy+Ti8rTR/DV+djS4StlV3BaYjxKmyBH4j1O3/LE9cjODZYbUvk6GoMOY1EnyNIZBxE0j/BagrZXpcmJJqwN36Aa81dpM37I6GRc1Hzjtt4LMlBcNRc0r+fhG/pWQTGv9GrmjbDkU+05GqixVchRcqwtX6DHF6KFKsEtQUxqYFkR3cPIpF5CLprIJp3hGUWvBUB5ydMJZvwoNtIn/cH7A1vo/ZSASiFlmCvfYVY/0tTMvcUxArPwbHhn3jKrqYl4yCQHDt7SlskFbT2RPQ4zvVPksj6U+/tefQ4vtKpyOEVBMa+1BGwhEQT/oV/RQ4ushotFk5HSLbiW3ImSvOnxPNPJDRkVvcPXtPAu+x85FApwbEvbd4ixNBwr7kdV+V94B9J67h30T3DwNTxLr8QU3QQKzy7+zkbSauQee3diIkGkv6JBEc+bqnhumkpYipZxAtOIZ77V/wLJuNdfgG6eyCab9zGW+EZRnjofXiXX4B79e1Etia9KgjonqGb7TVlZ3tp2wGtLbT2PmFSrKp3bzBNPGVXY9oyiG7Fl5kUezCijfCQv5O24Ghc6x4mWjJjZ89oi6SC1h6IveFtxGQzsd56C5om3mXnorR9Q3DkkySzDgVAjNfiX3AkUqya4NgXSWQfhhirxL9wMlK0omNV1G0qyzTxlF2Fo/4NwoP+tln6QUg041tyOkrLF8QKTsP528fQWzXrPStnoLR8aXXUdfbr8tBKw3t4Vl2PFKsgmbYvgdHPdr/S6wrJTXDMs6R/91vcZdcRmLi5P2G84GTkwDxclfdiCgLRATfugjl/AxMR6Frt+HOUhrdQWr8mNPTebS8wT7HHkcw8CLXP0bgq7iGeNwXDWbizp9QjKcn7Hohjw7Pozv69thxyrZ3ZHlhu60iViWod/vmHI8U3EBj3Oonsw6yGgT/8HlFtIDD+bUug0UPAcq++1TLnLbqYWNHFHS9JkXLSfjgEW+v/ERz+GOHhD4HsBNPEteZ2nOvnEi26mHjBKZ0OK0XK8S34K/5F0zBFB4Gxr/ScmuwBU8kiVnQRSts3yMFFnV4PD7ufWP4puCvuwb/gGOTAgq0+x5YnYSDGa9tl7Z9ja/nKcpXvhVuBFClHwEDvxZ6lkAzgKbuWpHc08YLTtzg+xf8W4cF3AAbuNbfv7KlskdRKaw9DipSjtP6XyMCbemVMqzR+iHvtncTzphIrugQAIdmCf8ExSGodbePfREvbBzlYin/B0Ziik8DE99E9Q7o/qGniXn0Lrsr7iRWcYcnl24ObreW/+BadBIJM217vb+JZaOAuvxHXuoeI5Z/SuSGhHsdVeT+uinsxJQfhQXdYK8l2Gf6mCFoQqf3BrzuLerSRiudNwbPqOmzNn6L5xvzsQBLh4Q+jeUfiXnMn6T8ciOYZiZp9OMn0fdG8Y7fOokqPIoeXIQdLkUOLrT+RVV12KtacJcT6X0y87xndHk5pd+ZIpm25nMG95m+Iai3BMc/tES3XU2xfDGc/YoXn4lz3ENGiC9G9o3b2lLpll/vpnTVrFl988QW1tbW4XC4mTZrEjBkzSE/fmM4YMmQIdrsdSdq4Qf7SSy8xZIj1IDUMgwceeIDXXnuNWCzG+PHjue222ygo6F3L9d0ZR81zmIJEPP+kLY4VY1V4l55D0juG0LAHrMCix/GXTkGKrCYw/nW0tH2QwmX4FxyDKXktVwhn/+4Pahp4yq7CWf04sYIzLOFFe8Cy176Md9n56K4BBMa9svE4egy+PgNX9WvE+k4nPPSezQKurfk/eFdchhSrJJ47mfDguzqJCKTQUhx1r6A0foQc2ei4YQo21D5HEh46C1PJ7jxdJQvNNRBbcCGxrq5HEIj3Oxc1bwr2uldw1L6Kq+IehAorJWco2WiuQRjOIgx7Dobst/bTTANBDyEmmmBZLemtK5FilQjtqTzDloHmHU2s4BR01yAMR0GHwvEnSbp3xaXorsFWR+NOEzdx1L5I0ju22xRqx/1r+QpH9RPEC8/qddfnFP97RIsvt0QZ5TcRGP/mzp5Ot+xyQUuSJGbNmsWgQYMIBoPMmDGDa6+9ljlz5mw27oknnmDvvffu8hhz587lvffe47nnniMnJ4e7776bc889l7fffhtR3IMzoqaOvfZlEpmHYthztzjWt3Q6mDrB0f+0XBFME+/yC7C1fUdw1DMkM35npQkX/sVaGU14u+eAZWh4V1yEo+Z5ov0uJDL4jo6A5ax8CE/5DSTSDyA45nlMm1V3JIWX4116DoQsQ9tY0YUd7xFj1bjLb8RR/waaaxBtE97dPOVpaNgb3sZZ9Si2wI+YgkwyfX8iuZPRPENBkLG1/Bfn+qeQ1FraJn7U9bSdRYjx6p5vly2NeOHZxAvPRkgGkEOlyMHFSJGVSNG12Fq/RlTrEcyNNlAmgrV35ClC841FzTsezTsKzTsWw9G329RqMuN3xPOnkvHtPrjLr6dt7y87jbHUicsIDXu4x3kLyQDeZeehu0oID7q1x7Ep/rcxbelEi2fgKb8eW/MXJDMP3NlT6pJdLmhdfvnlHX/PzMzk5JNP5oorrtiqY7z00ktMnz6dkhLLnWDGjBnst99+zJ8/n4kTJ27X+e5K2Fq+QFJriAy+c4tjnZUPWMFp5OMdLg7OdQ/jqLMsjdTcY8FQ8S2ahphooW3iRz3Xe+lxSxbf+D6RkmuJllxjPZTb97ZclfcRzzmW0MjHLTsp08Cx/ik8Zddgyj6Y9DYx+4HWsQwVZ9Uc3GvuAkzreP0v2yjHNZI4al/EVXEvUqwCzTWA8JCZxHOP75SuS2QfhmHPxVN+I2KsqstViWHLwBZd25tbDIBp85PM+F3nPUPTBENFMOIgSJiSCwSJ7Gwvoa1VD0ouEhkHoTR+0MUETFxr7kBXcohvKtfvYpxnxaWI6gba9voIJPfWzSHF/xyxwrNwVs/BXX4TbRlf/Gq977aGXS5o/Zxvv/2WoUM7W9VcccUVJJNJ8vPzmTp1Kscfb5m0hkIhNmzYwMiRIzvG+nw+ioqKWLFixVYFrczMra+f2ZFkZ3t7HrDyebBn4hs+BaSuJd8AtC6CtXdCv+PxjZpuBZeGr2H1zVA4GffEW3ALAsy7FgI/wv6vkd6vixTVTyQC8N/joPFLmPAw7iEX0vF4XHwLVN4HA8/BsdejOEQJItXw7cnQ8CXk/RFh32fBkU02wPp3YMHlEF4DBUfCXg/jdhdZxzM0qHwOltwGkQrImAB73Yvc92g8gki3n5Y5CcohU66G7BGdX/dmQWtwy/f3F7Btx24Cu6/ze6tehbZvYK9Hyc7todZq9eNQ/zqMuYP0QYdsw/l7z468d7sCu9P1/bLnlhfG3YH07SlkRz+A/lvntvJrsEsHrQ8++IBXX32V5557brP/f+aZZxg3bhyiKPLdd99x5ZVXomka06ZNIxwOA1ag2hSv19vxWm9pbg5jGLtGz5nsbC+NPXxbFxJNZK5/m1jh2URaEkDXbuUYGmk/nIokp9NSPBOzKYyQbCP9u6ng6EfrwAcwm8IojR/iL3/USvM5/wDdnFtINONfcCxyeAmhkU+gZpzQMdax/im8K24lln8S4f4zEerrcFbNxrnuETB1IsMfsfbeQiLZscUkfrgcpfk/aO6hhMe9QTLr9xAFIgHs9W/iWnMncrScpHcs0bEvk8j6kxVwm3p2qrbXLscHtKhZ6F1ch0vz4lJbaK5Z36Wbxy9lS59dl2hhsuo+I543hfAm7xWSAdLnXYbpGUWrf2q3n4scLCXtx0tIZh5MIPuCbsdtD7bp+nYjdoXr25qg+YufW+6jSPeMQlh4HS3OQ7utedyR9HS9u2zQev/997nllluYPXs2I0Zs/u143303ypsnTZrEaaedxjvvvMO0adPweKxvGaHQ5j9koVCo47U9EUfdqwhmcosCDGf1HGyhRQRG/6sjleYpuwpRraVt4ieYss+SR7c3cowMuqXbYwlqPWnzj0KKrSU45oXNvPqkSDmesmtJZB5MZMhM7LUv4i6/FSlRh5p9OOHBd2C4BiCoDbjX3Ak1zyBLPsKD7yRWeI6lCjQNlIa3ca+5GzmyAs09jMDo50j0OXKraqYcda+h2wu6NQVNZB+Oq+IePCsutpwiJDeCHrEMfrUggh62nN9FGVP2Y9hz0Z39d2itk3PDMwh6hHj+tM3+31N2FWKijrYx/+pWBSgkmvAtOhFDySI48oldMsWTYhdGEAkPupW0hcfiqHm+RwXrzmCXDFqvvvoqs2bNYs6cOUyYMGGL40VRxGyva/F6vRQUFLB06VJGjbJkm6FQiKqqKoYNG7ZD573TME0cG/5F0jt2Y+PFLhDjNbjX3IGa9ScSfY4GfmoQ+RKR4qs6lGWuNXcgqvW0jXmh23YmQrKFtAVHI8XWERj3Wqf9HVvrVwhGDKX5MzL/OxhBj5D0jiU49gXrPHoU19qZuCofACMOgy+iJe9yKxAYSew1L+CqvB85UobmHkxw1FOW00UvLJU2RW77DqX5P0RKruv2vZp/PNGSq3CvvRtHfe9VU7qSg+4daYkr3EMwHEUYSgYINjASiFoAIdkMgTDO1iYQRHRXCYmM34Hk6va4QqIRV8UsEumT0Pwb09n2mhdx1L7Y/ll1k+bW4/hLpyImGmmb+FGXiskUKbZEMvMQkv6JuCrutb4Ib21box3ILhe0/vWvf/Hoo4/y5JNPdgSdTVm2bBmGYTBkyBBEUeT777/n6aef5oILLugYM2XKFJ588kn22WcfcnJymDVrFv379+9VANwdsbX9n6UkG/5oj+Pc5TeAqREeMtNaqWhhPCsvR3MP7bBvkULLcK5/gnjf09H83dwvI4m/dKolix/3apdFzPG8KQjJAPaGdyzlXM5fSKbvD5g4NjyLa+1dSPH1qH2OIjLwZjL6j4faGpxVj+Fc9xhSvArNM5LgqKdRc47Z6mAFgB61ZOOOvkT7X9Tj0OiA61D7HG3J0vUopuTGtPkxZF+7oEJGMJIIWgBRrUWKrkEOL0cOLcXZ8thmqsGu2HSNn/SOoW2fr7oeaJp4V1yBoIUt6X87Umgx3hWXkUj7rSVy6fK9Bt5l52ELfE9g9D83s6ZKkWKrEASiJVfjXzgZR+1LXRb67yx2uaB1xx13IMsyp5yy+U16//33yc/Pp76+nlmzZlFXV4ckSeTn53PppZcyderGDcPp06cTCoWYNm0asViMCRMmMHv27D1W7u5Y/ySG7Cee+9dux8it3+Koe41I8YyO/lTutXcjxatpnfhxR22Rd8UlmHIakQE3dHss95rbsbV9a1k+ZR7U9SDJRaz4MmLFl1n/Nk1sLV/gWXUDcngJSd8EQiMeJ5mxP2K8FkqvJWPVbEQtQDJtX8JDZ23cs9oWTBPv8ouRwisIjHu9V8o53Tuix5VqtxgaUqwSMV6NoAUQDBVTVDBlP6Ytk/S8YpoCAhgJPGUzcNS9ZolKukjvOar/gb3hLcIDb+3wLxTUevylUzBs6YRGP911WtA0ca+6Hkf964QH3koi1Y04xS8kkXkommcUjurHU0GrJ8rKynp8/eCDD+bggw/ucYwoilxxxRVbLZXfHRESzdjr3yHe97TuU06mgWfVNej2AqLFVkmBFF6Os+pRYvmndLTncKx/ClvgB4Ij5nTr9CAkmnGue5h4/ombu6P3gByYj7v8RpTWr9Ed/QiOegY15y9IkRV4l56Dve41QCeZfRTR/hd1n/rqLaaJu/wGHHWvEBlwgyXo2JGIMrp7YPeN9FxezEgIjCRSbF1Hb6yfozR+hGfVtahZfyLWv92dRAviXzh5Y9lBN/V3roq/46p6lGjhuVvl7J8iRbcIArG+p+JdeSVysLTrlkI7gV0uaKXYOhwbnkEwE8T6ntntGHvd69iCCwmOmGOtOEwD74pLMWU/kfaCUym8Anf5zSQyDkLN617mam94D8HUenZfb0cOLsJVcQ/2hrcxlGxCQ/5OvO/pyMFSfKUnYG/6N6boItb3DFzjriIY2w77L6aBe9UNuKoeIVZ4NtHiXcS12lDxLr8IW2AewVHPdFotya3f4ltyGppnJKFRT1riCT2Cb+EJyOFlBMa+3Nlmqh3nukdwr7mDeN5UIkPu3gWNfVPsrqi5x+FZdQOOmmcJp4JWil+MoeGsnksi40CrpUdX6FHcq28m6R2LmncC0L6iavuO4IjZmEqm1WqkdCqm5CI0/JEeH3rmT6s5o5s9HNNEbvsO17qHsDe+jyH7iRTPINb/EuTgYvwLJ6O0fIlhyyBSci2xwrMxlUxcHi/EfqGsWI/hXXY+jvrXrb5fQ/6+azzAwxWk/XgCtsA8IiXXWYXbm2Br+Rp/6XHo9nyC417FlL2gR/AvPAFb27eERs3tcN7/Oc51j+JZdR3xnL9Ye5oppWCK7YhpSyeRdShK40cw5J5d4vcpFbR2Y5SmfyOpGwgPndXtGFflg0jx9YRGzgVBsqTo5Te2r6imWSrAH49EilfTNuG9LbYlSGYcgCm68C06mciQu0lkHQqYSKFlKM2fYq9/Azm6xgpWJdcR63cecngpvtKpKK1foSs5lqy97+nb1aFBjK7Ft/gUbKHFhAfeaqXIdvIvmBivwVV5L2x4BllQCIx+lkTO0ZuNsde9jnfpOeiuYgIT3sWw51rNOEuPR277gdDIf6DmTu7y+M7KB/CU34Ta52jr800Z4abYASTSJ2FveBdR3WDZj+1kUj/luzHO6sfR7fmWYKELxFglrsr7ieccSzJ9P9DjeJdOxxRshEY8hqjW4CudihQps9JPvWjvYdhzaf3NJ/gWn4JvyWmbvWYiksyYRLD/Fag5xyCHl+FbfApKy+dWsBoyk1jBaZbP4fbCNLHXvYxn5QxAIDD2lc3qxX5tBLUBe9NHKI0foDR9Ahgw4Axa8i7HcORvHGjquNbOxL32bqsf2NgXMW0ZiPEN+BcehxQpIzj6GRI5x3Q+SXsLF3fFLOI5f223xursdp8ixfZA91ruQlJ4ZSpopdh25OBClJYvCA+6rVs1mXfF5ZiCbBnXmibeFZdiCy4kMOZFBC2Mf+GxCMk2gmOe2yqxgu4dReu+P2Br+xZb2/eYooLuGkAybV9MJRO59Vv8i09Caf4MQ8m2jHALz+yxNmlbENR6vCuvwN7wDkn/bwiOmtuzoe+OwDSQQ0uwNf8He+N72AI/AqA7+hIrnE6s8Bwyi0ZjbOpqoTbgW3oWSsvnxPOmERr+IIh25OAifKXHI2hhAuNeIZnZhfWSqeNZeSXO9U8Syz+F8PAHt60cIEWKXqLb8wAQE407eSYWqaC1m+Jc9wiG5O22oZ9jw9MozZ8SGvJ3DEcBrjV34Kh9gUjJtYBA+g8HWr2x9nofzTcWQQtha/4UpeW/Vq2SFsaUvWjuoSTT9yWRefDm6TzRRjJjEsmMSda/jQT2hndxVs3GFvgBw5ZJeNDfiBVO3/5GraaBY/3TuFffiqBH29OBF/+qD28pXIZjwzPY699EUmsASPrGERlwA2r2YeiekZ3Tk6aJve41PGVXIugxQsMetqTEgoC97jW8yy7AUDJpm/hx19J7PYpvyXTsje8R7X8ZkYG37PQUaIr/AUTLqFow4jt5IhapoLUbIsaqsNe/aYkYuvDKk0JLOyyU4oVn46x8GPfamcTyTgTAt2gqmm8swdEvIsXW4F18GkrTx4h6GEPyorsHWnZOiSacrXNxVT2CKdpJpu1HMn0/NO9oDFsGgqEixSqxtX6D0vghotaG7iwmNGQW8YKTt/vKCiyVnWfVNdiCC0mkTyI87H509yAABC2E0vg+StMnyOFlJLL+RLTogu3nCmEksde/ZX0haP0aU1BIZB1KpM9NJDMP7rEdjBReiWfVNSjNn7XXqM2xGmkaCdyrbsRVNdtKE45+FtPep9P7RbUOX+kU5OBCS4XZ79ztc00pUmyBn5qUmtszrf8LSAWt3RD3mjtBkKzeUz9DSLbgXzQNw5ZGaPhsXJX34V59G/Hsw5HUDThrnyeeN4V47vH4lp6Gre07DFs6au5xqHknkPT/ZvN0o5HE1vYtSuOHKC1f4FpzJwKbm3EatkwSWX8gnjeFZObBO0TBJkbX4l59K476Ny2V3cgnUHOPB0FAbvse5/q52OvfQTBiGEofNPdgXJX3YWv9mrbffPrLTq5HcGx4Dte6h5Di1ejOYsIDbyZecMoWA6IYrYDvHyZ9zVOYstfa1+t7FogyYnQNviVnYgsuIFp4LpHBt3dplyMH5uNbdCKiFiA45kUSfQ7/ZdeTIsVWIMbWAWA4ehZp/VqkgtZuhhRahr32RWJFF3XeFNWj+BeegBivoW3Cuzgr78dVPYdE+oHYAvMRky1Eiq/G1vZ/pC08FkPpQ2jofcTzT+xeHLFJGjCCtZqRIisRkm0gKuiOvhjOkh2WphLVOlxrZ+LY8E8QlPbeWpeAaEdpfA/XukewtX2LIfuI508jnjfFKk4WRNyrrse17mEw9W1KHQrJAM7qOTirHkNMtpL070146D0ksv7Yc2A2jfbmk0+iNLwLomzVjJVcbRVtmwaO6ifwlN+EKdi6VBX+hL3G6mBsKLm0TvykY1M8RYpfCym6BgC9p356vyKpoLU7YZp4Vl2HKfs6nC06MBL4Fp+OHPiB4MjHcVXNxt7wFgn/PtjavkZ3FqGm7Yur8h5MOZ3wkLuJFZyOYKjYWr9GjpYjqo2AjmHLQncPsoQVts3dG0zZ+8sdK3qBkGjGte5BnFWPg5kgXnAa0ZKrMGzpOGpfwVl5H3J0DbqjX7sq8ZROe2em3N6exjRhK2KqkGi0WqhUz0XU2lCz/kS0+HI0/97dB2c9aq1Imz7G3vAeUrwaw5ZOrP/FuMbOIBKxWi1IkXI8yy9GafuGRObBhIY/iuEo6Hw8I4Fn1bU4q58gkT6J4OhnMJWs3l9EihTbCSm6GkPyYCg99G77FUkFrd0Ie83zKC2fExp6L6YtY+MLRhLf4tOwN31IeODNuNY9hhwqRXMNRgl8R8K3F3J0NfbGd4n3PYNo4XkoLZ/jX/AXbG3fdqT7TEECpA7zV1OQSGQeSrxwOonMQ7dqNSXGa7E3vEki8/fo7sG9fp+QDOCsehTnukcQ9Ahq7nFEBlyHofTBuf5pnFWPIKm1JL1jCIz+J4nsI7uvT2p3/u9tulKMVeOsegTn+mfAiJPo82dDYYkGAAAgAElEQVSixVd1dqIwDaRIOXJoIXKwFFtgHnKwFMFMYooOEhkHEhl4M2qfI0Fy4nJ5EQI1uCruwbnu0fYi7kct9+wu7qkYq8K35AxsgR+IFl1sCS5SNVgpdhJytBzdNWiXEf2kfhN2F4LleMquIpH2W+KbWjbpMXyLTsLe/AnRfhfirJqDmGzFlP1I0bVozhKU4I8k/b8hWnQh9oZ3yfj2Nwim1u7ufhXJ9P3RPCMwbZkgCAjJAHJoCUrzJ9hrXsS/cDJJ33iixVeSyD682yAgxmvaVxrvoDRb+0jRooutvZotoUVxVtyPq/J+a3XT52giA27AULLaU3T/QNTaSGT8jtCIx0hmHLzFX6Kf3DuEZGu3XoodDh5Vs1Ea3wVAzT2BaPHlG4OtoSEH56O0fIGt9f+Qg/MRtaD1dtGJ5htDrOgCEukHWPVwm674DBVWPUvG4lsQE43E86YRHnQrpr3rb61K/Tt4V1wEhmZ5NP7MPSNFil8bKbKaZNreO3saHaSC1u6AFoZ5k0G0ERq1samfkGzFt+gkbK1fE8s/GWf1k5iiDcwEppiGINoQk81Eiq9CDi3Bv/gUDMlLrPBs4vkndi3LBkybn2TG/iQz9icy4HocNS/iqrwX/6JpaM4S4n3PIJkxyXJv0ELIwVIcG55BabXabeibbNhqvvE9X5uh4ah5Dr6eiSe2ATXrD0QHXG+trNY9jHP9MwhGFDX7z0SLL0PzjkMOL0VpeAvBSKL5xnWoBzvdtvbWHPb6t4gXbu7NKEXKURrexVH3KnJ4GYacRqzoImJ9z7JcQYwkSuNH2BveQmn8wPoigIDuGYmaexxJ/15o3rHo7iFdr4L0qNWCZd2DEF+PlrYfkbEvd/Qs6+oz9pRdjbPmWZLecYRGPdm9AW+KFL8iYnw9uvP4nT2NDlJBa1fHNPAtOx8CSwmOfbVDfCGo9aQtOAYpXEYi+wicNc9iSD5EPYhhy0JKNKCmHwCyD3fF39u9/q4h1u+CrWspLyrE+55KPP9E7A1v4ax+HE9557Ylur2AyIAbSaTvj6vqEaR4NWr2n1Gzu1G6mSZK08e4y29AjpRB5j60jZiLbs/FVXE/jtoXAQM193ii/c5BDq/EVXEftpYvEfXwZoeK500jNOLRTmKLZNq+JNIPwFN2JUrTR+iugYhqLbbAj0hxSxGV9P+G0LAHiOedAJIbKbQUd9kjOGpfQUw2Y8h+Etl/IpF1GInMAzdPy3aBVb/1Txy1z3eIN6R9nyIgdb8fJrd9h3fpuUixCiLFVxItuTblcJFi18A0ETCAXcfTMhW0dnHc5Tdib3gLxs3qME2VwivxL/gLYqIFzTcOe+N7mIKCYMQwBRsYKmr2kShNH4EgECm+ilj/izcKE7YFUUbNnYyaOxkxVoktsABBa8MU7eie4Wiekdhav8a/+GTERIPlL9jvgi4f1FJoGZ5V16G0fI7mLCEw5gX8BWNwLLjValMi2ogXnEoi6/cojR+TNv8oRC2I7uiLmns8yYz90dxDAQFH7Uu41j1IMn2/zj1/RJng2BdxrbnbSlm2/BdDyULzjSPa/yISWYdZqyotjKPudRzrn8YWnG/VX2UfTjx/KonMQ3ru2mqaSJGVKE0fYa9/C1twAaYgo/Y5iljhOWjp+5Kd7YXGLsyA9QjutTNxVj6E4SgksNcHJNN/u+2fUYoU2xtBQLfnI8Uqd/ZMOhDMn/rUp+hEc3MYw9h5t8dZ+RCe8huIFZ6Nc/85NDaFsbV8hW/xSZimCJILUd0AGJiSB1EPk/SOQdQCSLFK4rnHExl0i7U6M03k0CJLKRgsRYpXg6lbNVaZB6HmTemkFOwtYnQt7rV3Y699Gd09hNDIf3TZNVdINONecweO9U9ZCsgB15JIOwBX5T046t/ElFzECk5Dd5bgqH3BCiCiEzXnaOIFp5FM27dLl4m0eYcixtfT8ttSkBy9nrccXGS5WtS+gqiH0NzDrFVl3pRuV1SCFkQKLcMWWojcNg9b6zdIiTrAcsRQc/5KPO+EzfassrO9NP4saNmaP7eaVMbXESs4lcjgOy13992Qrq5vT2JXuL7s7N7/bGzv55Z38akoLV/SfMDyHWIY0BU9XW9qpbWL4mhPw8VzjiU8ZCZOQUCpfxPfkrMwlCzERDPoQQQMTNGOoKskvWOxhUrRXANpG/8WycyDEePrca25G0fN8x0pMd3RF93ZH0QHUqQMb9OHuCofJDj66Y6GkL3CNHDUPI9n5ZUAxIouIjLg2s62TUYSx/onca+5E0EPES88k1jeibiqHsNddo31izDkEqKqiKP2RSS1Fs01iNCQWah5J/QcTAWByMAbSZt/JM4NTxHrd36PUxbVOux1r2OvfRFbaDGm6EDNOZpY3zM7SdrFeA1yYB62YClSeClyeAVSvKrjdd2eRzJjf6LpvyORdUivzEQFtR5P+Y04al9Ccw2gba8PU6urFLs08cKzcdS/iavyIaIDrtnZ00kFrV0RR/UTeFdeiZp1GKGRT1h7NSvuxb/4SnR7AZK6ARMZMAAwbFkIRhw5vIRI8VVES65Cilr2TPaGtxFMnUTmwURKriaZeQiGI2+z88mBefiWnIl/0Uk077+kVy7solqHd+k5KC2fk0j7LaFRT3U6LoCt+T94yq5BjpSRyDiQaP8rsde/Qfq8Q0BQiPc9HRMR15q5uLUwicxDCA97yGp50kupejJ9EomMg3CX34yJaKkrf9oT0mOWErL1vyiNHyEHfkDAtMQOQ+9BzT0O05YOWMIWpflzbM2fobT+tyMlYgo2dPdgkv6JxAtORfOORPOO2dy1fUsYCZzVT+BaOxNBj1p7V8Uztq/jfYoUO4Bk2n7Ec4/HtfZuNN8YEtmH7dT5pNKDPbAz0oOO6sc7AlZwzL8ACfeqa3FV/2OTgCWCaEMwVDT3UOTISjTPcEIj5mDY0nCvvh173WuYkpt439OIFZ61RfdzW+s3pP14GMERs1HzT+x5bPMXeJeejagFCA++k3jf0zsFGClSbu3HNX6A7iwmMuB65NAynNVzwNSI504GU8dR/wZgIvQ7gZa8i9C9IxDUBpTWr5FDpYiJRmuPKfMQEtl/BNHe5ZyEZAu+xaehtHyBKbnR7bkIhoqo1iKYOgBJ7xgS2Yej5v61Q84uJAMoje/hqHsVW8uXCKaOIaeRTN+fZPpvSabtjeYd1e15t4hpkp38Cu2Hi5Fja0lkHkx4yKxuFY+7I7tC+mxHsitc385MDwKgR0ibdzhyeDHhYQ923j/ezqTSg7sJzsqH8ZRfj5p9BMHRzyAYCXyLT7Vqnuw57ftXgCCDaaIrOUiRMqL9LiRSMgNX1WO4Ku4HQSRWdBHR/pe292iqxtb8GZgGmndUlzVCyfa0oBSr7n6CpomzejaesmvQXINoHf9mJzdyIdGMa+1MnOvnYopOwgNuAlHBU3YVYrIFNftwTEHBUfcqIBLvezrRokvIzPRiX/o4yrLzsIVKrdMJNgx7DoIWwrnhaZLesQTHvtzlis60ZRAY/zZK8yfYmj5FTDSA5ES356N5R5NM32+jT6CRsOTutS+hNH2MYKjozv7Eii5BzT4MzTdhuxTz2lq+xL3mDmj7DlyDCIx9lUTWH3aZIs0UKXqN5Caw13v4Fp+Md/mF2Fq+JDzk793XP+5AUkFrV8A02xsC3mm1TR85FzFRj3/h8Ujh5RiSH1FtQMBqtGhKXgQ9hIBJYMJ7YGpkfP+7dvHFZCID/4aoVuNefRtK44cdQgGwAoGaO5nQsAc2S00JerT9L908UA0Nz4qLcdY8ZwXVUU9uvimrR3FWzcZV+QCCFrLSaL5xuCrvQ4pVkkjbF0PJwd74vmX223c6saILkcPLrD2x5o9xmSaafyKRgTeRyDiofYWjgKFhb3gHz/IL8ZUeR9vEj7veEBYEEll/sAJDF/dYDszHXvcKjtpXEZNNGEofYn3PQM2djObba/sEE9PE1vo1rsp7UZo/Q7cXwMTZtPqO61mFmCLFLo4pewmMfRVXxb24Kv6O0vIlkYE3Wd6lv2JboFTQ2tmYJu7Vt+GqvLe9IeAjSJEy/KXHISSaQbAh6BtTE4ajACleTSLjQELDHsBV+RDODU+1iy/eRUw2Wa3aw0swJA+JrEOJpk+yimABpeEdnNX/wLClERkys+O4ctt3ACS7KAYWtBDeJWdgb/rI2jMbcO3GH1IjiaPmWVxrZyKptahZh6H2OQrn+idwbngazT2UeJ+jsDd9BKZOPP8Uov0vxN70CWk/HoEUX4eu5MDwa2hJn4bh7Nf5Hokyau6xmLIH38Lj8C47v3ft5dvl6Pb6t7DXvowcW7uJnH0aiczfbz97JFNHafwAV8U92IIL25tf3k6s8Gyyc7O7lrynSLG7IdqIDrgGtc8ReFdcinf5hTjXPWp90cw+bId0ePg5qaC1MzFN3GVX46qeQ6zgDMLD7sPW9i2+0hOATZquCRKYmpUOjFcT7X85atafSFtwDGKsimjRxVYR7arrkMNL0NyDCQ17yNo3kj2bnTKZsT9SdA1Ky3+JbPL/jprnMGzpJNP332y8kGzBv/A45OACyxG+cHr73A3sda/hXnMHUqyCpH9vIgOsmjLf8vPQ7Xmo2X/G1vIl9kgZav40ooXnYG94h/QfDrEKb9P2ITz4dhLZh5Odk7FZd9+uSGT9gcigv+EpvwEx2UJ48O3trh5ix/0UVUvxp7R+hdL0KVKsAhOBZMYkQsVXoPY5cpul/V0hxtdbxcQ1L7S3LelPaNiDxPOmpEQWKfZYdO8o2iZ+itLwDu7Vt+BfNBXNPZhY0SXE847f9j3gXpAKWjsL08Cz4lKcG54h2u98IoPvQml8H9/i0zAlN6LWatnYCjIggM2HoEcJjHkJKbqatPmHYdgLCIx5AWftS6StOw7d2Z/gyCdRc/9qPcjbBQidTq1kI4QWd/xbiqzG3vAuscJzNnvQivFa/AuORIpWEhz9LxJ9jmx3svg37tW3IYeXoXlGERz2MErrV3iXX4Ap+1Czj0Bum4e98T3UPkcSLTwPe/PHpM/7ExgxEtlHEO1/Cdo2+JlZRdJ+PKuuIeO7/THkNAx7DpgGYqJ+E09AF4mMA4gWXUgi+89d7oNtK0KiCaXx3zjqX8fW/Dlgksw4kPDguyxvxpS5bYr/BQSBRM7RJLKPwF7/Js51D+JdfgGu1X8j1u9c4n3P2K5fEH8i9du1MzB1vMsvxFHzvCV9HnAj9toX8S47H1NOQ9RarHGCjCk6rRWXI5fAsMdxVd6LveFd1OyjSGQegm/ZuQhGnMiAG4jlTcVR/xZp8/6AFF6OoEeJF55JePCdm33zkYML0T3D2+di4i6/EUQ70f6XdowRoxWkLTgaIdFEYPxb1gottBjPqutRWr5Ec5YQGnIvcmgp3pWXgWAjkfUH5NAy7I3vk0zbl1DxHJSWz0lbeCwYCdTcY4kWX2117P0FxPueitrnzyiNH2IL/IigtVqXohyE5h6M5h1rFTdvLyskQ0UOlqK0fInS9BG2wDwAdEc/osVXEC84eYvqzBQp9lhEGTXvONTcydhavsBV+QCe1bfgqriHeMFpxIrO71UNY29JBa1fG1PHu/QcHHWvWA0NS67Bsd6qyzLkjI6AZSJgyD6kZAuJ9EkoE2fh/fpEpFgF4QE3IYeX4V15idWYcOAtOOpeIfObcQhmgqR3DPH8kxC1IM7qJ0CPER7xGAByYAFyZAWhvqcDoDS+h73xfcKDbutQFUqRcvzzj0QwYgQmvI3uGoRnxeWWk4UtjfDAmxDVejzl14Gpk8g4EClWhb3pI5LeMYQH344tWIpv8SkIehQ1bwrR4iu3qwGsqWSiFpyEWnDSdjsmpoEYr7KKiMMrkSNlSOHlyOHlHe1akr5xRAbcQCLrD2jeMSklYIoUPyEIJDMPIpB5EFJosbXfXj0bZ/Uc1NzJRIsu6aQ23hZSQevXxNDwLjsHR92rRAbeRLT4yg6rJkPOQOgIWFYLeynZRDxvCvHc41E+/yMiEqFhD+OquAcpvo5IyXWYokzawr+CmSRecAqxwnPQPUM7Tikm6rC1iywAXBWzMCQvat5UxHgN3uUXo3lGEet3IWD5AqYtOAqAtgkfIMWr8JWeiJhoIF5wKobkwV1xr9VvKuN3iIlG7M2forkGEhz+CJJaj3fFJQhaEDXnWKIlV282n10FIdGMHCpFDi1BDi9rD1KrEIxYxxjdnofuHkqs33kk035jNcVMNWJMkWKL6N7RhEbNJTLwJpxVj+Hc8E8ctS+RyPw90f6Xkkw/YJu/8KWC1q+FqeNdfh6OulcJD7yFWPHlOCvuxbP6Vgw5HUFr7Wiua9iykZKNRPtfiuYejr/0ePANJZJ3ZvuKzEdo+Gxc6x5GDi9Bzf4z4cF3YLiKf3ZOEylagdauHLQ1/8daVQ28GVNy41s0DcGIExz9NIgycnAh/gXHYIpOAmNfxln9D5wbnkHzjCCadxzOmucQk60k0g9ASAawN3+G7uhLaOgDCFoQT/mNiMlW1Kw/ERl0y8YU5K6AoWELfI/S+G+Upo+QIys7XtLtBeieocTS90d3D0HzDEV3D9s6N/wUKVJ0wnD2IzLkbqIlV+Fc/xTOqtmkzf+zlbEYeAvJzIO2+pipoPVrYBrWHlbty0QG3tRFwGrr6B6sK32QEg2EB90Ggg3fsrNJpB2AUvh7vEsus6yEco/Hu+ISTMlFYMxLJPp03f5Dafq31e6i5CqEZADvsgvR3EOI9Tsfd/n1KK1fERwxB909GDkwD/+CYzFlP6Gh9+BbcgZSdDXxPscgh5bgXvcwSe9YdGcJSutX6PY8QkP+DoaGq8KSuycyDyYy4EY0/4Qe74WoWnVjhpK5Q1VG6HHsjR+gNLyD0vwZotaGKdhIpu9POG8Kmm88mm/0FtuNpEiR4pdh2jKIFl9JtN+FOGpfxFV5P2kLjkbNPpzw4DsxXCW9PlYqaO1oTBPPyiss0UXJdRtTgl0GrBykRD2hofciJltwr7kJNfsodEc+ypKbiff5C4YjH2/ZDBLp+1t+f/bcrs+rx3Cvug7dWYyacxy+pWcgJupoG/OJ9UNTNZtov/NQ86dha/0/fAuPw1QyiRaeYzWLlP0k0yfhaHgL3dGPpH8itsA8q/5o4K2Ysg9X5f1I8SrLe3DkEyQzJnV5/VKkDKXp3yjNn2ELzEPQLbG9IXlI9DmCaPHVkN3ZFX6bMFSU5i9QGt7G3vAOohbEULJR+/yZRNYfSWYevNu6qadIsdsjOYj3PZ143lScVY/hqriH9O8OIDRqbq89DVNBa0dimrjLb8K5/kmi/S8jWnI1jqp/bLKH1bpJwMpFStQRGvYgolqDe+1M4rlTMUUbruo5MOgCCGzAVfUosb7TCQ+Z2aM6zr36FuToGtrGv4Oz6mHsDe8QHnwnYqIZz8orUDMPJTLoDmwtX+JfeAK6oy/JjEl4V12L5h6KqNZja/s/kr5xyMFShGQLkZLr0O19cFfchxSvIukbR2j4QyQzD+48AT2Ovf51nFWzsbXL6zXPCOL5J6K5h4EgIQcXWI7r9W+D9iD4pmxbntvQsLV+jb3+dex1byDqIQzJS6LPkcTzTrCC6a9YsZ8iRYotIDmIFV+OmnscvkUn4iudQmjkE6h5W+6QvMca5hqGwQMPPMBrr71GLBZj/Pjx3HbbbRQUFPT6GL/UeNJVcQ/u1bcRKzyL8JB7sNe+gG/ZeRhyJoLW3LGHpdvzkNRaQsMesFZYq28jlmdZozhr/kWk/6W4E+VQ877lslB0UY8Pd3vtq/iWnkm08Fy0tH3wLTmNeO5kYn3PJm3B0WjuoQT2eg9b6zf4Fp+M7ixGt+dib/kCzTUQOboa3VGIoAUQ9AjxgjPQ3ENwVv8DOVpO0juO6MDrSWQe2mkeolqHs2o2jg3/REy2oLmHESs8k0T2ERiOzvdejNfiXXYuSsvnxHP+SmTIXd2vHjdBUBtQmj9BafoUpfk/VupPcqP2ORo15xgSmQft2NTjVrArGK7uSFLX9+vMobfs7D6AW40eJW3+UUjRtbT8diGmzf+/aZg7d+5c3nvvPZ577jlycnK4++67Offcc3n77bcRxR1vNeLY8C/cq28jnns84SGzUBo/xLvsgo49K2hXCdrzkdQawoPvAtPoeI+ppONa9wiR/pcjR1dDw/uEht5PvPDMHs9ra/4C77LzSKTtRyLzYPyLTiSZti+xvmfhL52M7sgnMP41lKZP8C6dju4aDGgoLV+h27KRomvR7X0tq6i036LmHItzw1M41z+B5hlFYPSzJPoc1TlYxSpxrXsEx4Z/gqmRyD6cWN+zSGb8rscAazjyCIx/k+zGR7Evvgl74/uoOX8hkfE7dGcxpuxGMBKIiUakWAVSaDm24I/I4eWAlVJNZB+Omn2Y5TmYcqFIkWL3QnIRLb4Cf+kJyMH5XWduNmGPDVovvfQS06dPp6TE2uCbMWMG++23H/Pnz2fixIk79NxK44d4ll9MIvMQQiNmt/erOg1DydwkYEkY9hwktYZI8VXoziJ8i05EzfoTmncsnvLriBWejWCo2BvegfH3Ec/cQsBq+Qr/oqno7kHEii7Gv/hUNM8wIiXX4S89wXJCn/Au9vb5aZ7hSGqdtcckyFYRsyAh6GEiJdegNH+Bt+wKdGcxwVFPoeYc28lbzOpafBf22ldBkIjnTyPa/7Kt2lhFEGHEdbR4jsBVcR/2hndw1L7Y5VDDlo7mG0849ziSmQejecemaqVSpNjNkX8q2HcWbXnsjp7MziAUCrFhwwZGjhzZ8X8+n4+ioiJWrFixQ4OWHFiAb8kZaN4xBEY/ixSrxF96AobkQko0tlsz2TBs6UhqDbGCU0lkH07aj4ej+cYTKzgF/6KTUPscSdK/d0eazzX0sh5NV5XGD/EtPhXd2Z9I/8vwLTkN3VVCZMAN+BafiCmn0zbhXex1r+MpvxHNMxI5sgpTciAYMQw5DVFrQ808BENOx7V2JqaSRWjYA8TzT+60fyaFV+CquAd7/RsgKMSKLiTW7/yta4z4MwxXCeERjxAe/iBSpBwxvr49kMoYSha6swjTlpUKUilS7CmYBs6q2bgr7iGe81cM55a/7O6RQSscDgNWoNoUr9fb8VpvyMz0bHnQpkRr4Oup4MjG9vv3yRbt8PFUMDXQgoCIICogOZCSrZD3R5y/uRvnR3uDIwvbfo+T9tmhkDYK+2/uw/7RXpC1H67fPgR0k9c2TSh7ABZdCenjkEum459/LqSNRB52NWnfnwquvnDQJ2SuegjK7wP/SOTAUsvPMBkEyYloxKDoROw1H4AehqGXI4y8Ea/iZ7OzBstg2V1Q8S+Q3TD4Yhg+A5czjy6ahWwVm1/fxPY/ewZbsyexO5K6vl2HrX5u7SxaS+GH86D5O8j/M44DXsAhbbl9zx4ZtDwe60MLhTZfmYRCoY7XesNWbWjqMdLmHYGcCNI68VP0oAP/wr9gC1W0m95KlpGqoWOKJoaziLbB/8D335Owxepo2+tD3N9fgqwnaBv+FK4fr8Wux2kd/DB6c5zsbFunzWBBC+JZcSmOutdQs/9M0jsKz4/nkUg/gHjOX/B+ezKaZwSBMS/g+f4KHPWvo7mHIAeWYohOhGQEAdDsBZiyF9u650mk/ZbwsPstF4sAgHVOKbIa15rbcdS/gSnaiRVdSLT/5VYTuDAQ/mUb1bvCZveOYk++Nkhd3681h96ySwsxTBNbyxc4qx7F3vQxhi2L8Ig5qHlToUUFVOB/sHOx1+uloKCApUuXMmrUKMAKWFVVVQwbNmz7n9A08a64DFuolMDYl9G9I3CX34TS8iW6kouYbAJAMFQ01wAktY7g2Jdw1L2M0vwfQkPvQw4vQWn9mtDwRzFFO/a6N4gVXdRtW3a59Vt8y85BjFURKbkGKbIGz9q7iOdMRneW4Ft5eXvPrYfwL52Ore1bNGcxcqQMEwnB1BHQSaTvjxxcBGo9oeGPWKnATdJvUnglroq/Y69/EwQ7keIrifU7b2MX4BQpUqTYAoLagKPuVRw1zyKHl2Mo2URKriXW71xMW/pWHWuPDFoAU6ZM4cknn2SfffYhJyeHWbNm0b9/fyZM6MGtYRtxVP8DR+0LREquJpF9GErDB7gqH7ACVHRNh7Q96RuHLbiQ4Mi5mIKEu/xm1Kw/ouYeT8Y3Y0ik7088/yQc659AwCDW94xO5xLUetyrb8VZ85zVu2nkE7gqH0AKL20PXqtxV/6deN5Uov0uwr/gGKT4eqsOLLbOOogog2GQ9I5Baf26vTh49mZO5WJ0La6K+3DUPIcpuYgVnku0/6UdpropUqRI0ROCFkJp/BB77csoLZ8hmDpJ7ziCI2aj5k7e5pKUPTZoTZ8+nVAoxLRp04jFYkyYMIHZs2dvd7m7rfUbPKuuRc0+nGjJtYixarzLz0NzFCJH12ACpmhHV/KQQ0uI552A+v/t3Xl4FdX9+PH3zN2zhyUgIAQDCQSygmEHQSKKKEWsW3GDhwZtBRW1KkbBqlgXakELlPpTVKyA1CoJWhGLoiwC3yhCQCBsCYSQ7SZ33+b8/rhwJQZZFLJxXs+TR++cmXPP585wP3dmzpzT/rfHx/gzYe85F3PJIlRfJY7uT4OioHMdRKDWnYum9gfCf5iHpeQNED6cXaYSsHQhcudUhGrClvx3LMULMdi+xdHtSfzhvYnZMgoUHUI1ovoqUdCC9arhCBX09kLs3Z8+/txX8OHbYFL8M+Yj74Cix9V5Cs6uDwcvA0qSJJ2G4q38cei0qrUomoeA+VJcXe7HfcnN52Xw7Bb7cPH5cKZrw6r7CLGbhqDpo7D2+wKhWojZcjU62w4UEQAFhGJACXgIhHVGCTipHrARfc0WYgrGY0+cjavzvbT6Oo2A+VJq+uYDoLduImbLtSjCi/uSW9HbvkNvL0QoOjztb8TV4U7CDr6CqeLT4P2rS24lYs8MELjQ96sAABzHSURBVAFsvRahc+wifO9MNFN7VE9Z8J6a8KIAAXMX1OMz7NamvUUgMhUAxVdD2IFXMBcvRNE8uC6djKvLtPM6eeLpNIX7BhdKS44NZHwN1Yaz1dD3tFR3CaZjKzEeCw5YoKARMHcJDp0Wdx2+mP71HpU5k4vunlaDEAEid0xBCTip7ZMfHIuvaDaGms34LQno3CWgeVHx4GmdjalyNTXpSxH6GMKLniFg6Yrr0snonHvRuQ7gjH8gVLU/ph+16e9iLnkDQ/U6AmHdIWMileFXYy77NzHf/haEwN79GVTXIaIK78UXmYYt+TXCDszBXPbv4APCnhIEOhCBYIcLSwJ6VxGeuLHYkl8NjmIuNEyl/yJiz1Mo3vLgdCIJM87r3FeSJLUsOscejMc+wnTsIwy1BQD4I5Jxdn0IT7vrCUSkXLBHU2TS+oXCDvwVY9VabD3nEYjogb5mC2H7/oIvMg2D7TsANF04AdOlGKwb8LYeibftNeitmzDUFmDr+QqoRnTOvUBwh5/M2+aq4AgPAJqPtvYPid1yLTr3QTxtrsbd6S7C9zyF3vEDzs734L7kVqK+vxuds4iAoS2qp+THyhQ9AV00Oveh0NkdioLO9j2RhfdhqP0/fNF9sWcsD874K0mSdDIh0Nm/x1QWTFQnpvbxRffF3v1pvG3HNNgPXZm0fgGd/QfCip7H3W4c7o53gOYnYud0NENr9I7daLpIUFRUfw3eqFRMR3djT3oeANPR9xGqCXf74MCQmin4MK7eth1/TL8676O6SzCVLsVS/E/wHEaLzMDW4wWM1euJ+u53aMZ2WDP+jc5ZROzmqxCqMXj/ym9FITj7sdDHBKejN0Rh7fNBMCn57YQX/RnLoYUIQytqey3Ec8nN53wKL0lSCyY09DVbMB0/o9K5DiBQ8cUOwtZpEt64MaccT/RCk0nrXGk+IrdPRugjsCe9CIqC5dBCDLYCvDEDUa2bUHEhVBOeNtdgLP8YT/sbCIQnAmCs+gJv7FDQB58X80em4o/oTcSuBzEdfR9f7ABUbwWGmq3o7d8D4I0diq7ffJzWWiJ3PYzOfQhXhztwxk8jYvcMTBWfEDBfis5djFAMwYeZAc3UHp2nFE/cb7Alz0MYotFXbyByxz3oXPtxd5qIo9uT59zlVJKkFkoI9LVbMZUuxXRsJTrPkeAcdK2G4Yyfjifu2kafvVsmrXNkOTg3+DxW6tsIUxyKt5ywoufwRl2O0boeTReGpo9F9RzBH9EbU8XHuDrfE9xYaOicRXjbjPqxQkXB2jcPy6GFmA+/icG6HmFojT+yF45uT+JudwOqtwLjzllEl6/DH5GMte/HKL4qYjdno/jtwYFu3cXBIaJEAFDR9FGonjLsic/h6vwH0JxE7JqOpXgRAXNnavrk42s1uOE/QEmSmhzVdQhz6XuYSt9D79yLUE1421yFI24m3jZX1+3J3Mhk0joHOscewve9gCfuOrztxgIQvu/54ICzOjOaLgw14ERTjMHntazr8Ef0xh99YjgiBaGaQPPUqVcYWuFMeAxnwmMgtOBlOiEwVH1B5K4HMVZ+Dqa22Hr8FW+bkUTsfhzTsZUETJegiBpUv/XHuvTRKP5ahD6cmozl+GOy0Fs3Ebk9B71rH87O9+Lolgu68Ib62CRJaoqEhrHyM8zFizBWfIqCCE4uG38/nrixwY5aTZBMWucgfPcMhGrEnvQSAKpzP+aS/4cnbizmYx+gGVrjN8Shdx/A3f4Wor6/E+dlj/xYgaIQiOiB6dhKXPEPnLI7ueo5iunYfzAffhu9fQeaMQ57t1lEpE2F7f8kdsNAFOH9sXegojt+dgXa8ZmP3e1uwN5zDkIXhWX/HMKL/oxm6oi1T96pZxeWJOnioXkwH36HsINz0bn2oxnjcHZ9CHfHO9DOYpT1xiaT1lkyVH+NqeIT7N1mhpJN2MG5gA4FDU21oPoqCVji0TQHmikOBYE/KrNOPfYec4jZcg2x6/vivnQSAXMXFM2NzlmEwboRvX07AL7IdGw95+K+5BYM1g3w2SAiawqD67uLUb1lwQqFCI4ar+pQ/TZsya/h7jAB1bWP6P8bj6F2K+5247D3nNtkfzlJktQANB/mw4sJOzAHnbsEX3RfHAlP4Gk3FtQzD1TbVMikdTY0PxG7HiFg7oSr8xQAFF81ptKleOKux1S+Cn/YZSiOPajuw3hbXYEaCI4mr/3kpqU/Kp2ajBVYDs7FcvA1FOELrqePwh+Vgb3bTLxxYwiEJ6K3fkP0tzdjrPofmOIIGNuhcx88/uzV8c4WhrbofGX4w9KwpbxOIKw75pLXidj9BEI1UJvyxvF5sOR0HpJ0sTJUf03EzgfRO3bii+6HLXkevlYjmuX3gkxaZ8F07CP09u+pTXkDdMEJOMxH3kUN2PFF98Vc9j5KwI0v+nKM1q9xRaYi1OB6qreyXn2+2IH4YgdCwIXqr0EoBoShVfAAEgJD9deE7348OAqyPhZ/eCJ6x25U1fxjJYoRTWdB9VXg6PoQzq6PoAQcRG27A9OxD/G2HoEt+bVG6ZIqSVITEXATsfsxLCWvBztgpf0Lb9vRzTJZnSCT1pkIgeXg3whYuuJp95vQYlPpMnyRGeidexBqGDp3Mb5WQ8D6NcLQCl90H4RqxlS2Am/bq09dt86Cdnx6eMVfi+noCizF/wjey9LH4otIRW/fhu74WRva8bMyYxt03jICpnhsmR/gj+6DsfwTInfci+K3Yu/+zPHxBJvvgSlJ0q+jukuI+vZ3GGwFOLvchyNhRuhHd3Mmk9YZGCrXHB/BYt6Pg8p6KzDYCnAk5GIsz8cXlY7Ruh6/JSFUjs6Cq/MUwg68cnzAyGl17ykJgc65F0PV/zBWrAmOgqx58Id1wxfTH711M3r7juPjBgYvBQpdBEIRqN5jP55daU4it/8ec+l7+CN6UdvnIwKRvevFIUnSxUN1lxCzZTSKr4qatPfwxo1u7CadNzJpnYGleCEB0yW4O9waWmao2QyAt9UQLIf+jqfNVWBdD3oLAUs8pvI8XPH340jIRfUcJXz/S4Tvfwl/RDJCF4kScKK6D6H6awAImDvjbT0SxVuJoWYjuA4eT1YegrtID5Z2qK4SfDH9sSf9BX9UBoaqdUTumILqKcVx2Z9wdn3oFw/3L0lSCxFwEv1/vwkmrMwP8Uef/+mYGpNMWqeh+KwYK9cEH849qXeN3rYNgUIgohdoXoQuCqELR2/bjjP+QSJ3TiVs/4s4u07H1vsfOOMfwHT0ffS271E0N5ohFl9MPzR9NKq3DFPFp5jK8xGqBRQDivAFR4cHAuZOqK6D4K8N9ibseGdwxuLC+7AcXkzAEo/18tUt7sCUJOmXCd83G51jDzV9PmqR3wsyaZ1GcOIyf517WRB8lkoYWiH0kWjmS9B5ivHEXYe5dClVXR/GE/cbwouewXhsJd422QQikvFHpaNZuqBz7j8+8OS/UX1VCEWHZmiDQAXNhVDNKMJHwNwR1VuB6jqEu9MkLFnP4a41YSr7gPAfHkX1luGMvx/HZY+2iOvUkiSdH+ayD3DGP4Cv1bDGbsoFIZPWaRjLP8Vvuazes1ZoXoQS/Oj80ZdjPLYSa+ZKTGUfEF1wI7aer+Bpew2WQ/MJOzAXRXhDmwpFj2Zsh2ZoHZy6JGBH9deCokMRGgFzZ4SvCr3rAJ7W2Ti6zyIQ2RtLoJrI73Mwl32ALzKd2vR/tchfUZIk/TqaPgZn1wcbuxkXjExap2Go3Yq7zZX1euFp5g6o3mMQcOHs/AdMR/5F2MFXqEl7l8jCPxK7ZRT+iGQCYd1wRWWg+qpRvWXonAfReY+g8xxGKEbE8Z6DaF78kSnoXAfRO3fji74cW7fFwd6ImpewfS/C/hcwAY6E3OABebxTiCRJ0sk8cWMR+qjGbsYFI5PWaSiaC19U/bMZX8wgFASm8nw87W/E0X0WEXtyg3NbxT+I6i3HULsVneMHDO4joBoQujCEzkLA1AHVc+T4UExd8UekoLdtw2D7Fm/sEJxdHw6e1isKxmOrCN87Mzh3TeffUtV5Jprl0kb4JCRJai68bbIbuwkXlExaZxAIS6i3zNdqKH7LZYTveRJvq2G44qcRsHQlfO9MInY/hiL8wXtUqgFF80AA8FUhVAu+qHR80X3QuY9iqN2MUPbjiRuDq/M9ofm0dPZCwvc8ianiU/xh3alJX0p08k1oLXhKc0mSzg9/RMt+5EUmrTMQ+lOM16eo2FLfJGbzKGK/GYmjWy6euLF4465Fb/sevXUTqvcYiuYNPlul6lG9Vehrv8Vg/RqF4L0rR0Iurk53IYxtgeCzFeF7n8Zc+h6aPjr4kHDne0A1NHDUkiQ1W6oeNNHYrbhgZNI6A+Un04ic4I9KpybzAyIK/0jk95OI0D+IPzIFzRgHioLir0XnPoLOWYSiuYLbhCfh7Dodb9tr8Ef1Cd0rU10HCds/B/ORJYDAGf8Azi5TEcbWDRWmJElSsyCT1hmorn0QlXbKMl/sQKoHbMJY+RnGY/nonbvR1xYAwTO0gLkj3lbD8Eel44vpX2/Yf51jD5ZDf8d85B0A3B1+h7Prg81iegBJkqTGIJPWaWhqOKaKT/G2G/fzK6kGvG2vwdv2mrOrVAgM1vVY9s/BVLkaoRhxd7gV52WPysFtJUmSzkAmrdPwxo3BtG8Ozi73E4hI+lV1qe4jmI+8g+noCvSOnWiGVjgSZuDueCeaqf15arEkSVLLJpPWaTg734vx0CKiC8ZRk/khgfDu57S96i7FUPU5prKPMFauRhF+vDEDsfX8G+5LbpYjWUiSJJ0jmbROQxhbY+2zkpitY4ndOARXx9txd5pEIDyp/rQfQqB6y473ENyAsfwT9I6dAARMHXF1vhdXp0loYV0bIRJJkqSWQSat01BVBS06jZqB6wk7MAdL1ReEVX2CposiYO4IOguIAIrfhuo5hqoF570Sih5fTF8c8cFnr/zhPUBRg3X+yva0ZC05vpYcG8j4pIajCCFabod+SZIkqUX5NT/8JUmSJKlByaQlSZIkNRsyaUmSJEnNhkxakiRJUrMhk5YkSZLUbMikJUmSJDUbMmlJkiRJzYZMWpIkSVKzIZOWJEmS1GzIpCVJkiQ1GzJpNWGapjFnzhwGDhxIRkYGkyZN4vDhw43drFOaN28ePXv2JCMjI/T34IMPhsoLCwu55ZZbSEtL44orruCtt96qs73b7ebJJ58kKyuLzMxM7r//fqxWa5118vLyuOqqq0hNTeX6669nw4YNFyye/Px8brvtNjIzM0lKqj8tTUPEU1xczKRJk8jIyGDgwIH89a9/5XyNunam+JKSkkhNTa2zP3/44YdQ+dkcm+vXr+f6668nLS2NUaNGsWrVqjrl1dXV3H///WRmZpKVlcWTTz6J1+v91bG9+OKLXHvttWRmZjJ48GAef/xxqqur66zT3PffRU1ITdbChQvF8OHDRVFRkbDb7eKJJ54QY8aMEYFAoLGbVs/cuXPFhAkTTllms9nEgAEDxLx584Tb7RYFBQXi8ssvFx9//HFondzcXDFu3Dhx9OhRYbVaxeTJk8Xvf//7UPnWrVtFSkqK+Pzzz4XH4xHLli0TaWlp4vDhwxckni+//FKsXLlSLF++XCQmJjZ4PH6/X4wePVo88cQTwm63i6KiIjF8+HDxz3/+84LHJ4QQiYmJYuPGjT+7/ZmOzeLiYpGamiqWLVsmPB6P+Pzzz0Vqaqr49ttvQ3VMnDhRTJ48WVitVnH06FExbtw4MWvWrF8d28svvyx27NghvF6vqKioEHfffbfIyckJlbeE/Xcxk0mrCRs+fLhYsmRJ6HVNTY3o1auX+OabbxqxVad2uqS1YsUKMWjQoDrJ9oUXXhC33367EEIIl8slUlJSxNq1a0Ple/fuFYmJiaEvgT/96U9i2rRpdeq98cYbxbx58853KHVs3Lix3pd6Q8SzceNG0atXL1FTUxMqX7JkiRgxYsQFj0+IMyetMx2bc+fOFTfeeGOdbaZNmyYeffRRIUQwqSUmJoq9e/eGyteuXSvS0tKE2+3+VTH91Oeffy4yMjJCr1vS/rsYycuDTZTNZuPw4cP07t07tCwqKoouXbqwc+fORmzZz9u+fTv9+/dn+PDhTJ8+neLiYgB27dpFcnIyqvrj4da7d2927doFwIEDB/B4PKSkpITKExISsFgsoVh37dpV57P4aR0NqSHi2bVrF126dCEqKqpOeUlJCXa7/YLFdrLp06fTr18/xo0bx7Jly0LLz+bYPJv4LBYLCQkJofKUlBRcLhf79+8/r3Fs2LCBHj16hF5fLPuvpZJJq4k6cWCffNADREZGNsmDftSoUeTl5bFhwwbee+89dDodd999Nw6HA7vdTmRkZJ31o6KiQnGc+O9P1zk5VrvdXu+zOLmOhtQQ8fzce5xc/4X05ptv8tlnn7Fu3ToeeOABXnrpJd59990673+6Y/OXxHfi9fmMb9WqVSxfvpwZM2aEll0M+68lk0mriYqIiACCv2pPZrPZQmVNSWJiIh07dkRRFNq1a8ezzz5LeXk5BQUFRERE1PuHWltbG4rjbGKNiIioV35yHQ2pIeL5ufc4uf4LacCAAZjNZoxGI0OHDuWuu+7io48+qvP+5zu+E+ufr/jy8/N56qmnmD9/Pr169Qotvxj2X0smk1YTFRkZSceOHdm+fXtomc1m49ChQ/Ts2bMRW3Z2FEVBURSEEPTo0YPCwkI0TQuV79ixI3TJJj4+HpPJVCfWoqIiXC5XaJ0ePXrUKf9pHQ2pIeLp0aMHBw8erPPFuGPHDjp16tQoX3qqqoZ6vp3NsXk28TmdToqKikLl27dvx2w207Vr11/d3uXLlzNr1iwWLFhA//7965RdjPuvRWnsm2rSz1u4cKG48sorxb59+4TD4RC5ublNtvdgfn6+qKysFEIIUVFRIR599FExfPhwYbPZQr21Xn31VeHxeMR3330nsrKyxKpVq0Lb5+bmivHjx4uysjJhtVpFTk6OmDx5cqh869atIjU1Vaxdu1Z4vV7x/vvvi7S0NFFSUnJB4vH7/cLtdot169aJxMRE4Xa7hdvtFoFAoEHiOdH7LDc3VzgcDrFv3z4xYsQIsWjRogse3/bt28W2bduEx+MRPp9PfPXVVyIrK0ssXrw4tP2Zjs1Dhw6J1NRU8f777wuv1xvqZPHT3oM5OTnCarWKsrIyMX78eDFz5sxfHdvixYtFVlaW2LZt2ynLW8L+u5jJpNWEBQIB8dJLL4n+/fuLtLQ0MXHiRFFcXNzYzTqlnJwc0a9fP5GamioGDx4sHnjgAXHgwIFQ+Y4dO8RNN90kUlJSxNChQ+t8AQoR7LH1xBNPiL59+4qMjAwxdepUUV1dXWedlStXiuzsbJGSkiLGjBkj1q9ff8HiWbFihUhMTKz3d6JHXUPEc+jQITFx4kSRlpYm+vfvL+bMmSM0Tbvg8a1Zs0ZcffXVIj09XfTp00dcd9114t13362z/dkcm19//bUYM2aMSElJEdnZ2SI/P79OeWVlpZg6darIyMgQffv2Fbm5ueel52BiYqJITk4W6enpdf5Ofjyiue+/i5kihHzaTZIkSWoe5D0tSZIkqdmQSUuSJElqNmTSkiRJkpoNmbQkSZKkZkMmLUmSJKnZkElLkiRJajZk0pJavBEjRpCUlMTBgwfPav3du3eTlJTEpk2bQsuSkpJ45513zrit3W7nb3/7G6NHjw7NR3XbbbexfPlyAoEAEJx7rF+/fr8sGEm6yOkbuwGSdCEVFBSEJifMy8vjD3/4wy+qZ+nSpXTq1Om061RWVnL77bdTW1vL3XffTa9evfB6vWzcuJHZs2cTGxvLyJEjf9H7S5IUJJOW1KLl5+cTFhZG9+7dyc/P/8VJKz09/YzrzJw5k9raWlasWEG7du1Cy4cOHcqECRPqDbAqSdK5k5cHpRYrEAjw8ccfM2LECMaPH09RUdEp599asmQJw4YNIz09nSlTplBeXl5vnTNdHiwpKWH16tXk5OTUSVgndOjQ4ZTT2p9QXFzMvffeS2ZmJhkZGUyZMqXe5czly5eHLjv269ePCRMmsGfPnlC5x+PhhRdeYNiwYfTu3Zvrr7+eL7744mffU5KaI5m0pBZr06ZNVFRUMHr0aEaNGoXBYCAvL6/OOp999hlPP/00V1xxBfPmzSMxMZHHH3/8nN9ry5YtCCEYMmTIOW/r9Xq56667KCoq4plnnuH555+npKSECRMmYLVaAdi8eTMzZ85k7NixLFq0iOeee46MjIw6Z29Tp07lgw8+ICcnhwULFpCSksI999zTZCcNlaRfQl4elFqsvLw8oqKiGDJkCEajkUGDBrFq1SqmT5+OoigALFiwgCFDhjBr1iwAhgwZQlVVFcuXLz+n9zp27BgQPKM6VytWrKC0tJT//ve/XHrppQCkpaUxcuRIli5dSk5ODtu2bSMpKYmcnJzQdldeeWXo/zds2MDatWt5++23ycrKAmDw4MEcOHCA+fPnM3fu3HNulyQ1RfJMS2qRvF4vq1evZuTIkRiNRgBGjx7N4cOHKSgoAMDv91NYWFjnyx8gOzu7Qdu6bds2kpOTQwkLoH379mRkZLB161YAevbsSWFhIc899xybN2/G6/XWqWP9+vW0bduWzMxM/H5/6G/AgAH15n2SpOZMnmlJLdKXX35JbW0tw4YNC80Y269fP4xGI/n5+WRmZlJdXU0gEKB169Z1tv3p67MRFxcHQGlpKV26dDmnbcvLy2nTpk295W3atOHIkSMADBw4kNmzZ/P222/z1ltvERYWxtixY3n44YcJCwujurqa8vLyOjP0nqDT6c45HklqqmTSklqk/Px8AKZNm1av7JNPPuHxxx8nNjYWnU5HZWVlnfKfvj4bl19+OYqi8NVXX51z0mrbti179+6tt7yiooLo6OjQ63HjxjFu3Diqqqr49NNPmT17NuHh4Tz00ENER0fTrl07XnvttXNuuyQ1JzJpSS2O0+nkf//7H2PGjOGmm26qU7Zz505mz57Nxo0bGTRoED179mTNmjXceuutoXVWr159zu/ZsWNHsrOzWbBgAdnZ2aEzrxNKS0upra09ZQ/CtLQ0PvzwQ4qLi0OXCMvKyigoKOC+++6rt36rVq245ZZbWL16dSjZDRgwgDfeeIOwsDASEhLOuf2S1FzIpCW1OGvWrMHlcnHHHXeQlpZWpywzM5P58+eTl5fHoEGDmDJlCn/84x956qmnyM7OZvPmzaxbt+4Xve/MmTOZMGEC48ePr/Nw8ebNm1myZAl/+ctfTpm0brjhBhYtWsTkyZOZOnUqOp2OV199ldjYWG6++WYA5s6dS01NDVlZWcTGxlJYWMg333zD9OnTARg0aBCDBw9m4sSJTJ48mW7dumG329m1axcejye0niQ1dzJpSS1Ofn4+8fHx9RIWgMFg4JprriEvL49Zs2aRnZ1Nbm4u//jHP/jPf/5DVlYWzz77LJMmTaq37Ykehz+ndevWLFu2jNdff51ly5Zx+PBh9Ho9ycnJPPbYYwwfPvyU2xmNRt58801mz57NjBkzAMjKymLevHnExMQAkJKSwptvvkl+fj4Oh4MOHTpw3333ceedd4ba9uqrr7JgwQIWL15MaWkp0dHR9OjRg9tvv/2cPj9JasoUIYRo7EZIUlNmt9vp06cPL7/8MmPGjGns5kjSRU2eaUnSaRQVFfHhhx+iKArJycmN3RxJuujJpCVJpzFnzhy2bdvGI488wmWXXdbYzZGki568PChJkiQ1G3JEDEmSJKnZkElLkiRJajZk0pIkSZKaDZm0JEmSpGZDJi1JkiSp2ZBJS5IkSWo2/j+07eH+GqT+HQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCTrZJf81AuS",
        "outputId": "ed109b83-4361-45f5-9667-60bed10c905e"
      },
      "source": [
        "#test_df2=test_df.drop(['change','change_label'])\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(test_df.drop(['change','change_label'],axis =1 ), test_df.change_label, test_size=0.25, \r\n",
        "                                                    stratify=test_df.change_label, random_state=30)\r\n",
        "\r\n",
        "print (\"train feature shape: \", X_train.shape)\r\n",
        "print (\"test feature shape: \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train feature shape:  (1369, 18)\n",
            "test feature shape:  (457, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8lqrDgX2_L2"
      },
      "source": [
        "#now PCA.\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}