{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Price Base Model New Input",
      "provenance": [],
      "collapsed_sections": [
        "BshD6EjfdHGy",
        "6EuYIwJAHyT6",
        "SFfMPY--bvrO",
        "FMo638lbIbdp",
        "mruUFVdyIxfH",
        "XqSIcZPr9qCY"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO2344KP0xmxH8TSaJVUeAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanzhaoZ/PreBit/blob/main/Price_Base_Model_New_Input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKJf58FLcogN",
        "outputId": "7be428fd-d38e-4c15-a42a-ca2a32a68554"
      },
      "source": [
        " !pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/78/56a7c88a57d0d14945472535d0df9fb4bbad7d34ede658ec7961635c790e/lxml-4.6.2-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22615 sha256=2edf0ba462e2905cd791a8e7a50561836bf901ee34afeb4c9c65b207c2b9db29\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.2 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0hPGdzadWND"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BshD6EjfdHGy"
      },
      "source": [
        "# Loading Price Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGzvjjDYdLoi",
        "outputId": "7647fe67-a47d-445b-ffd9-7e3ed60e1d33"
      },
      "source": [
        "start_date ='2015-01-01'\n",
        "end_date = '2019-12-31'\n",
        "price = yf.download(\"BTC-USD\", start=start_date, end=end_date)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiqImSEpgGt5"
      },
      "source": [
        "def get_technical_indicators(price):\n",
        "    # Create 7 and 21 days Moving Average\n",
        "    dataset = price.copy()\n",
        "\n",
        "    dataset['ma7'] = dataset['Close'].rolling(window=7).mean()\n",
        "    dataset['ma21'] = dataset['Close'].rolling(window=21).mean()\n",
        "    \n",
        "    # Create MACD\n",
        "    #dataset['26ema'] = pd.ewma(dataset['Close'], span=26)\n",
        "    dataset['26ema'] = dataset['Close'].ewm(span=26).mean()\n",
        "    #dataset['12ema'] = pd.ewma(dataset['Close'], span=12)\n",
        "    dataset['12ema'] = dataset['Close'].ewm(span=12).mean()\n",
        "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
        "\n",
        "    # Create Bollinger Bands\n",
        "    #dataset['20sd'] = pd.stats.moments.rolling_std(dataset['Close'],20)\n",
        "    dataset['20sd'] = dataset[\"Close\"].rolling(window=20).std()\n",
        "    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
        "    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
        "    \n",
        "    # Create Exponential moving average\n",
        "    dataset['ema'] = dataset['Close'].ewm(com=0.5).mean()\n",
        "    \n",
        "    # Create Momentum\n",
        "    #dataset['momentum'] = dataset['Close']-1\n",
        "\n",
        "    # Create high-low spred\n",
        "    dataset['spread'] = dataset['High'] - dataset['Low']\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-keoW2D4TEb"
      },
      "source": [
        "The Gold etf SPDR Gold future, has a lot of NAN values. \r\n",
        "That might cause some issues, but let's see how it goes first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szog27YrNQSG"
      },
      "source": [
        " # to be finished \n",
        "# def get_related_asset (price, start_date, end_date):\n",
        "#     other_price = yf.download(\"ETH-USD\", start=start_date, end=end_date)\n",
        "\n",
        "#     price['eth']=other_price[\"Close\"]\n",
        "#     #there are nan values because the price datarange is not the same. so I should probalby fill the value by non-0, coz i need to do division later...\n",
        "#     #let's fill it with the next valid value \n",
        "#     price.eth.fillna(method='bfill', inplace= True, axis=0)\n",
        "\n",
        "#     return price\n",
        "\n",
        " # to be finished \n",
        "def get_related_asset (price, start_date, end_date):\n",
        "    other_price = yf.download(\"ETH-USD GLD\", start=start_date, end=end_date)\n",
        "\n",
        "    price['eth']=other_price.Close['ETH-USD']\n",
        "    price['gold'] = other_price.Close['GLD']\n",
        "    #there are nan values because the price datarange is not the same. so I should probalby fill the value by non-0, coz i need to do division later...\n",
        "    #let's fill it with the next valid value \n",
        "    price.eth.fillna(method='bfill', inplace= True, axis=0)\n",
        "    price.gold.fillna(method='bfill', inplace= True, axis=0) \n",
        "\n",
        "    return price\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "291fHPUribeU"
      },
      "source": [
        "def get_label (price,threshold):\n",
        "\n",
        "\n",
        "    price['change']=price.shift(-1).High/price.Close -1 \n",
        "    price['change_label']=price['change'].apply (lambda x: x> threshold)\n",
        "\n",
        "    #convert True/False to 1/0\n",
        "    class2idx = {True: 1, False:0}\n",
        "    price['change_label'].replace(class2idx, inplace=True)\n",
        "\n",
        "    return price"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrQfP2Crtl8X"
      },
      "source": [
        "def normalise_close(price):\n",
        "    \n",
        "    df = price.copy()\n",
        "    for key in df.keys():\n",
        "        if not key in ['change','change_label','Volume','MACD','20sd','spread','eth','gold']:\n",
        "            df[key]=df[key]/price['Close'].shift(1) - 1\n",
        "        \n",
        "    df['Volume']=df['Volume']/price['Volume'].shift(1)-1\n",
        "    df['eth']  = df['eth']/price['eth'].shift(1)-1\n",
        "    df['gold'] = df['gold']/price['gold'].shift(1)-1\n",
        "    df['MACD'] = df['MACD']/price['Close'].shift(1)\n",
        "    df['20sd'] = df['20sd']/price['Close'].shift(1)\n",
        "    df['spread'] = df['spread']/price['Close'].shift(1)\n",
        "\n",
        "\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB1cLbyxCsb_"
      },
      "source": [
        "def get_ma_feature (price,threshold):\n",
        "    price['ma_feature']=price['ma7'].apply(lambda x: x > threshold)\n",
        "    \n",
        "    class2idx = {True: 1, False:0}\n",
        "    price['ma_feature'].replace(class2idx, inplace=True)\n",
        "    return price"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr-qb6DFd-Dw"
      },
      "source": [
        "#Here I want to define a function to return a new dataframe, that's INDEPENDANT, and produce relative price. \n",
        "def process_price (original_df,threshold, start_date,end_date):\n",
        "    #get the indicators\n",
        "    df = get_technical_indicators(original_df)\n",
        "\n",
        "    #get related asset\n",
        "    df = get_related_asset(df,start_date,end_date)\n",
        "\n",
        "    #get label\n",
        "    df = get_label(df, threshold)\n",
        "\n",
        "    #normalise the data\n",
        "    df_normalised_close = normalise_close(df)\n",
        "\n",
        "    #get ma label\n",
        "    df_normalised_close = get_ma_feature(df_normalised_close, threshold)\n",
        "\n",
        "    #return both normalized, and un-normalized data (w/o ma label). \n",
        "    return df, df_normalised_close\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS3krSQDeA93",
        "outputId": "ac3cfe72-786f-4982-e478-6bcb86e37d8c"
      },
      "source": [
        "test_df, test_df_norm = process_price(price,0.05,start_date,end_date)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  2 of 2 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "z-lIuKV9eA4H",
        "outputId": "c89fa007-737f-4297-ec5a-8d539e9a61f7"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "      <th>ema</th>\n",
              "      <th>spread</th>\n",
              "      <th>eth</th>\n",
              "      <th>gold</th>\n",
              "      <th>change</th>\n",
              "      <th>change_label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-01</th>\n",
              "      <td>320.434998</td>\n",
              "      <td>320.434998</td>\n",
              "      <td>314.002991</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>8036550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.248993</td>\n",
              "      <td>6.432007</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02</th>\n",
              "      <td>314.079010</td>\n",
              "      <td>315.838989</td>\n",
              "      <td>313.565002</td>\n",
              "      <td>315.032013</td>\n",
              "      <td>315.032013</td>\n",
              "      <td>7860650</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.655561</td>\n",
              "      <td>314.673129</td>\n",
              "      <td>0.017568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>314.836258</td>\n",
              "      <td>2.273987</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-03</th>\n",
              "      <td>314.846008</td>\n",
              "      <td>315.149994</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>281.082001</td>\n",
              "      <td>33054400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>302.592907</td>\n",
              "      <td>301.562504</td>\n",
              "      <td>-1.030403</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.467926</td>\n",
              "      <td>34.067993</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-04</th>\n",
              "      <td>281.145996</td>\n",
              "      <td>287.230011</td>\n",
              "      <td>257.612000</td>\n",
              "      <td>264.195007</td>\n",
              "      <td>264.195007</td>\n",
              "      <td>55629100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.858532</td>\n",
              "      <td>289.767045</td>\n",
              "      <td>-2.091487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>273.058706</td>\n",
              "      <td>29.618011</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.053544</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>265.084015</td>\n",
              "      <td>278.341003</td>\n",
              "      <td>265.084015</td>\n",
              "      <td>274.473999</td>\n",
              "      <td>274.473999</td>\n",
              "      <td>43962800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>287.826987</td>\n",
              "      <td>285.611979</td>\n",
              "      <td>-2.215008</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>274.006134</td>\n",
              "      <td>13.256989</td>\n",
              "      <td>2.77212</td>\n",
              "      <td>115.800003</td>\n",
              "      <td>0.047651</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...    change  change_label\n",
              "Date                                ...                        \n",
              "2015-01-01  320.434998  320.434998  ...  0.005060             0\n",
              "2015-01-02  314.079010  315.838989  ...  0.000375             0\n",
              "2015-01-03  314.846008  315.149994  ...  0.021873             0\n",
              "2015-01-04  281.145996  287.230011  ...  0.053544             1\n",
              "2015-01-05  265.084015  278.341003  ...  0.047651             0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e4KJZaWZeA1r",
        "outputId": "211e55c0-4cae-43ff-daf5-85c362b3ef21"
      },
      "source": [
        "test_df_norm.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "      <th>ema</th>\n",
              "      <th>spread</th>\n",
              "      <th>eth</th>\n",
              "      <th>gold</th>\n",
              "      <th>change</th>\n",
              "      <th>change_label</th>\n",
              "      <th>ma_feature</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-01</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02</th>\n",
              "      <td>-0.000541</td>\n",
              "      <td>0.005060</td>\n",
              "      <td>-0.002177</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>-0.021888</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001294</td>\n",
              "      <td>0.001350</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.007236</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-03</th>\n",
              "      <td>-0.000590</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>-0.107767</td>\n",
              "      <td>-0.107767</td>\n",
              "      <td>-0.107767</td>\n",
              "      <td>3.205047</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.039485</td>\n",
              "      <td>-0.042756</td>\n",
              "      <td>-0.003271</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.074799</td>\n",
              "      <td>0.108141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015077</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-04</th>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.021873</td>\n",
              "      <td>-0.083499</td>\n",
              "      <td>-0.060079</td>\n",
              "      <td>-0.060079</td>\n",
              "      <td>0.682956</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038339</td>\n",
              "      <td>0.030899</td>\n",
              "      <td>-0.007441</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.028544</td>\n",
              "      <td>0.105371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053544</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-05</th>\n",
              "      <td>0.003365</td>\n",
              "      <td>0.053544</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>0.038907</td>\n",
              "      <td>0.038907</td>\n",
              "      <td>-0.209716</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.089449</td>\n",
              "      <td>0.081065</td>\n",
              "      <td>-0.008384</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.037136</td>\n",
              "      <td>0.050179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047651</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Open      High       Low  ...    change  change_label  ma_feature\n",
              "Date                                      ...                                    \n",
              "2015-01-01       NaN       NaN       NaN  ...  0.005060             0           0\n",
              "2015-01-02 -0.000541  0.005060 -0.002177  ...  0.000375             0           0\n",
              "2015-01-03 -0.000590  0.000375 -0.107767  ...  0.021873             0           0\n",
              "2015-01-04  0.000228  0.021873 -0.083499  ...  0.053544             1           0\n",
              "2015-01-05  0.003365  0.053544  0.003365  ...  0.047651             0           0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EuYIwJAHyT6"
      },
      "source": [
        "# Some analysis with MA only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5-Qm6rHx_b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ePkc-bMv5VZ",
        "outputId": "efd5152d-6e8c-47a7-9cc5-f7322122b7ef"
      },
      "source": [
        "(test_df_norm['change_label']==test_df_norm['ma_feature']).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     1537\n",
              "False     289\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCinzG02Dyba",
        "outputId": "2204c0f1-0a1c-4092-f68e-77cfd93fa485"
      },
      "source": [
        "test_df_norm['change_label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1608\n",
              "1     218\n",
              "Name: change_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOgB2oowD_Uz",
        "outputId": "a5739857-2cb7-4112-b072-c6c624f73f62"
      },
      "source": [
        "#why not get a confusion matrix with these two labels and check it out. \n",
        "accuracy = (test_df_norm['change_label']==test_df_norm['ma_feature']).sum() / len(test_df_norm['change_label']==test_df_norm['ma_feature'])\n",
        "print ('accuracy:', accuracy)\n",
        "print (confusion_matrix(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "print (classification_report(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "\n",
        "#The true label, accuracy is only 0.27, and recall rate is quite low to be honest. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8417305585980285\n",
            "[[1495  113]\n",
            " [ 176   42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91      1608\n",
            "           1       0.27      0.19      0.23       218\n",
            "\n",
            "    accuracy                           0.84      1826\n",
            "   macro avg       0.58      0.56      0.57      1826\n",
            "weighted avg       0.82      0.84      0.83      1826\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt6Jsxx8F5I3",
        "outputId": "15d0d89a-87bb-4aed-c61b-8106ccb3398c"
      },
      "source": [
        "#for 21day ma features\n",
        "#why not get a confusion matrix with these two labels and check it out. \n",
        "accuracy = (test_df_norm['change_label']==test_df_norm['ma_feature']).sum() / len(test_df_norm['change_label']==test_df_norm['ma_feature'])\n",
        "print ('accuracy:', accuracy)\n",
        "print (confusion_matrix(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "print (classification_report(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "\n",
        "#The true label, accuracy is only 0.27, and recall rate is quite low to be honest. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7431544359255202\n",
            "[[1301  307]\n",
            " [ 162   56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.81      0.85      1608\n",
            "           1       0.15      0.26      0.19       218\n",
            "\n",
            "    accuracy                           0.74      1826\n",
            "   macro avg       0.52      0.53      0.52      1826\n",
            "weighted avg       0.80      0.74      0.77      1826\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67tCONaUIdX7",
        "outputId": "3a60c80a-bff8-4771-e2b5-2f8f4aec74db"
      },
      "source": [
        "#for ema features\n",
        "#why not get a confusion matrix with these two labels and check it out. \n",
        "accuracy = (test_df_norm['change_label']==test_df_norm['ma_feature']).sum() / len(test_df_norm['change_label']==test_df_norm['ma_feature'])\n",
        "print ('accuracy:', accuracy)\n",
        "print (confusion_matrix(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "print (classification_report(test_df_norm['change_label'].values, test_df_norm['ma_feature'].values))\n",
        "\n",
        "#The true label, accuracy is only 0.27, and recall rate is quite low to be honest. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.864184008762322\n",
            "[[1561   47]\n",
            " [ 201   17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93      1608\n",
            "           1       0.27      0.08      0.12       218\n",
            "\n",
            "    accuracy                           0.86      1826\n",
            "   macro avg       0.58      0.52      0.52      1826\n",
            "weighted avg       0.81      0.86      0.83      1826\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH2o4ZSOWDUY"
      },
      "source": [
        "#so bascially 7day ma works best among these 3. got it. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM2W-oEPWNs0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFfMPY--bvrO"
      },
      "source": [
        "# Format Custom Dataset input for Torch Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkcbqR134S4I"
      },
      "source": [
        "Creating two dataset classes for future use, 1 is for classification tast, the other for Regression task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me2mllPfb6bP"
      },
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.df = df\n",
        "        self.X, self.Y = self.clean_df()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "    def clean_df(self):\n",
        "        #drop NaN values, and also load the values into torch.tensor. \n",
        "        df = self.df.dropna()\n",
        "        y_values = df.change_label.values\n",
        "        df = df.drop (['change','change_label'],axis=1)\n",
        "        #try put the label as part of the feature see if the model cna leran that \n",
        "        #df = df.drop (['change'],axis=1)\n",
        "        x_values = df.values\n",
        "\n",
        "        return torch.from_numpy(x_values).float(), torch.from_numpy(y_values).long()\n",
        "\n",
        "\n",
        "      \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7l-Gu-vkq83"
      },
      "source": [
        "class RegressionDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.df = df\n",
        "        self.X, self.Y = self.clean_df()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "    def clean_df(self):\n",
        "        #drop NaN values, and also load the values into torch.tensor.\n",
        "        df = self.df.dropna()\n",
        "        y_values = df.change.values\n",
        "        df = df.drop (['change','change_label'],axis=1)\n",
        "        x_values = df.values\n",
        "\n",
        "        return torch.from_numpy(x_values).float(), torch.from_numpy(y_values).float()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfHatgydCwHs"
      },
      "source": [
        "# define a function for train_test split, and initiate dataset? \n",
        "def split_train_test (df, threshold):\n",
        "    length = len(df)\n",
        "    split_number  = round(threshold*length)\n",
        "    return df[0:split_number], df[split_number:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVI-SUEoD_k2"
      },
      "source": [
        "#for classification dataset construction\n",
        "test_df_train,test_df_eval = split_train_test(test_df_norm, 0.7)\n",
        "train_dataset = ClassifierDataset(test_df_train)\n",
        "eval_dataset = ClassifierDataset (test_df_eval)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTBt70ZjGOiw"
      },
      "source": [
        "# for Regression dataset construction\n",
        "\n",
        "# test_df_train,test_df_eval = split_train_test(test_df_norm, 0.7)\n",
        "# train_dataset = RegressionDataset(test_df_train)\n",
        "# eval_dataset = RegressionDataset (test_df_eval)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HfWHePSo1Pa",
        "outputId": "76d7a5aa-1be9-41df-f261-1dbf02d1fca6"
      },
      "source": [
        "eval_dataset[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0009,  0.0467, -0.0125,  0.0358,  0.0358, -0.0817, -0.0207,  0.0035,\n",
              "          0.0373, -0.0022, -0.0395,  0.0413,  0.0861, -0.0791,  0.0226,  0.0592,\n",
              "          0.0472,  0.0000,  0.0000]), tensor(0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMo638lbIbdp"
      },
      "source": [
        "# Format DataLoader, different sampling options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0kk1mR_tJI0"
      },
      "source": [
        "#Now let's try to flow the data into dataloader \n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, )\n",
        "eval_loader = DataLoader(eval_dataset, batch_size = 64, )\n",
        "# add in shuffle/sampler options later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX7oSm_rOE9R"
      },
      "source": [
        "The above is the normal dataloader. Below I will try to use weighted samplers, which will include oversample and undersamples, and in this case, it will also disrupt the ordering/sequence of the input, ummmmmmmmmmm, How will that affect the model performance, let's seeeeeeeee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZvQSmAVOEXy"
      },
      "source": [
        "#obtain the label list. \r\n",
        "target_list = []\r\n",
        "for _,t in train_dataset:\r\n",
        "  target_list.append(t)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN4VLeQuZfHh",
        "outputId": "5b39374b-f9d4-4f34-ed87-3dd323a3b460"
      },
      "source": [
        "#obtain the class weights\r\n",
        "leng = len(target_list)\r\n",
        "total_true = sum(target_list)\r\n",
        "class_count = [leng-total_true, total_true]\r\n",
        "class_weight = 1./torch.tensor(class_count, dtype=torch.float)\r\n",
        "class_weight"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0009, 0.0062])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCvHSf-2apzB",
        "outputId": "c8ba616c-fe94-419e-a9e0-22ffb65241eb"
      },
      "source": [
        "#a weight for each sample\r\n",
        "class_weights_all = class_weight[target_list]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0009, 0.0009, 0.0062,  ..., 0.0009, 0.0009, 0.0009])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H4P0ryYe-3B"
      },
      "source": [
        "weighted_sampler = WeightedRandomSampler(\r\n",
        "    weights = class_weights_all,\r\n",
        "    num_samples = leng,\r\n",
        "    replacement = True\r\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ku89M3fiah"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 64, sampler=weighted_sampler )\r\n",
        "eval_loader = DataLoader(eval_dataset, batch_size = 64, )\r\n",
        "# add in shuffle/sampler options later"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_-C0_dCfsSJ",
        "outputId": "07e768b9-6910-4fba-d9a4-4edc500e0d1d"
      },
      "source": [
        "for i, batch in enumerate(train_loader):\r\n",
        "    _,t = (m for m in batch)\r\n",
        "    print (sum(t)/len(t))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6094)\n",
            "tensor(0.4688)\n",
            "tensor(0.3750)\n",
            "tensor(0.4219)\n",
            "tensor(0.5781)\n",
            "tensor(0.6094)\n",
            "tensor(0.4688)\n",
            "tensor(0.5781)\n",
            "tensor(0.4375)\n",
            "tensor(0.5312)\n",
            "tensor(0.6094)\n",
            "tensor(0.5469)\n",
            "tensor(0.5469)\n",
            "tensor(0.5000)\n",
            "tensor(0.4531)\n",
            "tensor(0.4531)\n",
            "tensor(0.5156)\n",
            "tensor(0.4375)\n",
            "tensor(0.5156)\n",
            "tensor(0.3333)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chR_wC8ytJHm"
      },
      "source": [
        "#next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFK252mLtJGT"
      },
      "source": [
        "# for i, batch in enumerate(train_loader):\n",
        "#     print (i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLdhmP5MtJA8"
      },
      "source": [
        "#weighed random sampler test. \n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
        "# train_dataset = torch.tensor([1, 1 , 1, 1, 1, 1, 1, 1, 1, 0])\n",
        "\n",
        "\n",
        "# class_weights_all = [0.1, 0.1, 0.1, 0.1,0.1, 0.1, 0.1, 0.1,0.1, 0.9]\n",
        "\n",
        "# weighted_sampler = WeightedRandomSampler(\n",
        "#     weights=class_weights_all,\n",
        "#     num_samples=10,\n",
        "#     replacement=True #if True, sampler will draw repeating inputs, False will have 0 repeats. \n",
        "# )\n",
        "\n",
        "# BATCH_SIZE = 5\n",
        "# dataset = TensorDataset(train_dataset)\n",
        "# train_loader = DataLoader(dataset,\n",
        "#                           batch_size=BATCH_SIZE,\n",
        "#                           sampler=weighted_sampler\n",
        "# )\n",
        "# for batch in train_loader:\n",
        "#     print(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mruUFVdyIxfH"
      },
      "source": [
        "\n",
        "\n",
        "# Building Torch Model 1 - FeedForward Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2zH_3fttI6v"
      },
      "source": [
        "#let's first try a simple FC NN\n",
        "class FFNN (nn.Module):\n",
        "    def __init__(self, input_size, num_classes,num_hidden, hidden_dim ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert num_hidden > 0 \n",
        "\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([])\n",
        "        self.hidden_layers.append (self.fc1)\n",
        "        for i in range (num_hidden -1 ):\n",
        "            self.hidden_layers.append(self.fc2)\n",
        "        \n",
        "        self.final_layer = nn.Linear (hidden_dim,num_classes)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = hidden_layer(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.relu(x)\n",
        "        \n",
        "        out = self.final_layer(x)\n",
        "        out_dist = F.log_softmax(out, dim= -1) #why is it -1, ok, coz it's batch x input x class. \n",
        "        \n",
        "        return out_dist\n",
        "\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbT1kH2jFB6E"
      },
      "source": [
        "#try initiating the model\n",
        "INPUT_SIZE = 19\n",
        "NUM_CLASSES = 2\n",
        "NUM_HIDDEN = 2\n",
        "HIDDEN_DIM = 512\n",
        "\n",
        "model = FFNN(INPUT_SIZE, NUM_CLASSES, NUM_HIDDEN, HIDDEN_DIM)\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgc97Ziqkn1G",
        "outputId": "d4713fb8-236c-44a0-940b-670d5dbbb545"
      },
      "source": [
        "model"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (fc1): Linear(in_features=19, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=19, out_features=512, bias=True)\n",
              "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (final_layer): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nW0_Vjqk4Ec",
        "outputId": "52953da8-fb8e-4185-f3e0-362163b75893"
      },
      "source": [
        "#print model parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 273,922 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy_YDstOu6kG"
      },
      "source": [
        "#define loss fuction and optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.NLLLoss()\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhKFYZjEvrJ9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ejBYTW2rVg"
      },
      "source": [
        "#define a function to calcualte prediction accuracy\n",
        "def accuracy(pred,label):\n",
        "    _,pred_label = torch.max(pred,dim=1)\n",
        "    correct = (pred_label==label).float()\n",
        "    accuracy = correct.sum()/len(correct)\n",
        "    return accuracy"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV01Q5NlvukI"
      },
      "source": [
        "#now define the training and evaluation loop\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss= 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data, label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data)\n",
        "        loss = loss_fn(pred,label)\n",
        "        acc  = accuracy(pred,label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "        \n",
        "\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a07XNBqh5HdM"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0 \n",
        "    epoch_acc = 0 \n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        data,label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data)\n",
        "        loss = loss_fn(pred,label)\n",
        "        acc = accuracy(pred,label)\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)\n",
        "        "
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EZeClpayNzv",
        "outputId": "de853490-89d3-4eb0-ea4e-301ea0098f6a"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "for i in range(N_EPOCHS):\n",
        "    train_loss,train_acc = train(model,train_loader, optimizer, loss_fn)\n",
        "    \n",
        "    eval_loss, eval_acc = evaluate(model,eval_loader, loss_fn)\n",
        "    \n",
        "    print (f' Epoch Number {i}') \n",
        "    print (f' Train. Loss: {train_loss:.3f} Train. Acc: {train_acc*100:.2f}%')\n",
        "    print (f' Eval loss , {eval_loss:.3f}, eval acc, {eval_acc*100:.2f} %')\n",
        "    # print(f'\\t Train. Loss: {train_loss:.3f} |  Train. Acc: {train_acc*100:.2f}%')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch Number 0\n",
            " Train. Loss: 0.647 Train. Acc: 62.90%\n",
            " Eval loss , 0.646, eval acc, 76.16 %\n",
            " Epoch Number 1\n",
            " Train. Loss: 0.635 Train. Acc: 63.37%\n",
            " Eval loss , 0.474, eval acc, 83.08 %\n",
            " Epoch Number 2\n",
            " Train. Loss: 0.575 Train. Acc: 70.45%\n",
            " Eval loss , 0.571, eval acc, 73.53 %\n",
            " Epoch Number 3\n",
            " Train. Loss: 0.557 Train. Acc: 73.02%\n",
            " Eval loss , 0.522, eval acc, 77.35 %\n",
            " Epoch Number 4\n",
            " Train. Loss: 0.566 Train. Acc: 72.01%\n",
            " Eval loss , 0.419, eval acc, 83.08 %\n",
            " Epoch Number 5\n",
            " Train. Loss: 0.557 Train. Acc: 71.22%\n",
            " Eval loss , 0.507, eval acc, 76.51 %\n",
            " Epoch Number 6\n",
            " Train. Loss: 0.549 Train. Acc: 72.21%\n",
            " Eval loss , 0.478, eval acc, 78.04 %\n",
            " Epoch Number 7\n",
            " Train. Loss: 0.555 Train. Acc: 72.35%\n",
            " Eval loss , 0.426, eval acc, 82.21 %\n",
            " Epoch Number 8\n",
            " Train. Loss: 0.555 Train. Acc: 71.59%\n",
            " Eval loss , 0.512, eval acc, 75.12 %\n",
            " Epoch Number 9\n",
            " Train. Loss: 0.536 Train. Acc: 73.33%\n",
            " Eval loss , 0.521, eval acc, 75.12 %\n",
            " Epoch Number 10\n",
            " Train. Loss: 0.555 Train. Acc: 72.33%\n",
            " Eval loss , 0.487, eval acc, 78.42 %\n",
            " Epoch Number 11\n",
            " Train. Loss: 0.544 Train. Acc: 72.44%\n",
            " Eval loss , 0.459, eval acc, 78.91 %\n",
            " Epoch Number 12\n",
            " Train. Loss: 0.535 Train. Acc: 73.92%\n",
            " Eval loss , 0.525, eval acc, 73.53 %\n",
            " Epoch Number 13\n",
            " Train. Loss: 0.535 Train. Acc: 73.34%\n",
            " Eval loss , 0.485, eval acc, 75.78 %\n",
            " Epoch Number 14\n",
            " Train. Loss: 0.540 Train. Acc: 73.65%\n",
            " Eval loss , 0.423, eval acc, 81.17 %\n",
            " Epoch Number 15\n",
            " Train. Loss: 0.541 Train. Acc: 73.70%\n",
            " Eval loss , 0.497, eval acc, 74.08 %\n",
            " Epoch Number 16\n",
            " Train. Loss: 0.528 Train. Acc: 73.77%\n",
            " Eval loss , 0.576, eval acc, 70.63 %\n",
            " Epoch Number 17\n",
            " Train. Loss: 0.525 Train. Acc: 74.74%\n",
            " Eval loss , 0.666, eval acc, 63.23 %\n",
            " Epoch Number 18\n",
            " Train. Loss: 0.544 Train. Acc: 71.89%\n",
            " Eval loss , 0.579, eval acc, 68.03 %\n",
            " Epoch Number 19\n",
            " Train. Loss: 0.520 Train. Acc: 75.07%\n",
            " Eval loss , 0.627, eval acc, 66.73 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHUUqSS434YB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c11d9c-7042-444c-94fe-793a0827cb4f"
      },
      "source": [
        "#obtain the label list. \r\n",
        "target_list = []\r\n",
        "for _,t in eval_dataset:\r\n",
        "  target_list.append(t)\r\n",
        "\r\n",
        "#obtain the class weights\r\n",
        "leng = len(target_list)\r\n",
        "total_true = sum(target_list)\r\n",
        "class_count = [leng-total_true, total_true]\r\n",
        "class_count"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(496), tensor(51)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRZib4vB9pq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bed83ef-68a7-4152-bbac-d4cb8afd74f9"
      },
      "source": [
        "51/(496+51)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09323583180987204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqSIcZPr9qCY"
      },
      "source": [
        "# Torch Model 2 - Feedforward Regresssion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U02qHiN79wNe"
      },
      "source": [
        "#let's first try a simple FC NN\n",
        "class FFNN_regression (nn.Module):\n",
        "    def __init__(self, input_size,num_hidden, hidden_dim ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert num_hidden > 0 \n",
        "\n",
        "        self.fc1 = nn.Linear(input_size,hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([])\n",
        "        self.hidden_layers.append (self.fc1)\n",
        "        for i in range (num_hidden -1 ):\n",
        "            self.hidden_layers.append(self.fc2)\n",
        "        \n",
        "        self.final_layer = nn.Linear (hidden_dim,1)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = hidden_layer(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.relu(x)\n",
        "        \n",
        "        out = self.final_layer(x)\n",
        "        \n",
        "        return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOkl8d-M-EtB"
      },
      "source": [
        "#try initiating the model\n",
        "INPUT_SIZE = 18\n",
        "NUM_HIDDEN = 4\n",
        "HIDDEN_DIM = 1024\n",
        "\n",
        "model = FFNN_regression(INPUT_SIZE, NUM_HIDDEN, HIDDEN_DIM)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE-ZITBl-EqZ"
      },
      "source": [
        "#define loss fuction and optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQhSlaHL-Eit"
      },
      "source": [
        "#now define the training and evaluation loop\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss= 0\n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data, label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data).squeeze(1)\n",
        "        loss = loss_fn(pred,label)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/len(dataloader)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1LTWnox_rJK"
      },
      "source": [
        "def evaluate(model,dataloader,loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0 \n",
        "\n",
        "    for step,batch in enumerate(dataloader):\n",
        "        data,label = (t for t in batch)\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        pred = model(data).squeeze(1)\n",
        "        loss = loss_fn(pred,label)\n",
        "\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGq3iPf3-lO1",
        "outputId": "55b6a105-3143-4c36-e4dc-7c85e1a66556"
      },
      "source": [
        "N_EPOCHS = 20 \n",
        "\n",
        "for i in range(N_EPOCHS):\n",
        "    train_loss = train(model,train_loader, optimizer, loss_fn)\n",
        "    eval_loss = evaluate(model,eval_loader, loss_fn)\n",
        "    \n",
        "    print (f' Epoch Number {i}') \n",
        "    print (f' Train. Loss: {train_loss:.5f} ')\n",
        "    print (f' Eval loss , {eval_loss:.5f} ')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch Number 0\n",
            " Train. Loss: 0.01819 \n",
            " Eval loss , 0.01586 \n",
            " Epoch Number 1\n",
            " Train. Loss: 0.01819 \n",
            " Eval loss , 0.01614 \n",
            " Epoch Number 2\n",
            " Train. Loss: 0.01786 \n",
            " Eval loss , 0.01623 \n",
            " Epoch Number 3\n",
            " Train. Loss: 0.01790 \n",
            " Eval loss , 0.01642 \n",
            " Epoch Number 4\n",
            " Train. Loss: 0.01800 \n",
            " Eval loss , 0.01593 \n",
            " Epoch Number 5\n",
            " Train. Loss: 0.01772 \n",
            " Eval loss , 0.01546 \n",
            " Epoch Number 6\n",
            " Train. Loss: 0.01777 \n",
            " Eval loss , 0.01570 \n",
            " Epoch Number 7\n",
            " Train. Loss: 0.01737 \n",
            " Eval loss , 0.01564 \n",
            " Epoch Number 8\n",
            " Train. Loss: 0.01764 \n",
            " Eval loss , 0.01640 \n",
            " Epoch Number 9\n",
            " Train. Loss: 0.01744 \n",
            " Eval loss , 0.01590 \n",
            " Epoch Number 10\n",
            " Train. Loss: 0.01722 \n",
            " Eval loss , 0.01566 \n",
            " Epoch Number 11\n",
            " Train. Loss: 0.01740 \n",
            " Eval loss , 0.01632 \n",
            " Epoch Number 12\n",
            " Train. Loss: 0.01794 \n",
            " Eval loss , 0.01632 \n",
            " Epoch Number 13\n",
            " Train. Loss: 0.01759 \n",
            " Eval loss , 0.01537 \n",
            " Epoch Number 14\n",
            " Train. Loss: 0.01768 \n",
            " Eval loss , 0.01596 \n",
            " Epoch Number 15\n",
            " Train. Loss: 0.01705 \n",
            " Eval loss , 0.01582 \n",
            " Epoch Number 16\n",
            " Train. Loss: 0.01724 \n",
            " Eval loss , 0.01615 \n",
            " Epoch Number 17\n",
            " Train. Loss: 0.01743 \n",
            " Eval loss , 0.01585 \n",
            " Epoch Number 18\n",
            " Train. Loss: 0.01743 \n",
            " Eval loss , 0.01560 \n",
            " Epoch Number 19\n",
            " Train. Loss: 0.01714 \n",
            " Eval loss , 0.01593 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyEdBEQh_ayw"
      },
      "source": [
        "The loss seems way too small??? am I calculating it correctly???\n",
        "I'm going to use L1loss instead of L2 loss and see how it goes. \n",
        "It seems that the class imbalance is too dominant, I'll have to work around it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVf57rdX_GQh",
        "outputId": "3241d689-b33d-4b95-c43c-af6153234831"
      },
      "source": [
        "for i,batch in enumerate(train_loader):\n",
        "    data,label = (t for t in batch)\n",
        "    print (i)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GboHeo62BWBW",
        "outputId": "df0a8af7-4279-4a38-db5f-9a85f08658b7"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.9815e-04,  7.7955e-02, -4.8741e-04,  ...,  7.8442e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 1.8731e-03,  4.4611e-02, -2.0406e-03,  ...,  4.6651e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 4.7553e-04,  6.1652e-03, -3.5175e-02,  ...,  4.1340e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        ...,\n",
              "        [-2.4258e-04,  3.4845e-02, -2.3194e-02,  ...,  5.8039e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [-6.1106e-04,  9.8598e-04, -8.4670e-02,  ...,  8.5656e-02,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 7.6427e-03,  1.4638e-02, -3.6971e-02,  ...,  5.1609e-02,\n",
              "          0.0000e+00,  1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v5viZ5fBxE5",
        "outputId": "4a23d3c0-223a-4650-e376-a19c80c97d28"
      },
      "source": [
        "label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0446,  0.0062,  0.0658,  0.0292,  0.2194,  0.0073,  0.0116,  0.0205,\n",
              "         0.0400,  0.0313,  0.0649,  0.0670,  0.0324,  0.0123,  0.0553,  0.0617,\n",
              "         0.0361,  0.0074,  0.0025,  0.0077,  0.0162,  0.0138,  0.0834,  0.1036,\n",
              "         0.0322,  0.0200,  0.0510,  0.0026,  0.0269,  0.0284,  0.0473,  0.0076,\n",
              "         0.0175,  0.0042,  0.0025,  0.0010,  0.0856,  0.0034,  0.0291,  0.0619,\n",
              "         0.0367,  0.0090,  0.0314,  0.0052,  0.0188,  0.0058,  0.0669,  0.0360,\n",
              "         0.0193,  0.0024,  0.0005,  0.0035,  0.0165,  0.0270,  0.0061, -0.0006,\n",
              "         0.0310,  0.0150,  0.0017,  0.0374,  0.0348,  0.0010,  0.0146,  0.0331])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3swifsyBysK",
        "outputId": "e3be6c4d-f594-4733-aad6-04a049b6ab0c"
      },
      "source": [
        "model(data.to(device)).squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0306, 0.0253, 0.0240, 0.0256, 0.0248, 0.0387, 0.0230, 0.0273, 0.0294,\n",
              "        0.0302, 0.0312, 0.0329, 0.0207, 0.0208, 0.0152, 0.0203, 0.0126, 0.0092,\n",
              "        0.0113, 0.0096, 0.0081, 0.0083, 0.0082, 0.0177, 0.0202, 0.0215, 0.0082,\n",
              "        0.0101, 0.0153, 0.0084, 0.0109, 0.0119, 0.0129, 0.0082, 0.0082, 0.0078,\n",
              "        0.0074, 0.0177, 0.0110, 0.0160, 0.0200, 0.0211, 0.0205, 0.0203, 0.0196,\n",
              "        0.0192, 0.0197, 0.0226, 0.0210, 0.0200, 0.0206, 0.0205, 0.0193, 0.0161,\n",
              "        0.0170, 0.0176, 0.0211, 0.0222, 0.0179, 0.0064, 0.0064, 0.0088, 0.0134,\n",
              "        0.0227], device='cuda:0', grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp13tzHLB1mx",
        "outputId": "a27cd2bf-3d43-4de8-d2d3-a36645bc10a9"
      },
      "source": [
        "loss_fn(model(data.to(device)).squeeze(),label.to(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0214, device='cuda:0', grad_fn=<L1LossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_e3F0DCGp2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}